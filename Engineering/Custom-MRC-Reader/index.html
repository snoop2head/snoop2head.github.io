<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=0"/><style data-href="/styles.d53766664f3eaba3db40.css" id="gatsby-global-css">/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden],template{display:none}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}button{background-color:transparent;background-image:none}button:focus{outline:1px dotted;outline:5px auto -webkit-focus-ring-color}fieldset,ol,ul{margin:0;padding:0}ol,ul{list-style:none}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;line-height:1.5}*,:after,:before{box-sizing:border-box;border:0 solid #e2e8f0}hr{border-top-width:1px}img{border-style:solid}textarea{resize:vertical}input::-webkit-input-placeholder,textarea::-webkit-input-placeholder{color:#a0aec0}input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#a0aec0}input::placeholder,textarea::placeholder{color:#a0aec0}[role=button],button{cursor:pointer}table{border-collapse:collapse}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit}code,kbd,pre,samp{font-family:Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}</style><meta name="generator" content="Gatsby 2.32.13"/><style type="text/css">
    .toc-header.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .toc-header.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .toc-header svg,
    h2 .toc-header svg,
    h3 .toc-header svg,
    h4 .toc-header svg,
    h5 .toc-header svg,
    h6 .toc-header svg {
      visibility: hidden;
    }
    h1:hover .toc-header svg,
    h2:hover .toc-header svg,
    h3:hover .toc-header svg,
    h4:hover .toc-header svg,
    h5:hover .toc-header svg,
    h6:hover .toc-header svg,
    h1 .toc-header:focus svg,
    h2 .toc-header:focus svg,
    h3 .toc-header:focus svg,
    h4 .toc-header:focus svg,
    h5 .toc-header:focus svg,
    h6 .toc-header:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="preconnect" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><link rel="icon" href="/favicon-32x32-1c5857f550ca5d27138682501fbd1e0a.png" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><meta name="theme-color" content="#3F4145"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><title data-react-helmet="true">Customizing Question Answering Reader Model | snoop2head&#x27;s blog</title><meta data-react-helmet="true" name="description" content="👍 F1 score of 79.650 ranked the 5th place / 19 teams 💪 Exact Match score of 66.670 ranked 10th place / 19 teams  For Performance and Hyperparameters Comparison, Please refer to 🔗 wandb Extractive Mac…"/><meta data-react-helmet="true" property="og:title" content="Customizing Question Answering Reader Model"/><meta data-react-helmet="true" property="og:image" content="/static/social-image-a1864c5d52ffceef83c1d6baedf4493b.png"/><meta data-react-helmet="true" property="og:description" content="👍 F1 score of 79.650 ranked the 5th place / 19 teams 💪 Exact Match score of 66.670 ranked 10th place / 19 teams  For Performance and Hyperparameters Comparison, Please refer to 🔗 wandb Extractive Mac…"/><meta data-react-helmet="true" property="og:type" content="website"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:image" content="/static/social-image-a1864c5d52ffceef83c1d6baedf4493b.png"/><meta data-react-helmet="true" name="twitter:creator" content="Young Jin Ahn"/><meta data-react-helmet="true" name="twitter:title" content="Customizing Question Answering Reader Model"/><meta data-react-helmet="true" name="twitter:description" content="👍 F1 score of 79.650 ranked the 5th place / 19 teams 💪 Exact Match score of 66.670 ranked 10th place / 19 teams  For Performance and Hyperparameters Comparison, Please refer to 🔗 wandb Extractive Mac…"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link as="script" rel="preload" href="/webpack-runtime-2d2e6eca74f66222a671.js"/><link as="script" rel="preload" href="/framework-c8d3a5345e3f321d7da5.js"/><link as="script" rel="preload" href="/styles-e8fd4555a67a3390b64e.js"/><link as="script" rel="preload" href="/dc6a8720040df98778fe970bf6c000a41750d3ae-4121d07143daec1f6e61.js"/><link as="script" rel="preload" href="/app-6b37a0275bc86b56e034.js"/><link as="script" rel="preload" href="/d7eeaac4-dcbe97e7a5aa158c9d08.js"/><link as="script" rel="preload" href="/5e2a4920-da90abce4a08c86a094c.js"/><link as="script" rel="preload" href="/1bfc9850-103202d7f810115a42e7.js"/><link as="script" rel="preload" href="/commons-33df4d3f9aa201d0ec4c.js"/><link as="script" rel="preload" href="/b1bda0e5b3305dd279ac60c39e10b0f82af56c10-cca622a04473b7e5e8b2.js"/><link as="script" rel="preload" href="/7a297f752dcfe258c0b0106d89edb3a916af916e-d921dc7587d10ed55da7.js"/><link as="script" rel="preload" href="/component---src-templates-blog-post-js-5f317a7779dd1baa19f9.js"/><link as="fetch" rel="preload" href="/page-data/Engineering/Custom-MRC-Reader/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/1081905842.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3911196313.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><noscript><style data-emotion-css="1vyo7ug">.css-1vyo7ug{position:fixed;bottom:0;left:0;margin-left:0.5rem;margin-bottom:0.5rem;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;box-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px 0 rgba(0,0,0,0.06);-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));font-size:0.875rem;font-weight:700;padding-left:1rem;padding-right:1rem;padding-top:0.75rem;padding-bottom:0.75rem;background-color:#86a8e7;z-index:9999;}</style><div class="css-1vyo7ug"><style data-emotion-css="5x4yj0">.css-5x4yj0{fill:currentColor;width:1.5rem;height:1.5rem;margin-right:0.5rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 192 512" class="css-5x4yj0" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M20 424.229h20V279.771H20c-11.046 0-20-8.954-20-20V212c0-11.046 8.954-20 20-20h112c11.046 0 20 8.954 20 20v212.229h20c11.046 0 20 8.954 20 20V492c0 11.046-8.954 20-20 20H20c-11.046 0-20-8.954-20-20v-47.771c0-11.046 8.954-20 20-20zM96 0C56.235 0 24 32.235 24 72s32.235 72 72 72 72-32.235 72-72S135.764 0 96 0z"></path></svg><style data-emotion-css="1f2k2gl">.css-1f2k2gl{margin-left:0.5rem;}</style><div class="css-1f2k2gl">Please enable JavaScript to use this site.<br/>JavaScript를 활성화 시켜주세요.</div></div></noscript><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><style data-emotion-css="f6s0ma">.css-f6s0ma{-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#333333;}</style><style data-emotion-css="acifd">.css-acifd{min-height:100vh;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#333333;}</style><div class="css-acifd e60ayux0"><style data-emotion-css="8ezs2g">.css-8ezs2g{min-height:calc(100vh - 100px);}</style><div class="css-8ezs2g"><style data-emotion-css="1yxw6gp">.css-1yxw6gp{background:linear-gradient( 90deg,#7f7fd5,#86a8e7 );}</style><div class="css-1yxw6gp"><style data-emotion-css="1mqm4zt">.css-1mqm4zt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;max-width:1280px;margin-left:auto;margin-right:auto;padding:1.25rem;}</style><nav class="css-1mqm4zt e1czdvww0"><style data-emotion-css="1usmgm5">.css-1usmgm5{font-size:1.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));font-weight:700;}</style><a class="css-1usmgm5" href="/">Young Jin Ahn&#x27;s Blog</a><a aria-label="search page" href="/search"><style data-emotion-css="47445j">.css-47445j{--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));margin-top:auto;margin-bottom:auto;width:2rem;height:2rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-47445j" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0 0 11.6 0l43.6-43.5a8.2 8.2 0 0 0 0-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></a></nav></div><style data-emotion-css="aod07n">.css-aod07n{background:linear-gradient( 90deg,#7f7fd5,#86a8e7 );position:fixed;width:100%;box-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px 0 rgba(0,0,0,0.06);z-index:100;-webkit-transition:all 300ms cubic-bezier(0,0,0.2,1);transition:all 300ms cubic-bezier(0,0,0.2,1);top:-100px;}</style><div class="css-aod07n"><nav class="css-1mqm4zt e1czdvww0"><a class="css-1usmgm5" href="/">Young Jin Ahn&#x27;s Blog</a><a aria-label="search page" href="/search"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-47445j" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0 0 11.6 0l43.6-43.5a8.2 8.2 0 0 0 0-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></a></nav></div><style data-emotion-css="w27u98">.css-w27u98{margin-top:1rem;padding-left:1rem;padding-right:1rem;}</style><div class="blog-post-container css-w27u98"><div class="blog-post"><style data-emotion-css="1bdwg0l">.css-1bdwg0l{width:100%;max-width:768px;margin-left:auto;margin-right:auto;}</style><div class="css-1bdwg0l eyldt480"><style data-emotion-css="1abxlfd">.css-1abxlfd{font-size:2.25rem;font-weight:700;margin-bottom:1rem;}@media (min-width:768px){.css-1abxlfd{font-size:3rem;}}</style><h1 class="blog-title css-1abxlfd">Customizing Question Answering Reader Model</h1><style data-emotion-css="cpn9zx">.css-cpn9zx{font-size:1rem;margin-bottom:1rem;}</style><h2 class="blog-date css-cpn9zx">2021-11-04</h2><style data-emotion-css="cet0rr">.css-cet0rr{margin-bottom:0.5rem;}</style><div class="blog-tags css-cet0rr"><style data-emotion-css="1ak4bcm">.css-1ak4bcm{white-space:nowrap;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);font-size:1rem;font-weight:700;border-radius:9999px;margin-right:0.5rem;margin-top:0.25rem;margin-bottom:0.25rem;padding-top:0.25rem;padding-bottom:0.25rem;padding-left:0.75rem;padding-right:0.75rem;background-color:#edf2f7;color:#3737B9;}</style><button class="css-1ak4bcm">NLP</button><button class="css-1ak4bcm">MRC</button><button class="css-1ak4bcm">Competition</button></div><style data-emotion-css="1l4w6pd">.css-1l4w6pd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}</style><div class="css-1l4w6pd"><style data-emotion-css="yapsbb">.css-yapsbb{border-radius:9999px;width:100%;height:1px;--bg-opacity:1;background-color:rgba(247,250,252,var(--bg-opacity));background:linear-gradient( 270deg,#7f7fd5,#86a8e7,#91eac9 );}</style><div class="css-yapsbb"></div></div></div><div class="blog-content"><style data-emotion-css="19vk1qv">.css-19vk1qv{-webkit-scrollbar-width:thin;-moz-scrollbar-width:thin;-ms-scrollbar-width:thin;scrollbar-width:thin;-webkit-scrollbar-color:gray transparent;-moz-scrollbar-color:gray transparent;-ms-scrollbar-color:gray transparent;scrollbar-color:gray transparent;display:none;}.css-19vk1qv::-webkit-scrollbar{width:4px;}.css-19vk1qv::-webkit-scrollbar-track{background-color:transparent;}.css-19vk1qv::-webkit-scrollbar-thumb{border-radius:9999px;background-color:gray;}.css-19vk1qv::-webkit-scrollbar-button{width:0;height:0;}@media screen and (min-width:1280px){.css-19vk1qv{float:right;position:-webkit-sticky;position:sticky;top:100px;width:calc((100vw - 720px) / 2 - 80px);max-width:250px;margin-right:1rem;overflow:auto;word-break:break-word;max-height:calc(100vh - 200px);fontsize:1rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;border-left-width:4px;border-image:linear-gradient( 180deg,#7f7fd5,#86a8e7,#91eac9 );border-image-slice:1;}}</style><div class="css-19vk1qv"><style data-emotion-css="13af3fo">.css-13af3fo{margin-left:1rem;margin-right:1rem;}</style><div class="css-13af3fo"><style data-emotion-css="17i5xbf">.css-17i5xbf{font-weight:700;margin-bottom:0.5rem;font-size:1.125rem;--text-opacity:1;color:rgba(74,85,104,var(--text-opacity));}</style><h3 class="css-17i5xbf">TOC</h3><style data-emotion-css="1me4zjn">.css-1me4zjn ul{margin-left:0.5rem;}.css-1me4zjn ul > li a:hover{color:#555555;}.css-1me4zjn ul > li a{-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);--text-opacity:1;color:rgba(160,174,192,var(--text-opacity));font-size:0.875rem;}.css-1me4zjn ul > li a[href=""]{font-size:0.95rem;color:#555555;}</style><div class="css-1me4zjn"><ul>
<li>
<p><a href="/Engineering/Custom-MRC-Reader/#retrieval">Retrieval</a></p>
<ul>
<li><a href="/Engineering/Custom-MRC-Reader/#1-sparse-retrieval">1) Sparse Retrieval</a></li>
<li><a href="/Engineering/Custom-MRC-Reader/#2-dense-retrieval">2) Dense Retrieval</a></li>
</ul>
</li>
<li><a href="/Engineering/Custom-MRC-Reader/#reader">Reader</a></li>
<li><a href="/Engineering/Custom-MRC-Reader/#load-dataset">Load Dataset</a></li>
<li><a href="/Engineering/Custom-MRC-Reader/#make-custom-dataset">Make Custom Dataset</a></li>
<li><a href="/Engineering/Custom-MRC-Reader/#load-tokenizer">Load Tokenizer</a></li>
<li><a href="/Engineering/Custom-MRC-Reader/#custom-dataset-creation-and-truncation">Custom Dataset Creation and Truncation</a></li>
<li><a href="/Engineering/Custom-MRC-Reader/#define-losses-to-use">Define Losses to use</a></li>
<li><a href="/Engineering/Custom-MRC-Reader/#load-model">Load Model</a></li>
<li><a href="/Engineering/Custom-MRC-Reader/#define-optimizer-and-scheduler">Define Optimizer and Scheduler</a></li>
<li><a href="/Engineering/Custom-MRC-Reader/#training">Training</a></li>
</ul></div></div></div><div class="css-1bdwg0l eyldt480"><div><style data-emotion-css="c0q8g3">.css-c0q8g3{font-size:1rem;word-break:break-word;}.css-c0q8g3 h1 > a > svg,.css-c0q8g3 h2 > a > svg,.css-c0q8g3 h3 > a > svg,.css-c0q8g3 h4 > a > svg,.css-c0q8g3 h5 > a > svg,.css-c0q8g3 h6 > a > svg{fill:#000;}.css-c0q8g3 h1,.css-c0q8g3 h2{font-size:1.25rem;font-weight:600;margin-top:1.5rem;margin-bottom:1.5rem;}.css-c0q8g3 h3,.css-c0q8g3 h4,.css-c0q8g3 h5,.css-c0q8g3 h6{font-size:1.125rem;margin-top:1.5rem;margin-bottom:1.5rem;font-weight:600;}@media (min-width:640px){.css-c0q8g3 h1,.css-c0q8g3 h2{font-size:1.5rem;}.css-c0q8g3 h3,.css-c0q8g3 h4,.css-c0q8g3 h5,.css-c0q8g3 h6{font-size:1.25rem;}}.css-c0q8g3 a{color:#3737B9;}.css-c0q8g3 a:hover{-webkit-text-decoration:underline;text-decoration:underline;}.css-c0q8g3 p{margin:0.3rem;margin-top:0.75rem;margin-bottom:0.75rem;}.css-c0q8g3 ul,.css-c0q8g3 ol{margin:0.3rem;margin-left:2rem;}.css-c0q8g3 li > p,.css-c0q8g3 li > ul,.css-c0q8g3 li > ol{margin-bottom:0;}.css-c0q8g3 ol{list-style-type:decimal;}.css-c0q8g3 ul{list-style-type:disc;}.css-c0q8g3 blockquote{padding:0.5rem;background-color:#eee;margin:0.3rem;margin-top:0.5rem;margin-bottom:0.5rem;border-left-width:4px;border-color:#86a8e7;}.css-c0q8g3 blockquote > p{margin:0.5rem;}.css-c0q8g3 blockquote > h1,.css-c0q8g3 blockquote > h2,.css-c0q8g3 blockquote > h3,.css-c0q8g3 blockquote > h4,.css-c0q8g3 blockquote > h5{margin-top:0.5rem;margin-bottom:0.5rem;}.css-c0q8g3 td,.css-c0q8g3 th{padding-left:0.5rem;padding-right:0.5rem;padding-top:0.25rem;padding-bottom:0.25rem;border-width:1px;border-color:#86a8e7;}.css-c0q8g3 tr:nth-of-type(even){background-color:#eee;}.css-c0q8g3 th{background-color:#eee;}.css-c0q8g3 table{margin-bottom:1.5rem;display:block;max-width:-webkit-fit-content;max-width:-moz-fit-content;max-width:fit-content;margin:0 auto;overflow-x:auto;white-space:nowrap;}.css-c0q8g3 p > code,.css-c0q8g3 li > code{padding-top:0.1rem;padding-bottom:0.1rem;padding-right:0.25rem;padding-left:0.25rem;border-radius:0.25rem;color:#3737B9;background-color:#eee;white-space:pre-line;}.css-c0q8g3 pre.grvsc-container{margin-top:24px;margin-bottom:24px;}.css-c0q8g3 hr{margin-top:24px;margin-bottom:24px;height:2px;border:none;background:linear-gradient( 270deg,#7f7fd5,#86a8e7,#91eac9 );}</style><div class="markdown css-c0q8g3"><p>👍 <strong>F1 score of 79.650 ranked the 5th place / 19 teams</strong></p>
<p>💪 <strong>Exact Match score of 66.670 ranked 10th place / 19 teams</strong></p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 45.666666666666664%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABYlAAAWJQFJUiTwAAABZUlEQVQoz3VS7ZKDIAzkLa4qBBHkQ6W1Xq/3/k+2F9C215u5HzuRhITdjaLpJE5NC+scQgwgrXFqOzRS1dhKidF7OEanONcdNe5RfDemiMFaNJwvNSGJsOYFX/mKz7ximy9ILvEFhWEwuK8bvi9Xrq+4pgxnPDdKxOhxP6+4cd+2XHCOC0gZCDM4TGGBlBpSaSjqa/xgdjFMcNbzmaBKTfVoO2KmhCktML1DJ2nv41ohIepB92/QxqBleZLe89TvKAMl6Sr5VTMoakXLfhR0fJB8oVyuuSMWv0qu4wFF6qP2yD3j8S3KUog/4ugxxwRrBqZPKPmCgV9ec8a6ZHjrqvT2GFIf/QOh2XgbHPTQ77AGZHY2zo+4bxvOU0aOM2Oqvu2KDnZPtnsUxljc1hsWZpBS4u1FjC7UpUxp5qWE4zeSVf5TMr2Y/oYo5g+86RTmuu0lZoRx4tf003w6TK/mM6q8fwb+AHmu+BEz9Q/vAAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211104231519392"
        title="image-20211104231519392"
        src="/static/e54184b4b0b3c9b087f62821018a57fd/c1b63/image-20211104231519392.png"
        srcset="/static/e54184b4b0b3c9b087f62821018a57fd/5a46d/image-20211104231519392.png 300w,
/static/e54184b4b0b3c9b087f62821018a57fd/0a47e/image-20211104231519392.png 600w,
/static/e54184b4b0b3c9b087f62821018a57fd/c1b63/image-20211104231519392.png 1200w,
/static/e54184b4b0b3c9b087f62821018a57fd/d61c2/image-20211104231519392.png 1800w,
/static/e54184b4b0b3c9b087f62821018a57fd/97a96/image-20211104231519392.png 2400w,
/static/e54184b4b0b3c9b087f62821018a57fd/65184/image-20211104231519392.png 4144w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<p><strong>For Performance and Hyperparameters Comparison, Please refer to <a href="https://wandb.ai/happyface-boostcamp/KLUE-QA?workspace=user-snoop2head">🔗 wandb</a></strong></p>
<hr>
<p>Extractive Machine Reading Comprehension can be divided into two sub-tasks which are 1) Retrieval and 2) Reader. Retrieval task fetches documents that are related to the tasks. Reader task aims to extract the answer phrase for the given question.</p>
<h2 id="retrieval" style="position:relative;"><a href="#retrieval" aria-label="retrieval permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Retrieval</h2>
<p>For this competition, we tested all the available options given to us.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 26.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABYlAAAWJQFJUiTwAAABYElEQVQY0x2QUW/SUACF+0pGCwKjg3ERaktHL4V0yDrCkptYtJhKMyTqNl10TkNYlsWHLVP3Mk30ZfHZn/uJez5fTr5zNGE2CVoj3IZgKjfZLObJrGWxHYcwDKlUKtSqgmGg2PH7qF4L36pRyBmsZXVM08S2bQxdJ2cYaEMvIhm850XP4zZyUE7lvuQ4iXieTPH9DqV8mYvTr/y6/sGfywWHsaKYy1IqFPE9SRA8Rkqfak2gRb2U2e6SxajP34nFvFOlaVl8TMck0xTPa69sSlx8uub395/cXZ3xcjxClDdI1VsmOzHfXj/j5sOMYxWghZ5isvuGdNtnGXVRXgPd0NnrDUiezGmKRxTyRY5mp7zbP+D8IGWqQmrrG8yfnhCHMZ+jbb68ijmJBmgPG3Xa0mVLSjpBn3qjiRACp+XS7XZxXff+J1GvY63M5Yr7n2cyGcrmOu3VglZbYrtb5B4U+AcCoaBYBWT3OQAAAABJRU5ErkJggg=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211104223835084"
        title="image-20211104223835084"
        src="/static/c08c2e250354ad732ec90d216396d6b5/c1b63/image-20211104223835084.png"
        srcset="/static/c08c2e250354ad732ec90d216396d6b5/5a46d/image-20211104223835084.png 300w,
/static/c08c2e250354ad732ec90d216396d6b5/0a47e/image-20211104223835084.png 600w,
/static/c08c2e250354ad732ec90d216396d6b5/c1b63/image-20211104223835084.png 1200w,
/static/c08c2e250354ad732ec90d216396d6b5/d61c2/image-20211104223835084.png 1800w,
/static/c08c2e250354ad732ec90d216396d6b5/55681/image-20211104223835084.png 2062w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<h3 id="1-sparse-retrieval" style="position:relative;"><a href="#1-sparse-retrieval" aria-label="1 sparse retrieval permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>1) Sparse Retrieval</h3>
<ul>
<li>BM25</li>
<li>BM25+</li>
<li>Elastic Search</li>
</ul>
<h3 id="2-dense-retrieval" style="position:relative;"><a href="#2-dense-retrieval" aria-label="2 dense retrieval permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2) Dense Retrieval</h3>
<ul>
<li>Dense Passage Biencoder - (a)</li>
<li>Cross Encoder - (c)</li>
<li>ColBERT - (d)</li>
</ul>
<h2 id="reader" style="position:relative;"><a href="#reader" aria-label="reader permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reader</h2>
<p>I was interested in building reader model. I thought that Dense Retrieval methods may overperform sparse retrieval methods, but using transformers model is disadvantage in both computation time and resource.</p>
<p><strong>For the reader, I thought it was essential to run small but representative tests for the optimization.</strong></p>
<p>Variables that I tried to control are</p>
<ul>
<li>K-Fold</li>
<li>Learning Rate</li>
<li>Optimizer</li>
<li>Loss</li>
<li>Batch Size and Batching Strategy</li>
<li>Attaching different types of heads to the transformer backbone network(ex: bidirectional LSTM)</li>
<li>Ensemble Strategy</li>
</ul>
<p><strong>Reader's task is multi-class classification task where the model should identify 1) which token is the starting point and 2) which token is end point.</strong> <strong>Answer phrase are multiple tokens in between those predicted token indices.</strong> Thus, both the start<em>logit and end</em>logit is given to each sequence tokens in the sentence.</p>
<p><img src="http://www.mccormickml.com/assets/BERT/SQuAD/start_word_scores_barplot.png" alt="Start word scores"></p>
<p><img src="http://www.mccormickml.com/assets/BERT/SQuAD/end_word_scores_barplot.png" alt="End word scores"></p>
<p><a href="https://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/">Image Source - Question Answering with a Fine-Tuned BERT</a></p>
<p><strong>I customized experimentation code which satiesfied the following criteria.</strong> I aimed to control different types of variables that might affect the Reader's performance.</p>
<p>Validation result should show key primary indices for optimization.</p>
<ol>
<li>Start indexing accuracy(start_accuracy)</li>
<li>End indexing accuracy(end_accuracy)</li>
<li>Answer phrase Exact Match(EM) score</li>
</ol>
<p>These following variables should be customizable where different sets of parameters can be set.</p>
<ul>
<li>Learning Rate</li>
<li>Optimizer: AdamW, AdamP</li>
<li>Loss: FocalLoss, CrossEntropyLoss, LabelSmoothingLoss</li>
<li>Attaching different types of heads to the transformer backbone network(ex: bidirectional LSTM)</li>
</ul>
<h2 id="load-dataset" style="position:relative;"><a href="#load-dataset" aria-label="load dataset permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Load Dataset</h2>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="0"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> os</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">os.environ[</span><span class="mtk6">&quot;TOKENIZERS_PARALLELISM&quot;</span><span class="mtk1">] </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk6">&quot;false&quot;</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="1"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">class</span><span class="mtk1"> </span><span class="mtk11">dotdict</span><span class="mtk1">(</span><span class="mtk8">dict</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk6">&quot;&quot;&quot;dot.notation access to dictionary attributes, as dict.key_name, not as dict[&quot;key_name&quot;] &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk8">__getattr__</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">dict</span><span class="mtk1">.get</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk8">__setattr__</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">dict</span><span class="mtk1">.</span><span class="mtk8">__setitem__</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk8">__delattr__</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">dict</span><span class="mtk1">.</span><span class="mtk8">__delitem__</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="2"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> yaml</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Read config.yaml file</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">with</span><span class="mtk1"> </span><span class="mtk8">open</span><span class="mtk1">(</span><span class="mtk6">&quot;config.yaml&quot;</span><span class="mtk1">) </span><span class="mtk10 mtki">as</span><span class="mtk1"> infile:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk7">SAVED_CFG</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> yaml.</span><span class="mtk3">load</span><span class="mtk1">(infile, </span><span class="mtk4 mtki">Loader</span><span class="mtk8">=</span><span class="mtk1">yaml.FullLoader)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk7">SAVED_CFG</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">dotdict</span><span class="mtk1">(</span><span class="mtk7">SAVED_CFG</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># arguments setting</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">data_args </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">dotdict</span><span class="mtk1">(</span><span class="mtk7">SAVED_CFG</span><span class="mtk1">.data)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model_args </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">dotdict</span><span class="mtk1">(</span><span class="mtk7">SAVED_CFG</span><span class="mtk1">.custom_model)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># adding additional arguments</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model_args.batch_size </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">10</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model_args.num_rnn_layers </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">2</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model_args.learning_rate </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">2e-5</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model_args.num_folds </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">4</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model_args.gamma </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">1.0</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model_args.smoothing </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0.2</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model_args</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="3"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">{&#39;model_name_or_path&#39;: &#39;klue/roberta-large&#39;,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;save_steps&#39;: 100,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;num_train_epochs&#39;: 3,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;learning_rate&#39;: 2e-05,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;batch_size&#39;: 10,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;warmup_steps&#39;: 300,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;weight_decay&#39;: 0.01,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;validation&#39;: False,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;max_length&#39;: 512,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;DEBUG&#39;: True,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;num_rnn_layers&#39;: 2,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;num_folds&#39;: 4,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;gamma&#39;: 1.0,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;smoothing&#39;: 0.2}</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="4"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">name_of_experiment </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk10">f</span><span class="mtk6">&#39;lstm-trainer-AdamW-CE-num_rnn_layers-</span><span class="mtk7">{</span><span class="mtk1">model_args.num_rnn_layers</span><span class="mtk7">}</span><span class="mtk6">-no-clip&#39;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(name_of_experiment)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="5"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">lstm-trainer-AdamW-CE-num_rnn_layers-2-no-clip</span></span></code></pre>
<h2 id="make-custom-dataset" style="position:relative;"><a href="#make-custom-dataset" aria-label="make custom dataset permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Make Custom Dataset</h2>
<p><strong>Remove Passages where Answers located > 512 token length</strong></p>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="6"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> datasets </span><span class="mtk10 mtki">import</span><span class="mtk1"> load_from_disk</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> torch.utils.data </span><span class="mtk10 mtki">import</span><span class="mtk1"> (DataLoader, RandomSampler, TensorDataset)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># load dataset from the huggingface format dataset</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">datasets </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">load_from_disk</span><span class="mtk1">(data_args.dataset_name)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_dataset_from_huggingface </span><span class="mtk8">=</span><span class="mtk1"> datasets[</span><span class="mtk6">&#39;train&#39;</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">valid_dataset_from_huggingface </span><span class="mtk8">=</span><span class="mtk1"> datasets[</span><span class="mtk6">&#39;validation&#39;</span><span class="mtk1">]</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="7"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_dataset_from_huggingface[</span><span class="mtk7">0</span><span class="mtk1">]</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="8"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">{&#39;title&#39;: &#39;미국 상원&#39;,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;context&#39;: &#39;미국 상의원 또는 미국 상원(United States Senate)은 양원제인 미국 의회의 상원이다.\\n\\n미국 부통령이 상원의장이 된다. 각 주당 2명의 상원의원이 선출되어 100명의 상원의원으로 구성되어 있다. 임기는 6년이며, 2년마다 50개주 중 1/3씩 상원의원을 새로 선출하여 연방에 보낸다.\\n\\n미국 상원은 미국 하원과는 다르게 미국 대통령을 수반으로 하는 미국 연방 행정부에 각종 동의를 하는 기관이다. 하원이 세금과 경제에 대한 권한, 대통령을 포함한 대다수의 공무원을 파면할 권한을 갖고 있는 국민을 대표하는 기관인 반면 상원은 미국의 주를 대표한다. 즉 캘리포니아주, 일리노이주 같이 주 정부와 주 의회를 대표하는 기관이다. 그로 인하여 군대의 파병, 관료의 임명에 대한 동의, 외국 조약에 대한 승인 등 신속을 요하는 권한은 모두 상원에게만 있다. 그리고 하원에 대한 견제 역할(하원의 법안을 거부할 권한 등)을 담당한다. 2년의 임기로 인하여 급진적일 수밖에 없는 하원은 지나치게 급진적인 법안을 만들기 쉽다. 대표적인 예로 건강보험 개혁 당시 하원이 미국 연방 행정부에게 퍼블릭 옵션(공공건강보험기관)의 조항이 있는 반면 상원의 경우 하원안이 지나치게 세금이 많이 든다는 이유로 퍼블릭 옵션 조항을 제외하고 비영리건강보험기관이나 보험회사가 담당하도록 한 것이다. 이 경우처럼 상원은 하원이나 내각책임제가 빠지기 쉬운 국가들의 국회처럼 걸핏하면 발생하는 의회의 비정상적인 사태를 방지하는 기관이다. 상원은 급박한 처리사항의 경우가 아니면 법안을 먼저 내는 경우가 드물고 하원이 만든 법안을 수정하여 다시 하원에 되돌려보낸다. 이러한 방식으로 단원제가 빠지기 쉬운 함정을 미리 방지하는 것이다.날짜=2017-02-05&#39;,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;question&#39;: &#39;대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?&#39;,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;id&#39;: &#39;mrc-1-000067&#39;,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;answers&#39;: {&#39;answer_start&#39;: [235], &#39;text&#39;: [&#39;하원&#39;]},</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;document_id&#39;: 18293,</span></span>
<span class="grvsc-line"><span class="grvsc-source"> &#39;__index_level_0__&#39;: 42}</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="9"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> pandas </span><span class="mtk10 mtki">as</span><span class="mtk1"> pd</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> numpy </span><span class="mtk10 mtki">as</span><span class="mtk1"> np</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">pull_out_dictionary</span><span class="mtk1">(</span><span class="mtk7 mtki">df_input</span><span class="mtk1">: pd.DataFrame):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk6">&quot;&quot;&quot;pull out str `{}` values from the pandas dataframe and shape it as a new column&quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    df </span><span class="mtk8">=</span><span class="mtk1"> df_input.</span><span class="mtk3">copy</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># assign subject_entity and object_entity column values type as dictionary</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># df[&quot;answers&quot;] = df[&quot;answers&quot;].apply(lambda x: eval(x))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    df </span><span class="mtk8">=</span><span class="mtk1"> df.</span><span class="mtk3">assign</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># subject_entity</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">answer_start</span><span class="mtk8">=</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&quot;answers&quot;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&quot;answer_start&quot;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">text</span><span class="mtk8">=</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&quot;answers&quot;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&quot;text&quot;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># drop subject_entity and object_entity column</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    df </span><span class="mtk8">=</span><span class="mtk1"> df.</span><span class="mtk3">drop</span><span class="mtk1">([</span><span class="mtk6">&quot;answers&quot;</span><span class="mtk1">], </span><span class="mtk4 mtki">axis</span><span class="mtk8">=</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">return</span><span class="mtk1"> df</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">pull_out_list</span><span class="mtk1">(</span><span class="mtk7 mtki">df_input</span><span class="mtk1">: pd.DataFrame):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk6">&quot;&quot;&quot; pull out single item out of the list &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    df </span><span class="mtk8">=</span><span class="mtk1"> df_input.</span><span class="mtk3">copy</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    df[</span><span class="mtk6">&quot;answer_start&quot;</span><span class="mtk1">] </span><span class="mtk8">=</span><span class="mtk1"> df[</span><span class="mtk6">&quot;answer_start&quot;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: </span><span class="mtk8">int</span><span class="mtk1">(x[</span><span class="mtk7">0</span><span class="mtk1">]))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    df[</span><span class="mtk6">&quot;text&quot;</span><span class="mtk1">] </span><span class="mtk8">=</span><span class="mtk1"> df[</span><span class="mtk6">&quot;text&quot;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk7">0</span><span class="mtk1">])</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">return</span><span class="mtk1"> df</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="10"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">&quot;&quot;&quot; Converting train and validation dataset to Pandas dataframe for convenience &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_df </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">pull_out_dictionary</span><span class="mtk1">(pd.DataFrame.</span><span class="mtk3">from_records</span><span class="mtk1">(datasets[</span><span class="mtk6">&#39;train&#39;</span><span class="mtk1">]))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">val_df </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">pull_out_dictionary</span><span class="mtk1">(pd.DataFrame.</span><span class="mtk3">from_records</span><span class="mtk1">(datasets[</span><span class="mtk6">&#39;validation&#39;</span><span class="mtk1">]))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_df </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">pull_out_list</span><span class="mtk1">(train_df)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">val_df </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">pull_out_list</span><span class="mtk1">(val_df)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(train_df.shape)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(val_df.shape)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="11"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">(3952, 8)</span></span>
<span class="grvsc-line"><span class="grvsc-source">(240, 8)</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="12"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(train_df.columns)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="13"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">Index([&#39;title&#39;, &#39;context&#39;, &#39;question&#39;, &#39;id&#39;, &#39;document_id&#39;,</span></span>
<span class="grvsc-line"><span class="grvsc-source">       &#39;__index_level_0__&#39;, &#39;answer_start&#39;, &#39;text&#39;],</span></span>
<span class="grvsc-line"><span class="grvsc-source">      dtype=&#39;object&#39;)</span></span></code></pre>
<h2 id="load-tokenizer" style="position:relative;"><a href="#load-tokenizer" aria-label="load tokenizer permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Load Tokenizer</h2>
<p>Fixed: roberta not receiving sequence ids</p>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="14"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> transformers </span><span class="mtk10 mtki">import</span><span class="mtk1"> AutoModel, AutoTokenizer, AutoConfig</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># load tokenizer and configuration according to the model (ex: klue/roberta-large)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk6">&quot;roberta&quot;</span><span class="mtk1"> </span><span class="mtk10">in</span><span class="mtk1"> model_args.model_name_or_path:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    tokenizer </span><span class="mtk8">=</span><span class="mtk1"> AutoTokenizer.</span><span class="mtk3">from_pretrained</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        model_args.model_name_or_path,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">model_input_names</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> [</span><span class="mtk6">&quot;input_ids&quot;</span><span class="mtk1">, </span><span class="mtk6">&quot;attention_mask&quot;</span><span class="mtk1">],</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">use_fast</span><span class="mtk8">=</span><span class="mtk7">True</span><span class="mtk1"> </span><span class="mtk5 mtki"># use rust based tokenizer</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&quot;sequence id not used:&quot;</span><span class="mtk1">, model_args.model_name_or_path)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">else</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    tokenizer </span><span class="mtk8">=</span><span class="mtk1"> AutoTokenizer.</span><span class="mtk3">from_pretrained</span><span class="mtk1">(model_args.model_name_or_path)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk8">print</span><span class="mtk1">(model_args.model_name_or_path)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">config </span><span class="mtk8">=</span><span class="mtk1"> AutoConfig.</span><span class="mtk3">from_pretrained</span><span class="mtk1">(model_args.model_name_or_path)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="15"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">sequence id not used: klue/roberta-large</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="16"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># sample tokenization</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">tokens </span><span class="mtk8">=</span><span class="mtk1"> tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(train_dataset_from_huggingface[</span><span class="mtk7">1</span><span class="mtk1">][</span><span class="mtk6">&#39;question&#39;</span><span class="mtk1">])</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">&quot; &quot;</span><span class="mtk1">.</span><span class="mtk3">join</span><span class="mtk1">(tokens)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="17"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">&#39;현대 ##적 인사 ##조 ##직 ##관리 ##의 시발점 ##이 된 책 ##은 ?&#39;</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="18"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># test batch tokenization</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># https://github.com/huggingface/transformers/issues/10297#issuecomment-783464293</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">sample_answer_token </span><span class="mtk8">=</span><span class="mtk1"> [</span><span class="mtk6">&#39;크리스토&#39;</span><span class="mtk1">, </span><span class="mtk6">&#39;##포&#39;</span><span class="mtk1">, </span><span class="mtk6">&#39;알&#39;</span><span class="mtk1">, </span><span class="mtk6">&#39;##하우스&#39;</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(sample_answer_token)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&quot;Wrong Example:&quot;</span><span class="mtk1">, tokenizer.</span><span class="mtk3">encode</span><span class="mtk1">(sample_answer_token, </span><span class="mtk4 mtki">add_special_tokens</span><span class="mtk8">=</span><span class="mtk7">False</span><span class="mtk1">, </span><span class="mtk4 mtki">return_tensors</span><span class="mtk8">=</span><span class="mtk6">&#39;pt&#39;</span><span class="mtk1">, </span><span class="mtk4 mtki">is_split_into_words</span><span class="mtk8">=</span><span class="mtk7">True</span><span class="mtk1">))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&quot;Correctly Encoded:&quot;</span><span class="mtk1"> ,torch.</span><span class="mtk3">IntTensor</span><span class="mtk1">([tokenizer.</span><span class="mtk3">convert_tokens_to_ids</span><span class="mtk1">(sample_answer_token)])) </span><span class="mtk5 mtki"># apply int for torch Tensor</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="19"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">[&#39;크리스토&#39;, &#39;##포&#39;, &#39;알&#39;, &#39;##하우스&#39;]</span></span>
<span class="grvsc-line"><span class="grvsc-source">Wrong Example: tensor([[21533,     7,     7,  1862,  1381,     7,     7,  6634]])</span></span>
<span class="grvsc-line"><span class="grvsc-source">Correctly Encoded: tensor([[21533,  2208,  1381, 17975]], dtype=torch.int32)</span></span></code></pre>
<h2 id="custom-dataset-creation-and-truncation" style="position:relative;"><a href="#custom-dataset-creation-and-truncation" aria-label="custom dataset creation and truncation permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Custom Dataset Creation and Truncation</h2>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="20"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_df.shape</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="21"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">(3952, 8)</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="22"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># change dataframe to dictionary</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_df_dict </span><span class="mtk8">=</span><span class="mtk1"> train_df.</span><span class="mtk3">to_dict</span><span class="mtk1">(</span><span class="mtk6">&#39;records&#39;</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">valid_df_dict </span><span class="mtk8">=</span><span class="mtk1"> val_df.</span><span class="mtk3">to_dict</span><span class="mtk1">(</span><span class="mtk6">&#39;records&#39;</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(train_df_dict[</span><span class="mtk7">0</span><span class="mtk1">])</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(train_df_dict[</span><span class="mtk7">0</span><span class="mtk1">].</span><span class="mtk3">keys</span><span class="mtk1">())</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk8">len</span><span class="mtk1">(train_df_dict))</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="23"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">{&#39;title&#39;: &#39;미국 상원&#39;, &#39;context&#39;: &#39;미국 상의원 또는 미국 상원(United States Senate)은 양원제인 미국 의회의 상원이다.\\n\\n미국 부통령이 상원의장이 된다. 각 주당 2명의 상원의원이 선출되어 100명의 상원의원으로 구성되어 있다. 임기는 6년이며, 2년마다 50개주 중 1/3씩 상원의원을 새로 선출하여 연방에 보낸다.\\n\\n미국 상원은 미국 하원과는 다르게 미국 대통령을 수반으로 하는 미국 연방 행정부에 각종 동의를 하는 기관이다. 하원이 세금과 경제에 대한 권한, 대통령을 포함한 대다수의 공무원을 파면할 권한을 갖고 있는 국민을 대표하는 기관인 반면 상원은 미국의 주를 대표한다. 즉 캘리포니아주, 일리노이주 같이 주 정부와 주 의회를 대표하는 기관이다. 그로 인하여 군대의 파병, 관료의 임명에 대한 동의, 외국 조약에 대한 승인 등 신속을 요하는 권한은 모두 상원에게만 있다. 그리고 하원에 대한 견제 역할(하원의 법안을 거부할 권한 등)을 담당한다. 2년의 임기로 인하여 급진적일 수밖에 없는 하원은 지나치게 급진적인 법안을 만들기 쉽다. 대표적인 예로 건강보험 개혁 당시 하원이 미국 연방 행정부에게 퍼블릭 옵션(공공건강보험기관)의 조항이 있는 반면 상원의 경우 하원안이 지나치게 세금이 많이 든다는 이유로 퍼블릭 옵션 조항을 제외하고 비영리건강보험기관이나 보험회사가 담당하도록 한 것이다. 이 경우처럼 상원은 하원이나 내각책임제가 빠지기 쉬운 국가들의 국회처럼 걸핏하면 발생하는 의회의 비정상적인 사태를 방지하는 기관이다. 상원은 급박한 처리사항의 경우가 아니면 법안을 먼저 내는 경우가 드물고 하원이 만든 법안을 수정하여 다시 하원에 되돌려보낸다. 이러한 방식으로 단원제가 빠지기 쉬운 함정을 미리 방지하는 것이다.날짜=2017-02-05&#39;, &#39;question&#39;: &#39;대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?&#39;, &#39;id&#39;: &#39;mrc-1-000067&#39;, &#39;document_id&#39;: 18293, &#39;__index_level_0__&#39;: 42, &#39;answer_start&#39;: 235, &#39;text&#39;: &#39;하원&#39;}</span></span>
<span class="grvsc-line"><span class="grvsc-source">dict_keys([&#39;title&#39;, &#39;context&#39;, &#39;question&#39;, &#39;id&#39;, &#39;document_id&#39;, &#39;__index_level_0__&#39;, &#39;answer_start&#39;, &#39;text&#39;])</span></span>
<span class="grvsc-line"><span class="grvsc-source">3952</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="24"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">tokenizer.mask_token_id</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="25"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">4</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="26"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk7">DEBUG_MODE</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">True</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">drop_truncated_data</span><span class="mtk1">(</span><span class="mtk7 mtki">dict_df</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk6">&quot;&quot;&quot; dataset creation reference: https://mccormickml.com/2021/05/27/question-answering-system-tf-idf/ &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># Lists to store the encoded samples.</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    all_input_ids </span><span class="mtk8">=</span><span class="mtk1"> []</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    attention_masks </span><span class="mtk8">=</span><span class="mtk1"> []</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    start_positions </span><span class="mtk8">=</span><span class="mtk1"> []</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    end_positions </span><span class="mtk8">=</span><span class="mtk1"> []</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    num_dropped </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">for</span><span class="mtk1"> num, item </span><span class="mtk10">in</span><span class="mtk1"> </span><span class="mtk8">enumerate</span><span class="mtk1">(dict_df):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        answer_tokens </span><span class="mtk8">=</span><span class="mtk1"> tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(item[</span><span class="mtk6">&#39;text&#39;</span><span class="mtk1">], </span><span class="mtk4 mtki">add_special_tokens</span><span class="mtk8">=</span><span class="mtk7">False</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        sentinel_str </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk6">&quot; &quot;</span><span class="mtk1">.</span><span class="mtk3">join</span><span class="mtk1">([tokenizer.mask_token]</span><span class="mtk8">*len</span><span class="mtk1">(answer_tokens))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        start_char_i </span><span class="mtk8">=</span><span class="mtk1"> item[</span><span class="mtk6">&#39;answer_start&#39;</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        end_char_i </span><span class="mtk8">=</span><span class="mtk1"> start_char_i </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(item[</span><span class="mtk6">&#39;text&#39;</span><span class="mtk1">])</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        context_w_sentinel </span><span class="mtk8">=</span><span class="mtk1"> \</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            item[</span><span class="mtk6">&#39;context&#39;</span><span class="mtk1">][:start_char_i] \</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk8">+</span><span class="mtk1"> sentinel_str \</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk8">+</span><span class="mtk1"> item[</span><span class="mtk6">&#39;context&#39;</span><span class="mtk1">][end_char_i:]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        encoded_dict </span><span class="mtk8">=</span><span class="mtk1"> tokenizer.</span><span class="mtk3">encode_plus</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            item[</span><span class="mtk6">&#39;question&#39;</span><span class="mtk1">],</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            context_w_sentinel,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">add_special_tokens</span><span class="mtk8">=</span><span class="mtk7">True</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">max_length</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> model_args.max_seq_length,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk6">&#39;max_length&#39;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">return_attention_mask</span><span class="mtk8">=</span><span class="mtk7">True</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">return_tensors</span><span class="mtk8">=</span><span class="mtk6">&#39;pt&#39;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">truncation</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">True</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        input_ids </span><span class="mtk8">=</span><span class="mtk1"> encoded_dict[</span><span class="mtk6">&#39;input_ids&#39;</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        is_mask_token </span><span class="mtk8">=</span><span class="mtk1"> (input_ids[</span><span class="mtk7">0</span><span class="mtk1">] </span><span class="mtk8">==</span><span class="mtk1"> tokenizer.mask_token_id)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        mask_token_indeces </span><span class="mtk8">=</span><span class="mtk1"> is_mask_token.</span><span class="mtk3">nonzero</span><span class="mtk1">(</span><span class="mtk4 mtki">as_tuple</span><span class="mtk8">=</span><span class="mtk7">False</span><span class="mtk1">)[:, </span><span class="mtk7">0</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk10">not</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(mask_token_indeces) </span><span class="mtk8">==</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(answer_tokens):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            num_dropped </span><span class="mtk8">+=</span><span class="mtk1"> </span><span class="mtk7">1</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk10 mtki">continue</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        start_index </span><span class="mtk8">=</span><span class="mtk1"> mask_token_indeces[</span><span class="mtk7">0</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        end_index </span><span class="mtk8">=</span><span class="mtk1"> mask_token_indeces[</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># change start_index tensor and end_index tensor into integer type</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        start_index </span><span class="mtk8">=</span><span class="mtk1"> start_index.</span><span class="mtk3">item</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        end_index </span><span class="mtk8">=</span><span class="mtk1"> end_index.</span><span class="mtk3">item</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        answer_token_ids </span><span class="mtk8">=</span><span class="mtk1"> tokenizer.</span><span class="mtk3">convert_tokens_to_ids</span><span class="mtk1">(answer_tokens)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        input_ids[</span><span class="mtk7">0</span><span class="mtk1">, start_index : end_index </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">] </span><span class="mtk8">=</span><span class="mtk1"> torch.</span><span class="mtk3">tensor</span><span class="mtk1">(answer_token_ids)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        all_input_ids.</span><span class="mtk3">append</span><span class="mtk1">(input_ids)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        attention_masks.</span><span class="mtk3">append</span><span class="mtk1">(encoded_dict[</span><span class="mtk6">&#39;attention_mask&#39;</span><span class="mtk1">])</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        start_positions.</span><span class="mtk3">append</span><span class="mtk1">(start_index)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        end_positions.</span><span class="mtk3">append</span><span class="mtk1">(end_index)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># Convert the lists of tensors into 2D tensors.</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    all_input_ids </span><span class="mtk8">=</span><span class="mtk1"> torch.</span><span class="mtk3">cat</span><span class="mtk1">(all_input_ids, </span><span class="mtk4 mtki">dim</span><span class="mtk8">=</span><span class="mtk7">0</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    attention_masks </span><span class="mtk8">=</span><span class="mtk1"> torch.</span><span class="mtk3">cat</span><span class="mtk1">(attention_masks, </span><span class="mtk4 mtki">dim</span><span class="mtk8">=</span><span class="mtk7">0</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># Convert the &quot;labels&quot; (the start and end indeces) into tensors.</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    start_positions </span><span class="mtk8">=</span><span class="mtk1"> torch.</span><span class="mtk3">tensor</span><span class="mtk1">(start_positions)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    end_positions </span><span class="mtk8">=</span><span class="mtk1"> torch.</span><span class="mtk3">tensor</span><span class="mtk1">(end_positions)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">return</span><span class="mtk1"> all_input_ids, attention_masks, start_positions, end_positions</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="27"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> torch.utils.data </span><span class="mtk10 mtki">import</span><span class="mtk1"> DataLoader</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_truncated </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">drop_truncated_data</span><span class="mtk1">(train_df_dict)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_dataset </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">TensorDataset</span><span class="mtk1">(train_truncated[</span><span class="mtk7">0</span><span class="mtk1">], train_truncated[</span><span class="mtk7">1</span><span class="mtk1">], train_truncated[</span><span class="mtk7">2</span><span class="mtk1">], train_truncated[</span><span class="mtk7">3</span><span class="mtk1">])</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_dataloader </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">DataLoader</span><span class="mtk1">(train_dataset, </span><span class="mtk4 mtki">batch_size</span><span class="mtk8">=</span><span class="mtk1">model_args.batch_size, </span><span class="mtk4 mtki">shuffle</span><span class="mtk8">=</span><span class="mtk7">True</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">valid_truncated </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">drop_truncated_data</span><span class="mtk1">(valid_df_dict)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">valid_dataset </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">TensorDataset</span><span class="mtk1">(valid_truncated[</span><span class="mtk7">0</span><span class="mtk1">], valid_truncated[</span><span class="mtk7">1</span><span class="mtk1">], valid_truncated[</span><span class="mtk7">2</span><span class="mtk1">], valid_truncated[</span><span class="mtk7">3</span><span class="mtk1">])</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">valid_dataloader </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">DataLoader</span><span class="mtk1">(valid_dataset, </span><span class="mtk4 mtki">batch_size</span><span class="mtk8">=</span><span class="mtk1">model_args.batch_size, </span><span class="mtk4 mtki">shuffle</span><span class="mtk8">=</span><span class="mtk7">False</span><span class="mtk1">)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="28"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(train_df.shape)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk8">len</span><span class="mtk1">(train_dataset)) </span><span class="mtk5 mtki"># number of clipped samples where answers are located out of the maximum sequence length</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(val_df.shape)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">len</span><span class="mtk1">(valid_dataset) </span><span class="mtk5 mtki"># number of clipped samples where answers are located out of the maximum sequence length</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="29"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">(3952, 8)</span></span>
<span class="grvsc-line"><span class="grvsc-source">3706</span></span>
<span class="grvsc-line"><span class="grvsc-source">(240, 8)</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">220</span></span></code></pre>
<h2 id="define-losses-to-use" style="position:relative;"><a href="#define-losses-to-use" aria-label="define losses to use permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Define Losses to use</h2>
<ul>
<li>CrossEntropyLoss provided by torch.nn was the best</li>
<li>For Performance Comparison, Please refer to <a href="https://wandb.ai/happyface-boostcamp/KLUE-QA?workspace=user-snoop2head">🔗 wandb</a></li>
</ul>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="30"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch.nn </span><span class="mtk10 mtki">as</span><span class="mtk1"> nn</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch.nn.functional </span><span class="mtk10 mtki">as</span><span class="mtk1"> F</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> torch.autograd </span><span class="mtk10 mtki">import</span><span class="mtk1"> Variable</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">class</span><span class="mtk1"> </span><span class="mtk11">FocalLoss</span><span class="mtk1">(</span><span class="mtk11">nn</span><span class="mtk1">.</span><span class="mtk11">Module</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk8">__init__</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">, </span><span class="mtk7 mtki">gamma</span><span class="mtk1">=</span><span class="mtk7">0.5</span><span class="mtk1">, </span><span class="mtk7 mtki">alpha</span><span class="mtk1">=</span><span class="mtk7">None</span><span class="mtk1">, </span><span class="mtk7 mtki">size_average</span><span class="mtk1">=</span><span class="mtk7">True</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk8">super</span><span class="mtk1">(FocalLoss, </span><span class="mtk11">self</span><span class="mtk1">).</span><span class="mtk8">__init__</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.gamma </span><span class="mtk8">=</span><span class="mtk1"> gamma</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.alpha </span><span class="mtk8">=</span><span class="mtk1"> alpha</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk8">isinstance</span><span class="mtk1">(alpha, (</span><span class="mtk8">float</span><span class="mtk1">, </span><span class="mtk8">int</span><span class="mtk1">)):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk11">self</span><span class="mtk1">.alpha </span><span class="mtk8">=</span><span class="mtk1"> torch.</span><span class="mtk3">Tensor</span><span class="mtk1">([alpha, </span><span class="mtk7">1</span><span class="mtk1"> </span><span class="mtk8">-</span><span class="mtk1"> alpha])</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk8">isinstance</span><span class="mtk1">(alpha, </span><span class="mtk8">list</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk11">self</span><span class="mtk1">.alpha </span><span class="mtk8">=</span><span class="mtk1"> torch.</span><span class="mtk3">Tensor</span><span class="mtk1">(alpha)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.size_average </span><span class="mtk8">=</span><span class="mtk1"> size_average</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">forward</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">, </span><span class="mtk7 mtki">input</span><span class="mtk1">, </span><span class="mtk7 mtki">target</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk8">input</span><span class="mtk1">.</span><span class="mtk3">dim</span><span class="mtk1">() </span><span class="mtk8">&gt;</span><span class="mtk1"> </span><span class="mtk7">2</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk8">input</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">input</span><span class="mtk1">.</span><span class="mtk3">view</span><span class="mtk1">(</span><span class="mtk8">input</span><span class="mtk1">.</span><span class="mtk3">size</span><span class="mtk1">(</span><span class="mtk7">0</span><span class="mtk1">), </span><span class="mtk8">input</span><span class="mtk1">.</span><span class="mtk3">size</span><span class="mtk1">(</span><span class="mtk7">1</span><span class="mtk1">), </span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">)  </span><span class="mtk5 mtki"># N,C,H,W =&gt; N,C,H*W</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk8">input</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">input</span><span class="mtk1">.</span><span class="mtk3">transpose</span><span class="mtk1">(</span><span class="mtk7">1</span><span class="mtk1">, </span><span class="mtk7">2</span><span class="mtk1">)  </span><span class="mtk5 mtki"># N,C,H*W =&gt; N,H*W,C</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk8">input</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">input</span><span class="mtk1">.</span><span class="mtk3">contiguous</span><span class="mtk1">().</span><span class="mtk3">view</span><span class="mtk1">(</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">, </span><span class="mtk8">input</span><span class="mtk1">.</span><span class="mtk3">size</span><span class="mtk1">(</span><span class="mtk7">2</span><span class="mtk1">))  </span><span class="mtk5 mtki"># N,H*W,C =&gt; N*H*W,C</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        target </span><span class="mtk8">=</span><span class="mtk1"> target.</span><span class="mtk3">view</span><span class="mtk1">(</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">, </span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        logpt </span><span class="mtk8">=</span><span class="mtk1"> F.</span><span class="mtk3">log_softmax</span><span class="mtk1">(</span><span class="mtk8">input</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        logpt </span><span class="mtk8">=</span><span class="mtk1"> logpt.</span><span class="mtk3">gather</span><span class="mtk1">(</span><span class="mtk7">1</span><span class="mtk1">, target)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        logpt </span><span class="mtk8">=</span><span class="mtk1"> logpt.</span><span class="mtk3">view</span><span class="mtk1">(</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        pt </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">Variable</span><span class="mtk1">(logpt.data.</span><span class="mtk3">exp</span><span class="mtk1">())</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.alpha </span><span class="mtk10">is</span><span class="mtk1"> </span><span class="mtk10">not</span><span class="mtk1"> </span><span class="mtk7">None</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.alpha.</span><span class="mtk3">type</span><span class="mtk1">() </span><span class="mtk8">!=</span><span class="mtk1"> </span><span class="mtk8">input</span><span class="mtk1">.data.</span><span class="mtk3">type</span><span class="mtk1">():</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk11">self</span><span class="mtk1">.alpha </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.alpha.</span><span class="mtk3">type_as</span><span class="mtk1">(</span><span class="mtk8">input</span><span class="mtk1">.data)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            at </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.alpha.</span><span class="mtk3">gather</span><span class="mtk1">(</span><span class="mtk7">0</span><span class="mtk1">, target.data.</span><span class="mtk3">view</span><span class="mtk1">(</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            logpt </span><span class="mtk8">=</span><span class="mtk1"> logpt </span><span class="mtk8">*</span><span class="mtk1"> </span><span class="mtk3">Variable</span><span class="mtk1">(at)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        loss </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1"> </span><span class="mtk8">*</span><span class="mtk1"> (</span><span class="mtk7">1</span><span class="mtk1"> </span><span class="mtk8">-</span><span class="mtk1"> pt) </span><span class="mtk8">**</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.gamma </span><span class="mtk8">*</span><span class="mtk1"> logpt</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.size_average:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk10 mtki">return</span><span class="mtk1"> loss.</span><span class="mtk3">mean</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">else</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk10 mtki">return</span><span class="mtk1"> loss.</span><span class="mtk3">sum</span><span class="mtk1">()</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="31"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch.nn.functional </span><span class="mtk10 mtki">as</span><span class="mtk1"> F</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> torch.nn.modules.loss </span><span class="mtk10 mtki">import</span><span class="mtk1"> _WeightedLoss</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">class</span><span class="mtk1"> </span><span class="mtk11">LabelSmoothCrossEntropyLoss</span><span class="mtk1">(</span><span class="mtk11">_WeightedLoss</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># https://github.com/NingAnMe/Label-Smoothing-for-CrossEntropyLoss-PyTorch/blob/main/label_smothing_cross_entropy_loss.py</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk8">__init__</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">, </span><span class="mtk7 mtki">weight</span><span class="mtk1">=</span><span class="mtk7">None</span><span class="mtk1">, </span><span class="mtk7 mtki">reduction</span><span class="mtk1">=</span><span class="mtk6">&#39;mean&#39;</span><span class="mtk1">, </span><span class="mtk7 mtki">smoothing</span><span class="mtk1">=</span><span class="mtk7">0.0</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk8">super</span><span class="mtk1">().</span><span class="mtk8">__init__</span><span class="mtk1">(</span><span class="mtk4 mtki">weight</span><span class="mtk8">=</span><span class="mtk1">weight, </span><span class="mtk4 mtki">reduction</span><span class="mtk8">=</span><span class="mtk1">reduction)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.smoothing </span><span class="mtk8">=</span><span class="mtk1"> smoothing</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.weight </span><span class="mtk8">=</span><span class="mtk1"> weight</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.reduction </span><span class="mtk8">=</span><span class="mtk1"> reduction</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk3">    @</span><span class="mtk8">staticmethod</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">_smooth_one_hot</span><span class="mtk1">(</span><span class="mtk7 mtki">targets</span><span class="mtk1">: torch.Tensor, </span><span class="mtk7 mtki">n_classes</span><span class="mtk1">: </span><span class="mtk8">int</span><span class="mtk1">, </span><span class="mtk7 mtki">smoothing</span><span class="mtk1">=</span><span class="mtk7">0.0</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">assert</span><span class="mtk1"> </span><span class="mtk7">0</span><span class="mtk1"> </span><span class="mtk8">&lt;=</span><span class="mtk1"> smoothing </span><span class="mtk8">&lt;</span><span class="mtk1"> </span><span class="mtk7">1</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">with</span><span class="mtk1"> torch.</span><span class="mtk3">no_grad</span><span class="mtk1">():</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            targets </span><span class="mtk8">=</span><span class="mtk1"> torch.</span><span class="mtk3">empty</span><span class="mtk1">(</span><span class="mtk4 mtki">size</span><span class="mtk8">=</span><span class="mtk1">(targets.</span><span class="mtk3">size</span><span class="mtk1">(</span><span class="mtk7">0</span><span class="mtk1">), n_classes),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                                  </span><span class="mtk4 mtki">device</span><span class="mtk8">=</span><span class="mtk1">targets.device) \</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                .</span><span class="mtk3">fill_</span><span class="mtk1">(smoothing </span><span class="mtk8">/</span><span class="mtk1"> (n_classes </span><span class="mtk8">-</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">)) \</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                .</span><span class="mtk3">scatter_</span><span class="mtk1">(</span><span class="mtk7">1</span><span class="mtk1">, targets.data.</span><span class="mtk3">unsqueeze</span><span class="mtk1">(</span><span class="mtk7">1</span><span class="mtk1">), </span><span class="mtk7">1</span><span class="mtk1">. </span><span class="mtk8">-</span><span class="mtk1"> smoothing)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">return</span><span class="mtk1"> targets</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">forward</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">, </span><span class="mtk7 mtki">inputs</span><span class="mtk1">, </span><span class="mtk7 mtki">targets</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        targets </span><span class="mtk8">=</span><span class="mtk1"> LabelSmoothCrossEntropyLoss.</span><span class="mtk3">_smooth_one_hot</span><span class="mtk1">(targets, inputs.</span><span class="mtk3">size</span><span class="mtk1">(</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                                                              </span><span class="mtk11">self</span><span class="mtk1">.smoothing)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        lsm </span><span class="mtk8">=</span><span class="mtk1"> F.</span><span class="mtk3">log_softmax</span><span class="mtk1">(inputs, </span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.weight </span><span class="mtk10">is</span><span class="mtk1"> </span><span class="mtk10">not</span><span class="mtk1"> </span><span class="mtk7">None</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            lsm </span><span class="mtk8">=</span><span class="mtk1"> lsm </span><span class="mtk8">*</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.weight.</span><span class="mtk3">unsqueeze</span><span class="mtk1">(</span><span class="mtk7">0</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        loss </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">-</span><span class="mtk1">(targets </span><span class="mtk8">*</span><span class="mtk1"> lsm).</span><span class="mtk3">sum</span><span class="mtk1">(</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.reduction </span><span class="mtk8">==</span><span class="mtk1"> </span><span class="mtk6">&#39;sum&#39;</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            loss </span><span class="mtk8">=</span><span class="mtk1"> loss.</span><span class="mtk3">sum</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">elif</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.reduction </span><span class="mtk8">==</span><span class="mtk1"> </span><span class="mtk6">&#39;mean&#39;</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            loss </span><span class="mtk8">=</span><span class="mtk1"> loss.</span><span class="mtk3">mean</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">return</span><span class="mtk1"> loss</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="32"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># https://github.com/cvqluu/Angular-Penalty-Softmax-Losses-Pytorch -&gt; doesn&#39;t work, full of bugs</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># https://github.com/ronghuaiyang/arcface-pytorch/blob/master/models/metrics.py -&gt; fail</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="33"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># https://github.com/CoinCheung/pytorch-loss/blob/master/dice_loss.py -&gt; Not working</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># https://github.com/ShannonAI/dice_loss_for_NLP/blob/master/loss/dice_loss.py -&gt; Loss too big: 300 or more</span></span></span></code></pre>
<h2 id="load-model" style="position:relative;"><a href="#load-model" aria-label="load model permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Load Model</h2>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="34"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model_args.</span><span class="mtk7">DEBUG</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">False</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">device </span><span class="mtk8">=</span><span class="mtk1"> torch.</span><span class="mtk3">device</span><span class="mtk1">(</span><span class="mtk6">&#39;cuda:0&#39;</span><span class="mtk1"> </span><span class="mtk10 mtki">if</span><span class="mtk1"> torch.cuda.</span><span class="mtk3">is_available</span><span class="mtk1">() </span><span class="mtk10 mtki">and</span><span class="mtk1"> model_args.</span><span class="mtk7">DEBUG</span><span class="mtk1"> </span><span class="mtk8">==</span><span class="mtk1"> </span><span class="mtk7">False</span><span class="mtk1"> </span><span class="mtk10 mtki">else</span><span class="mtk1"> </span><span class="mtk6">&#39;cpu&#39;</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk9">!</span><span class="mtk1">nvidia</span><span class="mtk8">-</span><span class="mtk1">smi</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="35"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">cuda:0</span></span>
<span class="grvsc-line"><span class="grvsc-source">Tue Nov  2 07:16:46 2021</span></span>
<span class="grvsc-line"><span class="grvsc-source">+-----------------------------------------------------------------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source">| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|-------------------------------+----------------------+----------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span></span>
<span class="grvsc-line"><span class="grvsc-source">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|                               |                      |               MIG M. |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|===============================+======================+======================|</span></span>
<span class="grvsc-line"><span class="grvsc-source">|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                  Off |</span></span>
<span class="grvsc-line"><span class="grvsc-source">| N/A   34C    P0    36W / 250W |      4MiB / 32510MiB |      0%      Default |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|                               |                      |                  N/A |</span></span>
<span class="grvsc-line"><span class="grvsc-source">+-------------------------------+----------------------+----------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">+-----------------------------------------------------------------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source">| Processes:                                                                  |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|        ID   ID                                                   Usage      |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|=============================================================================|</span></span>
<span class="grvsc-line"><span class="grvsc-source">|  No running processes found                                                 |</span></span>
<span class="grvsc-line"><span class="grvsc-source">+-----------------------------------------------------------------------------+</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="36"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> transformers </span><span class="mtk10 mtki">import</span><span class="mtk1"> AutoModelForQuestionAnswering, AutoConfig</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">&quot;&quot;&quot; default model, but not using this one &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">if</span><span class="mtk1"> model_args.</span><span class="mtk7">DEBUG</span><span class="mtk1"> </span><span class="mtk8">==</span><span class="mtk1"> </span><span class="mtk7">True</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    model_config </span><span class="mtk8">=</span><span class="mtk1"> AutoConfig.</span><span class="mtk3">from_pretrained</span><span class="mtk1">(model_args.model_name_or_path)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    model </span><span class="mtk8">=</span><span class="mtk1"> AutoModelForQuestionAnswering.</span><span class="mtk3">from_pretrained</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        model_args.model_name_or_path,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">config</span><span class="mtk8">=</span><span class="mtk1">model_config,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )</span></span></span></code></pre>
<p><img src="https://discuss.pytorch.org/uploads/default/original/2X/e/e7496a33d835f085d800ee17c0ade05895a89551.png" alt="img"></p>
<ul>
<li>t: length of passage (or input text)</li>
<li>depth: number of rnn layers</li>
</ul>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="37"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch.nn </span><span class="mtk10 mtki">as</span><span class="mtk1"> nn</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch.nn.functional </span><span class="mtk10 mtki">as</span><span class="mtk1"> F</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> transformers </span><span class="mtk10 mtki">import</span><span class="mtk1"> AutoModel, AutoConfig, AutoModelForQuestionAnswering</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> torch.cuda.amp </span><span class="mtk10 mtki">import</span><span class="mtk1"> autocast</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">&quot;&quot;&quot; Reference: https://github.com/snexus/nlp-question-answering-system/blob/main/model.py &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">class</span><span class="mtk1"> </span><span class="mtk11">QAModel</span><span class="mtk1">(</span><span class="mtk11">nn</span><span class="mtk1">.</span><span class="mtk11">Module</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk6">&quot;&quot;&quot; Custom Question Answering Model with Bidirectionaal LSTM head attached &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk8">__init__</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">, </span><span class="mtk7 mtki">MODEL_NAME</span><span class="mtk1">, </span><span class="mtk7 mtki">dropout_proba</span><span class="mtk1">=</span><span class="mtk7">0.1</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk8">super</span><span class="mtk1">().</span><span class="mtk8">__init__</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.model_config</span><span class="mtk8">=</span><span class="mtk1"> AutoConfig.</span><span class="mtk3">from_pretrained</span><span class="mtk1">(</span><span class="mtk7">MODEL_NAME</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.transformer </span><span class="mtk8">=</span><span class="mtk1"> AutoModel.</span><span class="mtk3">from_pretrained</span><span class="mtk1">(</span><span class="mtk7">MODEL_NAME</span><span class="mtk1">, </span><span class="mtk4 mtki">config</span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.model_config)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.embed_dim </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.model_config.hidden_size </span><span class="mtk5 mtki"># roberta hidden dim = 1024</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki">#self.device=&quot;cuda&quot; if torch.cuda.is_available else &quot;cpu&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># We replace the head with lstm layer</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.lstm</span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">LSTM</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">input_size</span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.embed_dim,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">hidden_size</span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.embed_dim,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">num_layers</span><span class="mtk8">=</span><span class="mtk1"> model_args.num_rnn_layers,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">dropout</span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0.2</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">batch_first</span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">True</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">bidirectional</span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">True</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.qa_head </span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">Linear</span><span class="mtk1">(</span><span class="mtk4 mtki">in_features</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.embed_dim</span><span class="mtk8">*</span><span class="mtk7">2</span><span class="mtk1">, </span><span class="mtk4 mtki">out_features</span><span class="mtk8">=</span><span class="mtk7">2</span><span class="mtk1">, </span><span class="mtk4 mtki">bias</span><span class="mtk8">=</span><span class="mtk7">True</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.dropout </span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">Dropout</span><span class="mtk1">(</span><span class="mtk4 mtki">p</span><span class="mtk8">=</span><span class="mtk1">dropout_proba)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">forward</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">, </span><span class="mtk7 mtki">input_ids</span><span class="mtk1">, </span><span class="mtk7 mtki">attention_mask</span><span class="mtk1">, </span><span class="mtk7 mtki">start_positions</span><span class="mtk1">, </span><span class="mtk7 mtki">end_positions</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        Forward step for the question-answering model</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        Parameters</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        ----------</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        input_enc - encoding dictionary from the tokenizer.</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        Returns</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        -------</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        start_logits - logit corresponding to the start position of the answer (batch_size, sentence_size, 1)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        start_positions - true start position (batch_size, 1) or None</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        end_logits - logit corresponding to the end position of the answer (batch_size, sentence_size, 1)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        end_positions - ture end position (batch_size, 1) or None</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        trans_out </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">transformer</span><span class="mtk1">(input_ids, </span><span class="mtk4 mtki">attention_mask</span><span class="mtk8">=</span><span class="mtk1">attention_mask)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        hidden_state </span><span class="mtk8">=</span><span class="mtk1"> trans_out.last_hidden_state  </span><span class="mtk5 mtki"># (batch_size, len_sentence, embed_dim)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        hidden_out, (last_hidden, last_cell) </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">lstm</span><span class="mtk1">(hidden_state)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># Pass through the linear layer, we need to learn it&#39;s parameters</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        final_output </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">qa_head</span><span class="mtk1">(hidden_out)  </span><span class="mtk5 mtki"># (batch_size, len_sentence, 2)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        start_logits, end_logits </span><span class="mtk8">=</span><span class="mtk1"> final_output.</span><span class="mtk3">split</span><span class="mtk1">(</span><span class="mtk7">1</span><span class="mtk1">, </span><span class="mtk4 mtki">dim</span><span class="mtk8">=-</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        start_logits </span><span class="mtk8">=</span><span class="mtk1"> start_logits.</span><span class="mtk3">squeeze</span><span class="mtk1">(</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">)  </span><span class="mtk5 mtki"># (bs, max_query_len)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        end_logits </span><span class="mtk8">=</span><span class="mtk1"> end_logits.</span><span class="mtk3">squeeze</span><span class="mtk1">(</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">return</span><span class="mtk1"> {</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk6">&quot;start_logits&quot;</span><span class="mtk1">: start_logits,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk6">&quot;start_positions&quot;</span><span class="mtk1">: start_positions,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk6">&quot;end_logits&quot;</span><span class="mtk1">: end_logits,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk6">&quot;end_positions&quot;</span><span class="mtk1">: end_positions</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            }</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">compute_loss</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">, </span><span class="mtk7 mtki">start_logits</span><span class="mtk1">, </span><span class="mtk7 mtki">start_positions</span><span class="mtk1">, </span><span class="mtk7 mtki">end_logits</span><span class="mtk1">, </span><span class="mtk7 mtki">end_positions</span><span class="mtk1">, </span><span class="mtk7 mtki">return_outputs</span><span class="mtk1">=</span><span class="mtk7">False</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(start_positions.</span><span class="mtk3">size</span><span class="mtk1">()) </span><span class="mtk8">&gt;</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            start_positions </span><span class="mtk8">=</span><span class="mtk1"> start_positions.</span><span class="mtk3">squeeze</span><span class="mtk1">(</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(end_positions.</span><span class="mtk3">size</span><span class="mtk1">()) </span><span class="mtk8">&gt;</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            end_positions </span><span class="mtk8">=</span><span class="mtk1"> end_positions.</span><span class="mtk3">squeeze</span><span class="mtk1">(</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        start_loss_fct, end_loss_fct </span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">CrossEntropyLoss</span><span class="mtk1">(), nn.</span><span class="mtk3">CrossEntropyLoss</span><span class="mtk1">() </span><span class="mtk5 mtki"># -&gt; so far the best performance</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># start_loss_fct, end_loss_fct = FocalLoss(gamma=model_args.gamma), FocalLoss(gamma=model_args.gamma)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># start_loss_fct, end_loss_fct = LabelSmoothCrossEntropyLoss(smoothing=model_args.smoothing), LabelSmoothCrossEntropyLoss(smoothing=model_args.smoothing)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        start_loss </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">start_loss_fct</span><span class="mtk1">(start_logits, start_positions)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        end_loss </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">end_loss_fct</span><span class="mtk1">(end_logits, end_positions)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        total_loss </span><span class="mtk8">=</span><span class="mtk1"> (start_loss </span><span class="mtk8">+</span><span class="mtk1"> end_loss) </span><span class="mtk8">/</span><span class="mtk1"> </span><span class="mtk7">2</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">return</span><span class="mtk1"> (total_loss, outputs) </span><span class="mtk10 mtki">if</span><span class="mtk1"> return_outputs </span><span class="mtk10 mtki">else</span><span class="mtk1"> total_loss</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">QAModel</span><span class="mtk1">(model_args.model_name_or_path)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="38"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: [&#39;lm_head.layer_norm.weight&#39;, &#39;lm_head.layer_norm.bias&#39;, &#39;lm_head.decoder.weight&#39;, &#39;lm_head.dense.weight&#39;, &#39;lm_head.bias&#39;, &#39;lm_head.decoder.bias&#39;, &#39;lm_head.dense.bias&#39;]</span></span>
<span class="grvsc-line"><span class="grvsc-source">- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).</span></span>
<span class="grvsc-line"><span class="grvsc-source">- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</span></span>
<span class="grvsc-line"><span class="grvsc-source">Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: [&#39;roberta.pooler.dense.weight&#39;, &#39;roberta.pooler.dense.bias&#39;]</span></span>
<span class="grvsc-line"><span class="grvsc-source">You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="39"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model.</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk9">!</span><span class="mtk1">nvidia</span><span class="mtk8">-</span><span class="mtk1">smi</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="40"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">Tue Nov  2 07:16:58 2021</span></span>
<span class="grvsc-line"><span class="grvsc-source">+-----------------------------------------------------------------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source">| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|-------------------------------+----------------------+----------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span></span>
<span class="grvsc-line"><span class="grvsc-source">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|                               |                      |               MIG M. |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|===============================+======================+======================|</span></span>
<span class="grvsc-line"><span class="grvsc-source">|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                  Off |</span></span>
<span class="grvsc-line"><span class="grvsc-source">| N/A   34C    P0    36W / 250W |   2931MiB / 32510MiB |      2%      Default |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|                               |                      |                  N/A |</span></span>
<span class="grvsc-line"><span class="grvsc-source">+-------------------------------+----------------------+----------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">+-----------------------------------------------------------------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source">| Processes:                                                                  |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|        ID   ID                                                   Usage      |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|=============================================================================|</span></span>
<span class="grvsc-line"><span class="grvsc-source">+-----------------------------------------------------------------------------+</span></span></code></pre>
<h2 id="define-optimizer-and-scheduler" style="position:relative;"><a href="#define-optimizer-and-scheduler" aria-label="define optimizer and scheduler permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Define Optimizer and Scheduler</h2>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="41"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> transformers </span><span class="mtk10 mtki">import</span><span class="mtk1"> AdamW</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># from adamp import AdamP</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">optimizer </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">AdamW</span><span class="mtk1">(model.</span><span class="mtk3">parameters</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                  </span><span class="mtk4 mtki">lr</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> model_args.learning_rate, </span><span class="mtk5 mtki"># args.learning_rate - default is 5e-5</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                  </span><span class="mtk4 mtki">eps</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">1e-8</span><span class="mtk1"> </span><span class="mtk5 mtki"># args.adam_epsilon  - default is 1e-8.</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                )</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="42"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> transformers </span><span class="mtk10 mtki">import</span><span class="mtk1"> get_linear_schedule_with_warmup</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> transformers </span><span class="mtk10 mtki">import</span><span class="mtk1"> get_cosine_schedule_with_warmup</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">epochs </span><span class="mtk8">=</span><span class="mtk1"> model_args.num_train_epochs</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">total_steps </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(train_dataloader) </span><span class="mtk8">*</span><span class="mtk1"> epochs</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">scheduler </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">get_linear_schedule_with_warmup</span><span class="mtk1">(optimizer,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                                            </span><span class="mtk4 mtki">num_warmup_steps</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                                            </span><span class="mtk4 mtki">num_training_steps</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> total_steps)</span></span></span></code></pre>
<h2 id="training" style="position:relative;"><a href="#training" aria-label="training permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Training</h2>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="43"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">class</span><span class="mtk1"> </span><span class="mtk11">Metrics</span><span class="mtk1">(</span><span class="mtk8">object</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk8">__init__</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">reset</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">reset</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.val </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.avg </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.sum </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.count </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">update</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">, </span><span class="mtk7 mtki">val</span><span class="mtk1">, </span><span class="mtk7 mtki">n</span><span class="mtk1">=</span><span class="mtk7">1</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.val </span><span class="mtk8">=</span><span class="mtk1"> val</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.sum </span><span class="mtk8">+=</span><span class="mtk1"> val </span><span class="mtk8">*</span><span class="mtk1"> n</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.count </span><span class="mtk8">+=</span><span class="mtk1"> n</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.avg </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.sum </span><span class="mtk8">/</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.count</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="44"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">name_of_experiment</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="45"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">&#39;lstm-trainer-AdamW-CE-num_rnn_layers-2-no-clip&#39;</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="46"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> time</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> wandb</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> random</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> numpy </span><span class="mtk10 mtki">as</span><span class="mtk1"> np</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> tqdm.auto </span><span class="mtk10 mtki">import</span><span class="mtk1"> tqdm</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> wandb</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">seed_val </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">42</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">random.</span><span class="mtk3">seed</span><span class="mtk1">(seed_val)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">np.random.</span><span class="mtk3">seed</span><span class="mtk1">(seed_val)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">torch.</span><span class="mtk3">manual_seed</span><span class="mtk1">(seed_val)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">torch.cuda.</span><span class="mtk3">manual_seed_all</span><span class="mtk1">(seed_val)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">training_stats </span><span class="mtk8">=</span><span class="mtk1"> []</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># https://wandb.ai/happyface-boostcamp/KLUE-QA</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(name_of_experiment)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">wandb.</span><span class="mtk3">init</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk4 mtki">project</span><span class="mtk8">=</span><span class="mtk6">&#39;KLUE-QA&#39;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk4 mtki">entity</span><span class="mtk8">=</span><span class="mtk6">&#39;happyface-boostcamp&#39;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk4 mtki">name</span><span class="mtk8">=</span><span class="mtk1">name_of_experiment,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk4 mtki">config</span><span class="mtk8">=</span><span class="mtk1">model_args</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">fold_num </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">best_acc </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0.0</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Initialize using Metrics</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_acc, train_loss </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">Metrics</span><span class="mtk1">(), </span><span class="mtk3">Metrics</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">dev_acc, dev_loss </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">Metrics</span><span class="mtk1">(), </span><span class="mtk3">Metrics</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">dev_start_acc, dev_end_acc </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">Metrics</span><span class="mtk1">(), </span><span class="mtk3">Metrics</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">for</span><span class="mtk1"> epoch_i </span><span class="mtk10">in</span><span class="mtk1"> </span><span class="mtk8">range</span><span class="mtk1">(</span><span class="mtk7">0</span><span class="mtk1">, epochs):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&quot;&quot;</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;======== Epoch </span><span class="mtk7">{</span><span class="mtk10">:</span><span class="mtk7">}</span><span class="mtk6"> / </span><span class="mtk7">{</span><span class="mtk10">:</span><span class="mtk7">}</span><span class="mtk6"> ========&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(epoch_i </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">, epochs))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;Training </span><span class="mtk7">{</span><span class="mtk10">:,</span><span class="mtk7">}</span><span class="mtk6"> batches...&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(</span><span class="mtk8">len</span><span class="mtk1">(train_dataloader)))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># change the model to train mode</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    model.</span><span class="mtk3">train</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    num_batches </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(train_dataloader)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># For each batch of training data...</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">for</span><span class="mtk1"> step, batch </span><span class="mtk10">in</span><span class="mtk1"> </span><span class="mtk8">enumerate</span><span class="mtk1">(</span><span class="mtk3">tqdm</span><span class="mtk1">(train_dataloader)):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># get info from batch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        b_input_ids </span><span class="mtk8">=</span><span class="mtk1"> batch[</span><span class="mtk7">0</span><span class="mtk1">].</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        b_input_mask </span><span class="mtk8">=</span><span class="mtk1"> batch[</span><span class="mtk7">1</span><span class="mtk1">].</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        b_start_pos </span><span class="mtk8">=</span><span class="mtk1"> batch[</span><span class="mtk7">2</span><span class="mtk1">].</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        b_end_pos </span><span class="mtk8">=</span><span class="mtk1"> batch[</span><span class="mtk7">3</span><span class="mtk1">].</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># get outputs from the model</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        model.</span><span class="mtk3">zero_grad</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        outputs </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">model</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            b_input_ids,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">attention_mask</span><span class="mtk8">=</span><span class="mtk1">b_input_mask,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">start_positions</span><span class="mtk8">=</span><span class="mtk1">b_start_pos,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">end_positions</span><span class="mtk8">=</span><span class="mtk1">b_end_pos,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># get logits(probability) and loss</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        start_logits </span><span class="mtk8">=</span><span class="mtk1"> outputs[</span><span class="mtk6">&#39;start_logits&#39;</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        end_logits </span><span class="mtk8">=</span><span class="mtk1"> outputs[</span><span class="mtk6">&#39;end_logits&#39;</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        loss </span><span class="mtk8">=</span><span class="mtk1"> model.</span><span class="mtk3">compute_loss</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">start_logits</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> start_logits,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">start_positions</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> outputs[</span><span class="mtk6">&#39;start_positions&#39;</span><span class="mtk1">],</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">end_logits</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> end_logits,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk4 mtki">end_positions</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> outputs[</span><span class="mtk6">&#39;end_positions&#39;</span><span class="mtk1">],</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># record train loss</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        train_loss.</span><span class="mtk3">update</span><span class="mtk1">(loss.</span><span class="mtk3">item</span><span class="mtk1">(), </span><span class="mtk8">len</span><span class="mtk1">(b_input_ids))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># backward propagation &amp; optimizer stepping</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        loss.</span><span class="mtk3">backward</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        optimizer.</span><span class="mtk3">step</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        scheduler.</span><span class="mtk3">step</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># EVALUATE every 100 steps</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> step </span><span class="mtk8">!=</span><span class="mtk1"> </span><span class="mtk7">0</span><span class="mtk1"> </span><span class="mtk10">and</span><span class="mtk1"> step </span><span class="mtk8">%</span><span class="mtk1"> </span><span class="mtk7">100</span><span class="mtk1"> </span><span class="mtk8">==</span><span class="mtk1"> </span><span class="mtk7">0</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;Epoch: </span><span class="mtk7">{}</span><span class="mtk6">/</span><span class="mtk7">{}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(epoch_i</span><span class="mtk8">+</span><span class="mtk7">1</span><span class="mtk1">, model_args.num_train_epochs), </span><span class="mtk6">&#39;Step: </span><span class="mtk7">{}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(step), </span><span class="mtk6">&#39;Train Loss: </span><span class="mtk7">{</span><span class="mtk10">:.4f</span><span class="mtk7">}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(train_loss.avg))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&quot;Running Validation...&quot;</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk5 mtki"># initialize prediction and labels for future accuracy calculation</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            pred_start, pred_end, true_start, true_end </span><span class="mtk8">=</span><span class="mtk1"> [], [], [], []</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk5 mtki"># Evaluate data for one epoch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk10 mtki">for</span><span class="mtk1"> batch </span><span class="mtk10">in</span><span class="mtk1"> </span><span class="mtk3">tqdm</span><span class="mtk1">(valid_dataloader):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk5 mtki"># get info from batch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                b_input_ids </span><span class="mtk8">=</span><span class="mtk1"> batch[</span><span class="mtk7">0</span><span class="mtk1">].</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                b_input_mask </span><span class="mtk8">=</span><span class="mtk1"> batch[</span><span class="mtk7">1</span><span class="mtk1">].</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                b_start_pos </span><span class="mtk8">=</span><span class="mtk1"> batch[</span><span class="mtk7">2</span><span class="mtk1">].</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                b_end_pos </span><span class="mtk8">=</span><span class="mtk1"> batch[</span><span class="mtk7">3</span><span class="mtk1">].</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk5 mtki"># Evaluate and get outputs</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk5 mtki"># model.eval() # lstm does not accept model.eval()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk10 mtki">with</span><span class="mtk1"> torch.</span><span class="mtk3">no_grad</span><span class="mtk1">():</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                    outputs </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">model</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        b_input_ids,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        </span><span class="mtk5 mtki"># token_type_ids=b_seg_ids,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        </span><span class="mtk4 mtki">attention_mask</span><span class="mtk8">=</span><span class="mtk1">b_input_mask,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        </span><span class="mtk4 mtki">start_positions</span><span class="mtk8">=</span><span class="mtk1">b_start_pos,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        </span><span class="mtk4 mtki">end_positions</span><span class="mtk8">=</span><span class="mtk1">b_end_pos,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                    )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk5 mtki"># get logits(probability) and loss</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                start_logits </span><span class="mtk8">=</span><span class="mtk1"> outputs[</span><span class="mtk6">&#39;start_logits&#39;</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                end_logits </span><span class="mtk8">=</span><span class="mtk1"> outputs[</span><span class="mtk6">&#39;end_logits&#39;</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                loss </span><span class="mtk8">=</span><span class="mtk1"> model.</span><span class="mtk3">compute_loss</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                    </span><span class="mtk4 mtki">start_logits</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> start_logits,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                    </span><span class="mtk4 mtki">start_positions</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> outputs[</span><span class="mtk6">&#39;start_positions&#39;</span><span class="mtk1">],</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                    </span><span class="mtk4 mtki">end_logits</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> end_logits,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                    </span><span class="mtk4 mtki">end_positions</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> outputs[</span><span class="mtk6">&#39;end_positions&#39;</span><span class="mtk1">],</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk5 mtki"># record evaluation loss</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                dev_loss.</span><span class="mtk3">update</span><span class="mtk1">(loss.</span><span class="mtk3">item</span><span class="mtk1">(), </span><span class="mtk8">len</span><span class="mtk1">(b_input_ids))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk5 mtki"># get logits and predictions for evaluation accuracy</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                start_logits </span><span class="mtk8">=</span><span class="mtk1"> start_logits.</span><span class="mtk3">detach</span><span class="mtk1">().</span><span class="mtk3">cpu</span><span class="mtk1">().</span><span class="mtk3">numpy</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                end_logits </span><span class="mtk8">=</span><span class="mtk1"> end_logits.</span><span class="mtk3">detach</span><span class="mtk1">().</span><span class="mtk3">cpu</span><span class="mtk1">().</span><span class="mtk3">numpy</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                b_start_pos </span><span class="mtk8">=</span><span class="mtk1"> b_start_pos.</span><span class="mtk3">to</span><span class="mtk1">(</span><span class="mtk6">&#39;cpu&#39;</span><span class="mtk1">).</span><span class="mtk3">numpy</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                b_end_pos </span><span class="mtk8">=</span><span class="mtk1"> b_end_pos.</span><span class="mtk3">to</span><span class="mtk1">(</span><span class="mtk6">&#39;cpu&#39;</span><span class="mtk1">).</span><span class="mtk3">numpy</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                answer_start </span><span class="mtk8">=</span><span class="mtk1"> np.</span><span class="mtk3">argmax</span><span class="mtk1">(start_logits, </span><span class="mtk4 mtki">axis</span><span class="mtk8">=</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                answer_end </span><span class="mtk8">=</span><span class="mtk1"> np.</span><span class="mtk3">argmax</span><span class="mtk1">(end_logits, </span><span class="mtk4 mtki">axis</span><span class="mtk8">=</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk5 mtki"># append the prediction and ground truth to the list for comparison</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                pred_start.</span><span class="mtk3">append</span><span class="mtk1">(answer_start)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                pred_end.</span><span class="mtk3">append</span><span class="mtk1">(answer_end)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                true_start.</span><span class="mtk3">append</span><span class="mtk1">(b_start_pos)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                true_end.</span><span class="mtk3">append</span><span class="mtk1">(b_end_pos)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk5 mtki"># compare start for accuracy calculation</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            pred_start </span><span class="mtk8">=</span><span class="mtk1"> np.</span><span class="mtk3">concatenate</span><span class="mtk1">(pred_start, </span><span class="mtk4 mtki">axis</span><span class="mtk8">=</span><span class="mtk7">0</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            true_start </span><span class="mtk8">=</span><span class="mtk1"> np.</span><span class="mtk3">concatenate</span><span class="mtk1">(true_start, </span><span class="mtk4 mtki">axis</span><span class="mtk8">=</span><span class="mtk7">0</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            num_start_correct </span><span class="mtk8">=</span><span class="mtk1"> np.</span><span class="mtk3">sum</span><span class="mtk1">(pred_start </span><span class="mtk8">==</span><span class="mtk1"> true_start)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            dev_start_acc.</span><span class="mtk3">update</span><span class="mtk1">((pred_start </span><span class="mtk8">==</span><span class="mtk1"> true_start).</span><span class="mtk3">mean</span><span class="mtk1">(), </span><span class="mtk8">len</span><span class="mtk1">(true_start))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk5 mtki"># compare end for accuracy calculation</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            pred_end </span><span class="mtk8">=</span><span class="mtk1"> np.</span><span class="mtk3">concatenate</span><span class="mtk1">(pred_end, </span><span class="mtk4 mtki">axis</span><span class="mtk8">=</span><span class="mtk7">0</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            true_end </span><span class="mtk8">=</span><span class="mtk1"> np.</span><span class="mtk3">concatenate</span><span class="mtk1">(true_end, </span><span class="mtk4 mtki">axis</span><span class="mtk8">=</span><span class="mtk7">0</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            num_end_correct </span><span class="mtk8">=</span><span class="mtk1"> np.</span><span class="mtk3">sum</span><span class="mtk1">(pred_end </span><span class="mtk8">==</span><span class="mtk1"> true_end)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            dev_end_acc.</span><span class="mtk3">update</span><span class="mtk1">((pred_end </span><span class="mtk8">==</span><span class="mtk1"> true_end).</span><span class="mtk3">mean</span><span class="mtk1">(), </span><span class="mtk8">len</span><span class="mtk1">(true_end))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk5 mtki"># compare both start and end for EM accuracy calculation</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            total_correct </span><span class="mtk8">=</span><span class="mtk1"> num_start_correct </span><span class="mtk8">+</span><span class="mtk1"> num_end_correct</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            total_indeces </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(true_start) </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(true_end)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk5 mtki"># get both cases where pred_start == true_start and pred_end == true_end</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            both_correct </span><span class="mtk8">=</span><span class="mtk1"> np.</span><span class="mtk3">mean</span><span class="mtk1">(np.</span><span class="mtk3">logical_and</span><span class="mtk1">(pred_start </span><span class="mtk8">==</span><span class="mtk1"> true_start, pred_end </span><span class="mtk8">==</span><span class="mtk1"> true_end))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            dev_acc.</span><span class="mtk3">update</span><span class="mtk1">(both_correct, </span><span class="mtk8">len</span><span class="mtk1">(b_input_ids))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk5 mtki"># Report the final accuracy for this validation run.</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;Epoch: </span><span class="mtk7">{}</span><span class="mtk6">/</span><span class="mtk7">{}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(epoch_i</span><span class="mtk8">+</span><span class="mtk7">1</span><span class="mtk1">, epochs), </span><span class="mtk6">&#39;Step: </span><span class="mtk7">{}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(step), </span><span class="mtk6">&#39;Dev Loss: </span><span class="mtk7">{</span><span class="mtk10">:.4f</span><span class="mtk7">}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(dev_loss.avg), </span><span class="mtk6">&#39;Dev Acc: </span><span class="mtk7">{</span><span class="mtk10">:.4f</span><span class="mtk7">}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(dev_acc.avg))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk5 mtki"># log on wandb</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            wandb.</span><span class="mtk3">log</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                    {</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        </span><span class="mtk6">&#39;train/loss&#39;</span><span class="mtk1">: train_loss.avg,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        </span><span class="mtk6">&#39;train/learning_rate&#39;</span><span class="mtk1">:optimizer.param_groups[</span><span class="mtk7">0</span><span class="mtk1">][</span><span class="mtk6">&#39;lr&#39;</span><span class="mtk1">],</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        </span><span class="mtk6">&#39;eval/loss&#39;</span><span class="mtk1">: dev_loss.avg,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        </span><span class="mtk6">&#39;eval/accuracy&#39;</span><span class="mtk1">:dev_acc.avg,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        </span><span class="mtk6">&#39;eval/start_accuracy&#39;</span><span class="mtk1">:dev_start_acc.avg,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        </span><span class="mtk6">&#39;eval/end_accuracy&#39;</span><span class="mtk1">:dev_end_acc.avg,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                        }</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                    )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk5 mtki"># save the best model based on EM accuracy</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk10 mtki">if</span><span class="mtk1"> best_acc </span><span class="mtk8">&lt;</span><span class="mtk1"> dev_acc.avg:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                best_acc </span><span class="mtk8">=</span><span class="mtk1"> dev_acc.avg</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                torch.</span><span class="mtk3">save</span><span class="mtk1">(model.</span><span class="mtk3">state_dict</span><span class="mtk1">(), </span><span class="mtk6">&#39;./results/</span><span class="mtk7">{}</span><span class="mtk6">-fold-</span><span class="mtk7">{}</span><span class="mtk6">-best-acc-model.pt&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(fold_num</span><span class="mtk8">+</span><span class="mtk7">1</span><span class="mtk1">, model_args.num_folds))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;Saved model with highest EM accuracy: </span><span class="mtk7">{</span><span class="mtk10">:.4f</span><span class="mtk7">}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(best_acc))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                wandb.</span><span class="mtk3">log</span><span class="mtk1">({</span><span class="mtk6">&#39;best_acc&#39;</span><span class="mtk1">:best_acc})</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk5 mtki"># reset metrics</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            train_loss.</span><span class="mtk3">reset</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            dev_loss.</span><span class="mtk3">reset</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            dev_acc.</span><span class="mtk3">reset</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            dev_start_acc.</span><span class="mtk3">reset</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            dev_end_acc.</span><span class="mtk3">reset</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&quot;Training complete!&quot;</span><span class="mtk1">)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="47"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">lstm-trainer-AdamW-CE-num_rnn_layers-2-no-clip</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">[34m[1mwandb[0m: Currently logged in as: [33msnoop2head[0m (use `wandb login --relogin` to force relogin)</span></span>
<span class="grvsc-line"><span class="grvsc-source">[34m[1mwandb[0m: wandb version 0.12.6 is available!  To upgrade, please run:</span></span>
<span class="grvsc-line"><span class="grvsc-source">[34m[1mwandb[0m:  $ pip install wandb --upgrade</span></span></code></pre>
<p>Syncing run <strong><a href="https://wandb.ai/happyface-boostcamp/KLUE-QA/runs/v9a69h0d" target="_blank">lstm-trainer-AdamW-CE-num<em>rnn</em>layers-2-no-clip</a></strong> to <a href="https://wandb.ai/happyface-boostcamp/KLUE-QA" target="_blank">Weights &#x26; Biases</a> (<a href="https://docs.wandb.com/integrations/jupyter.html" target="_blank">docs</a>).<br/></p>
<p> ======== Epoch 1 / 3 ========
​ Training 371 batches...</p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="48"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=371.0), HTML(value=&#39;&#39;)))</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">Epoch: 1/3 Step: 100 Train Loss: 3.1070</span></span>
<span class="grvsc-line"><span class="grvsc-source">Running Validation...</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value=&#39;&#39;)))</span></span></code></pre>
<p> Epoch: 1/3 Step: 100 Dev Loss: 1.6518 Dev Acc: 0.4455
​ Saved model with highest EM accuracy: 0.4455
​ Epoch: 1/3 Step: 200 Train Loss: 0.8847
​ Running Validation...</p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="49"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value=&#39;&#39;)))</span></span></code></pre>
<p> Epoch: 1/3 Step: 200 Dev Loss: 0.8757 Dev Acc: 0.7364
​ Saved model with highest EM accuracy: 0.7364
​ Epoch: 1/3 Step: 300 Train Loss: 0.6086
​ Running Validation...</p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="50"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value=&#39;&#39;)))</span></span></code></pre>
<p> Epoch: 1/3 Step: 300 Dev Loss: 0.6843 Dev Acc: 0.7591
​ Saved model with highest EM accuracy: 0.7591</p>
<p> ======== Epoch 2 / 3 ========
​ Training 371 batches...</p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="51"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=371.0), HTML(value=&#39;&#39;)))</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">Epoch: 2/3 Step: 100 Train Loss: 0.3378</span></span>
<span class="grvsc-line"><span class="grvsc-source">Running Validation...</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value=&#39;&#39;)))</span></span></code></pre>
<p> Epoch: 2/3 Step: 100 Dev Loss: 0.5934 Dev Acc: 0.7864
​ Saved model with highest EM accuracy: 0.7864
​ Epoch: 2/3 Step: 200 Train Loss: 0.2142
​ Running Validation...</p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="52"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value=&#39;&#39;)))</span></span></code></pre>
<p> Epoch: 2/3 Step: 200 Dev Loss: 0.6438 Dev Acc: 0.7773
​ Epoch: 2/3 Step: 300 Train Loss: 0.2250
​ Running Validation...</p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="53"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value=&#39;&#39;)))</span></span></code></pre>
<p> Epoch: 2/3 Step: 300 Dev Loss: 0.5673 Dev Acc: 0.7909
​ Saved model with highest EM accuracy: 0.7909</p>
<p> ======== Epoch 3 / 3 ========
​ Training 371 batches...</p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="54"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=371.0), HTML(value=&#39;&#39;)))</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">Epoch: 3/3 Step: 100 Train Loss: 0.1450</span></span>
<span class="grvsc-line"><span class="grvsc-source">Running Validation...</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value=&#39;&#39;)))</span></span></code></pre>
<p> Epoch: 3/3 Step: 100 Dev Loss: 0.4982 Dev Acc: 0.8409
​ Saved model with highest EM accuracy: 0.8409
​ Epoch: 3/3 Step: 200 Train Loss: 0.0798
​ Running Validation...</p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="55"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value=&#39;&#39;)))</span></span></code></pre>
<p> Epoch: 3/3 Step: 200 Dev Loss: 0.5151 Dev Acc: 0.8227
​ Epoch: 3/3 Step: 300 Train Loss: 0.0685
​ Running Validation...</p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="56"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value=&#39;&#39;)))</span></span></code></pre>
<p> Epoch: 3/3 Step: 300 Dev Loss: 0.5888 Dev Acc: 0.7955</p>
<p> Training complete!</p>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="57"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk9">!</span><span class="mtk1">nvidia</span><span class="mtk8">-</span><span class="mtk1">smi</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="58"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">Tue Nov  2 07:44:26 2021</span></span>
<span class="grvsc-line"><span class="grvsc-source">+-----------------------------------------------------------------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source">| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|-------------------------------+----------------------+----------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span></span>
<span class="grvsc-line"><span class="grvsc-source">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|                               |                      |               MIG M. |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|===============================+======================+======================|</span></span>
<span class="grvsc-line"><span class="grvsc-source">|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                  Off |</span></span>
<span class="grvsc-line"><span class="grvsc-source">| N/A   57C    P0    50W / 250W |  29163MiB / 32510MiB |      0%      Default |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|                               |                      |                  N/A |</span></span>
<span class="grvsc-line"><span class="grvsc-source">+-------------------------------+----------------------+----------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">+-----------------------------------------------------------------------------+</span></span>
<span class="grvsc-line"><span class="grvsc-source">| Processes:                                                                  |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|        ID   ID                                                   Usage      |</span></span>
<span class="grvsc-line"><span class="grvsc-source">|=============================================================================|</span></span>
<span class="grvsc-line"><span class="grvsc-source">+-----------------------------------------------------------------------------+</span></span></code></pre>
<pre><code class="language-python"></code></pre>
<style class="grvsc-styles">
  .grvsc-container {
    overflow: auto;
    position: relative;
    -webkit-overflow-scrolling: touch;
    padding-top: 1rem;
    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));
    padding-bottom: 1rem;
    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));
    border-radius: 8px;
    border-radius: var(--grvsc-border-radius, 8px);
    font-feature-settings: normal;
    line-height: 1.4;
  }
  
  .grvsc-code {
    display: table;
  }
  
  .grvsc-line {
    display: table-row;
    box-sizing: border-box;
    width: 100%;
    position: relative;
  }
  
  .grvsc-line > * {
    position: relative;
  }
  
  .grvsc-gutter-pad {
    display: table-cell;
    padding-left: 0.75rem;
    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);
  }
  
  .grvsc-gutter {
    display: table-cell;
    -webkit-user-select: none;
    -moz-user-select: none;
    user-select: none;
  }
  
  .grvsc-gutter::before {
    content: attr(data-content);
  }
  
  .grvsc-source {
    display: table-cell;
    padding-left: 1.5rem;
    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));
    padding-right: 1.5rem;
    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));
  }
  
  .grvsc-source:empty::after {
    content: ' ';
    -webkit-user-select: none;
    -moz-user-select: none;
    user-select: none;
  }
  
  .grvsc-gutter + .grvsc-source {
    padding-left: 0.75rem;
    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);
  }
  
  /* Line transformer styles */
  
  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {
    content: ' ';
    position: absolute;
    width: 100%;
  }
  
  .grvsc-line-diff-add::before {
    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));
  }
  
  .grvsc-line-diff-del::before {
    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));
  }
  
  .grvsc-line-number {
    padding: 0 2px;
    text-align: right;
    opacity: 0.7;
  }
  
  .one-dark-pro {
    background-color: #282c34;
    color: #abb2bf;
  }
  .one-dark-pro .mtki { font-style: italic; }
  .one-dark-pro .mtk10 { color: #C678DD; }
  .one-dark-pro .mtk1 { color: #ABB2BF; }
  .one-dark-pro .mtk6 { color: #98C379; }
  .one-dark-pro .mtk8 { color: #56B6C2; }
  .one-dark-pro .mtk11 { color: #E5C07B; }
  .one-dark-pro .mtk5 { color: #7F848E; }
  .one-dark-pro .mtk7 { color: #D19A66; }
  .one-dark-pro .mtk3 { color: #61AFEF; }
  .one-dark-pro .mtk4 { color: #E06C75; }
  .one-dark-pro .mtk9 { color: #FFFFFF; }
  .one-dark-pro .grvsc-line-highlighted::before {
    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));
    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));
  }
</style></div></div></div></div><div class="css-1bdwg0l eyldt480"><div><style data-emotion-css="17t5ffy">.css-17t5ffy{margin-top:1rem;margin-bottom:1rem;}</style><div class="css-17t5ffy"><div class="css-1l4w6pd"><div class="css-yapsbb"></div></div></div><style data-emotion-css="i1cgbm">.css-i1cgbm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;margin-top:1rem;padding-left:0.5rem;padding-right:0.5rem;}</style><div class="css-i1cgbm"><style data-emotion-css="9nr5sz">.css-9nr5sz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;margin-left:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#1CA1F2;}</style><button class="css-9nr5sz"><style data-emotion-css="u7tj59">.css-u7tj59{fill:currentColor;margin-top:auto;margin-bottom:auto;margin-right:0.25rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-u7tj59" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>Share with <!-- -->Twitter</button><style data-emotion-css="rk0yc0">.css-rk0yc0{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;margin-left:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#6E7783;}</style><button class="css-rk0yc0"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-u7tj59" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg>Share with <!-- -->URL</button></div></div></div></div></div><div class="css-1bdwg0l eyldt480"><style data-emotion-css="17t1oy1">.css-17t1oy1{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap-reverse;-ms-flex-wrap:wrap-reverse;flex-wrap:wrap-reverse;margin-left:0.5rem;margin-right:0.5rem;margin-top:1rem;}@media (min-width:768px){.css-17t1oy1{-webkit-flex-wrap:nowrap;-ms-flex-wrap:nowrap;flex-wrap:nowrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}}</style><div class="css-17t1oy1 e816y8n0"><style data-emotion-css="1pwr1ry">.css-1pwr1ry{width:100%;margin:0.5rem;}@media (min-width:768px){.css-1pwr1ry{width:50%;margin:1rem;}}</style><div class="css-1pwr1ry e816y8n1"><style data-emotion-css="vl2eok">.css-vl2eok{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);text-align:left;width:100%;height:100%;padding:0.5rem;background-color:#eee;border-radius:0.25rem;border-left-width:4px;border-color:#86a8e7;}.css-vl2eok:hover{background-color:#ddd;}</style><a rel="prev" class="css-vl2eok" href="/Engineering/Dacon-Result/"><style data-emotion-css="19o7xeo">.css-19o7xeo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;margin-right:1rem;margin-left:0.5rem;height:100%;}</style><div class="css-19o7xeo"><style data-emotion-css="11za1ik">.css-11za1ik{width:2rem;height:2rem;margin-top:auto;margin-bottom:auto;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-11za1ik" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M872 474H286.9l350.2-304c5.6-4.9 2.2-14-5.2-14h-88.5c-3.9 0-7.6 1.4-10.5 3.9L155 487.8a31.96 31.96 0 0 0 0 48.3L535.1 866c1.5 1.3 3.3 2 5.2 2h91.5c7.4 0 10.8-9.2 5.2-14L286.9 550H872c4.4 0 8-3.6 8-8v-60c0-4.4-3.6-8-8-8z"></path></svg></div><style data-emotion-css="v38or">.css-v38or{display:inline-block;margin-top:0.5rem;margin-bottom:0.5rem;}</style><div class="css-v38or"><style data-emotion-css="2m7hin">.css-2m7hin{color:#3737B9;}</style><p class="css-2m7hin">Previous Post</p><p>Assessment on the Dacon’s Stock Price Prediction Competition</p></div></a></div><div class="css-1pwr1ry e816y8n1"><style data-emotion-css="xhvfnc">.css-xhvfnc{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);text-align:right;width:100%;height:100%;padding:0.5rem;background-color:#eee;border-radius:0.25rem;border-right-width:4px;border-color:#86a8e7;}.css-xhvfnc:hover{background-color:#ddd;}</style><a rel="next" class="css-xhvfnc" href="/Researching/Python-language-structure/"><div class="css-v38or"><p class="css-2m7hin">Next Post</p><p>Python Language Structure</p></div><div class="css-19o7xeo"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-11za1ik" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M869 487.8L491.2 159.9c-2.9-2.5-6.6-3.9-10.5-3.9h-88.5c-7.4 0-10.8 9.2-5.2 14l350.2 304H152c-4.4 0-8 3.6-8 8v60c0 4.4 3.6 8 8 8h585.1L386.9 854c-5.6 4.9-2.2 14 5.2 14h91.5c1.9 0 3.8-.7 5.2-2L869 536.2a32.07 32.07 0 0 0 0-48.4z"></path></svg></div></a></div></div><style data-emotion-css="14yohw7">.css-14yohw7{width:100%;max-width:768px;padding-left:1rem;padding-right:1rem;margin-left:auto;margin-right:auto;padding-top:2rem;margin-top:0.5rem;margin-bottom:1rem;}@media (min-width:768px){.css-14yohw7{padding-left:0;padding-right:0;padding-top:3rem;}}</style><div class="css-14yohw7 e16bs3iv0"><style data-emotion-css="180ky7f">.css-180ky7f{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:0.5rem;padding-right:0.5rem;}@media (min-width:768px){.css-180ky7f{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}</style><div class="css-180ky7f e16bs3iv1"><style data-emotion-css="p5b1u1">.css-p5b1u1{border-radius:9999px;border-width:1px;--border-opacity:1;border-color:rgba(214,188,250,var(--border-opacity));margin-right:2rem;margin-bottom:0.5rem;}@media (min-width:768px){.css-p5b1u1{margin-bottom:1rem;}}</style><div class="css-p5b1u1 gatsby-image-wrapper" style="position:relative;overflow:hidden;display:inline-block;width:128px;height:128px"><img aria-hidden="true" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAQBBf/EABYBAQEBAAAAAAAAAAAAAAAAAAECA//aAAwDAQACEAMQAAABynZIqtSk4c5qdwD/AP/EABgQAAMBAQAAAAAAAAAAAAAAAAABAgMR/9oACAEBAAEFApTIkuNHXZgjWK2bZvTM6b1P/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAEQEf/aAAgBAwEBPwFiK//EABURAQEAAAAAAAAAAAAAAAAAAAEg/9oACAECAQE/ASP/xAAdEAACAQQDAAAAAAAAAAAAAAAAASECEBFRIjGB/9oACAEBAAY/AvCZ2QoMsw5TOJ2Up7t//8QAHRAAAgICAwEAAAAAAAAAAAAAAAERIUFhMVFxkf/aAAgBAQABPyGQ1UIIVo1dtoaHoXgWF10MklGMEvhCEYta+DAJgvw//9oADAMBAAIAAwAAABBYODz/xAAYEQEBAQEBAAAAAAAAAAAAAAABABEhQf/aAAgBAwEBPxB279ksrt//xAAXEQEBAQEAAAAAAAAAAAAAAAABABAx/9oACAECAQE/EI9kM//EAB4QAQEAAgICAwAAAAAAAAAAAAERACFRYTFBoeHw/9oACAEBAAE/ENiSENW+VTiZpVWrCLvvKMeEnTGARaXZevjBBRTTtdPnjWuccCRSa1+JjqKA/TCoCwoW324ixDPbn//Z" alt="profileImg" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/584d7a912ca03da16698aea724815677/6dc0c/profile.jpg 1x,
/static/584d7a912ca03da16698aea724815677/cc017/profile.jpg 1.5x,
/static/584d7a912ca03da16698aea724815677/0c30b/profile.jpg 2x" /><img loading="lazy" width="128" height="128" srcset="/static/584d7a912ca03da16698aea724815677/6dc0c/profile.jpg 1x,
/static/584d7a912ca03da16698aea724815677/cc017/profile.jpg 1.5x,
/static/584d7a912ca03da16698aea724815677/0c30b/profile.jpg 2x" src="/static/584d7a912ca03da16698aea724815677/6dc0c/profile.jpg" alt="profileImg" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div><div><span>Written by </span><style data-emotion-css="1t4jyca">.css-1t4jyca{display:inline-block;font-size:1.25rem;font-weight:700;border-radius:9999px;margin-bottom:0.5rem;padding-left:0.75rem;padding-right:0.75rem;--bg-opacity:1;background-color:rgba(237,242,247,var(--bg-opacity));color:#3737B9;}</style><p class="css-1t4jyca"><a class="author-name-content" href="/about"><span>@<!-- -->Young Jin Ahn</span></a></p><style data-emotion-css="vg2p6i">.css-vg2p6i{font-size:0.875rem;font-weight:400;margin-bottom:0.5rem;}</style><div class="css-vg2p6i">break, compose, display</div></div></div><style data-emotion-css="1air669">.css-1air669{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-left:0.5rem;margin-right:0.5rem;}</style><div class="css-1air669"><div class="css-yapsbb"></div></div><style data-emotion-css="1baulvz">.css-1baulvz{display:inline-block;}</style><a title="github Link" href="https://github.com/snoop2head" class="css-1baulvz"><style data-emotion-css="vnd1fq">.css-vnd1fq{width:2rem;height:2rem;margin-top:1rem;margin-left:1rem;-webkit-transition:all 300ms cubic-bezier(0,0,0.2,1);transition:all 300ms cubic-bezier(0,0,0.2,1);color:#888;}.css-vnd1fq:hover{color:#000;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="css-vnd1fq" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="facebook Link" href="https://www.facebook.com/profile.php?id=100009133042568" class="css-1baulvz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-vnd1fq" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"></path></svg></a></div><style data-emotion-css="18jj1tc">.css-18jj1tc{margin-top:1.25rem;margin-left:0.5rem;margin-right:0.5rem;}</style><div class="css-18jj1tc"><div class="utterances"></div></div></div></div><style data-emotion-css="xgi74q">.css-xgi74q{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:fixed;bottom:0;right:0;padding-right:1.5rem;padding-bottom:1.5rem;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}</style><div class="css-xgi74q e8huvi00"><style data-emotion-css="1a68u">.css-1a68u{box-shadow:0 2px 2px 0 rgba(0,0,0,0.15);-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#636363;font-size:0.75rem;padding-left:0.5rem;padding-right:0.5rem;padding-top:0.5rem;padding-bottom:0.5rem;border-radius:9999px;--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;-webkit-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));-ms-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-content:flex-end;-ms-flex-line-pack:end;align-content:flex-end;z-index:100;}.css-1a68u:hover{background-color:#404040;color:#FFFFFF;}.css-1a68u:hover{--transform-scale-x:1.05;--transform-scale-y:1.05;}</style><button title="change to darkmode" class="css-1a68u"><style data-emotion-css="1alqh2e">.css-1alqh2e{fill:currentColor;--text-opacity:1;color:rgba(246,224,94,var(--text-opacity));width:1rem;height:1rem;margin-top:auto;margin-bottom:auto;margin-left:0;margin-right:0;}@media (min-width:768px){.css-1alqh2e{display:inline-block;margin-left:0.25rem;margin-right:0.25rem;}}</style><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="css-1alqh2e" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg><style data-emotion-css="flxr9x">.css-flxr9x{display:none;margin-right:0;}@media (min-width:768px){.css-flxr9x{display:inline-block;margin-right:0.25rem;}}</style><span class="css-flxr9x">Use Dark Mode</span></button><style data-emotion-css="15afv4q">.css-15afv4q{box-shadow:0 2px 2px 0 rgba(0,0,0,0.15);-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#636363;font-size:0.75rem;padding-left:0.5rem;padding-right:0.5rem;padding-top:0.5rem;padding-bottom:0.5rem;border-radius:9999px;--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;-webkit-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));-ms-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));cursor:pointer;margin-left:0.5rem;margin-top:auto;margin-bottom:auto;z-index:100;}.css-15afv4q:hover{background-color:#404040;color:#FFFFFF;}.css-15afv4q:hover{--transform-scale-x:1.05;--transform-scale-y:1.05;}</style><button title="top page" class="css-15afv4q"><style data-emotion-css="13htjwu">.css-13htjwu{width:1rem;height:1rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-13htjwu" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M868 545.5L536.1 163a31.96 31.96 0 0 0-48.3 0L156 545.5a7.97 7.97 0 0 0 6 13.2h81c4.6 0 9-2 12.1-5.5L474 300.9V864c0 4.4 3.6 8 8 8h60c4.4 0 8-3.6 8-8V300.9l218.9 252.3c3 3.5 7.4 5.5 12.1 5.5h81c6.8 0 10.5-8 6-13.2z"></path></svg></button></div><style data-emotion-css="1k8xcyw">.css-1k8xcyw{text-align:center;padding-top:2rem;padding-bottom:2rem;bottom:0;}</style><footer class="css-1k8xcyw"><style data-emotion-css="1xju3od">.css-1xju3od{font-size:0.75rem;font-weight:700;}</style><a href="https://github.com/snoop2head" class="css-1xju3od">©snoop2head</a></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-186254784-2', 'auto', {});
      
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/Engineering/Custom-MRC-Reader/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-efbe87ab08854460e1b4.js"],"app":["/app-6b37a0275bc86b56e034.js"],"component---src-pages-404-js":["/component---src-pages-404-js-23314e5a1122284127b1.js"],"component---src-pages-about-js":["/component---src-pages-about-js-78029fb8e6dade72d83f.js"],"component---src-pages-index-js":["/component---src-pages-index-js-81659046284b3feb90f5.js"],"component---src-pages-search-js":["/component---src-pages-search-js-6bfc09fa0dcf8ea3b63d.js"],"component---src-templates-blog-post-js":["/component---src-templates-blog-post-js-5f317a7779dd1baa19f9.js"],"component---src-templates-category-js":["/component---src-templates-category-js-5fbfac713624a9c1ac35.js"]};/*]]>*/</script><script src="/polyfill-efbe87ab08854460e1b4.js" nomodule=""></script><script src="/component---src-templates-blog-post-js-5f317a7779dd1baa19f9.js" async=""></script><script src="/7a297f752dcfe258c0b0106d89edb3a916af916e-d921dc7587d10ed55da7.js" async=""></script><script src="/b1bda0e5b3305dd279ac60c39e10b0f82af56c10-cca622a04473b7e5e8b2.js" async=""></script><script src="/commons-33df4d3f9aa201d0ec4c.js" async=""></script><script src="/1bfc9850-103202d7f810115a42e7.js" async=""></script><script src="/5e2a4920-da90abce4a08c86a094c.js" async=""></script><script src="/d7eeaac4-dcbe97e7a5aa158c9d08.js" async=""></script><script src="/app-6b37a0275bc86b56e034.js" async=""></script><script src="/dc6a8720040df98778fe970bf6c000a41750d3ae-4121d07143daec1f6e61.js" async=""></script><script src="/styles-e8fd4555a67a3390b64e.js" async=""></script><script src="/framework-c8d3a5345e3f321d7da5.js" async=""></script><script src="/webpack-runtime-2d2e6eca74f66222a671.js" async=""></script></body></html>