<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=0"/><style data-href="/styles.d53766664f3eaba3db40.css" id="gatsby-global-css">/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden],template{display:none}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}button{background-color:transparent;background-image:none}button:focus{outline:1px dotted;outline:5px auto -webkit-focus-ring-color}fieldset,ol,ul{margin:0;padding:0}ol,ul{list-style:none}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;line-height:1.5}*,:after,:before{box-sizing:border-box;border:0 solid #e2e8f0}hr{border-top-width:1px}img{border-style:solid}textarea{resize:vertical}input::-webkit-input-placeholder,textarea::-webkit-input-placeholder{color:#a0aec0}input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#a0aec0}input::placeholder,textarea::placeholder{color:#a0aec0}[role=button],button{cursor:pointer}table{border-collapse:collapse}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit}code,kbd,pre,samp{font-family:Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}</style><meta name="generator" content="Gatsby 2.32.13"/><style type="text/css">
    .toc-header.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .toc-header.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .toc-header svg,
    h2 .toc-header svg,
    h3 .toc-header svg,
    h4 .toc-header svg,
    h5 .toc-header svg,
    h6 .toc-header svg {
      visibility: hidden;
    }
    h1:hover .toc-header svg,
    h2:hover .toc-header svg,
    h3:hover .toc-header svg,
    h4:hover .toc-header svg,
    h5:hover .toc-header svg,
    h6:hover .toc-header svg,
    h1 .toc-header:focus svg,
    h2 .toc-header:focus svg,
    h3 .toc-header:focus svg,
    h4 .toc-header:focus svg,
    h5 .toc-header:focus svg,
    h6 .toc-header:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="preconnect" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><link rel="icon" href="/favicon-32x32-1c5857f550ca5d27138682501fbd1e0a.png" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><meta name="theme-color" content="#3F4145"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><title data-react-helmet="true">VGG Implementation with Trial and Error | snoop2head&#x27;s blog</title><meta data-react-helmet="true" name="description" content="Personal Tips for Reading Paper Read Tables and Figures first: Most of the papers summarizes important findings on the tables and figures. Often times, most of the text on the papers are peripheral e…"/><meta data-react-helmet="true" property="og:title" content="VGG Implementation with Trial and Error"/><meta data-react-helmet="true" property="og:image" content="/static/social-image-a1864c5d52ffceef83c1d6baedf4493b.png"/><meta data-react-helmet="true" property="og:description" content="Personal Tips for Reading Paper Read Tables and Figures first: Most of the papers summarizes important findings on the tables and figures. Often times, most of the text on the papers are peripheral e…"/><meta data-react-helmet="true" property="og:type" content="website"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:image" content="/static/social-image-a1864c5d52ffceef83c1d6baedf4493b.png"/><meta data-react-helmet="true" name="twitter:creator" content="Young Jin Ahn"/><meta data-react-helmet="true" name="twitter:title" content="VGG Implementation with Trial and Error"/><meta data-react-helmet="true" name="twitter:description" content="Personal Tips for Reading Paper Read Tables and Figures first: Most of the papers summarizes important findings on the tables and figures. Often times, most of the text on the papers are peripheral e…"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link as="script" rel="preload" href="/webpack-runtime-2d2e6eca74f66222a671.js"/><link as="script" rel="preload" href="/framework-c8d3a5345e3f321d7da5.js"/><link as="script" rel="preload" href="/styles-e8fd4555a67a3390b64e.js"/><link as="script" rel="preload" href="/dc6a8720040df98778fe970bf6c000a41750d3ae-4121d07143daec1f6e61.js"/><link as="script" rel="preload" href="/app-6b37a0275bc86b56e034.js"/><link as="script" rel="preload" href="/d7eeaac4-dcbe97e7a5aa158c9d08.js"/><link as="script" rel="preload" href="/5e2a4920-da90abce4a08c86a094c.js"/><link as="script" rel="preload" href="/1bfc9850-103202d7f810115a42e7.js"/><link as="script" rel="preload" href="/commons-33df4d3f9aa201d0ec4c.js"/><link as="script" rel="preload" href="/b1bda0e5b3305dd279ac60c39e10b0f82af56c10-cca622a04473b7e5e8b2.js"/><link as="script" rel="preload" href="/7a297f752dcfe258c0b0106d89edb3a916af916e-d921dc7587d10ed55da7.js"/><link as="script" rel="preload" href="/component---src-templates-blog-post-js-5f317a7779dd1baa19f9.js"/><link as="fetch" rel="preload" href="/page-data/Researching/Friendly-VGG-Implementation/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/1081905842.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3911196313.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><noscript><style data-emotion-css="1vyo7ug">.css-1vyo7ug{position:fixed;bottom:0;left:0;margin-left:0.5rem;margin-bottom:0.5rem;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;box-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px 0 rgba(0,0,0,0.06);-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));font-size:0.875rem;font-weight:700;padding-left:1rem;padding-right:1rem;padding-top:0.75rem;padding-bottom:0.75rem;background-color:#86a8e7;z-index:9999;}</style><div class="css-1vyo7ug"><style data-emotion-css="5x4yj0">.css-5x4yj0{fill:currentColor;width:1.5rem;height:1.5rem;margin-right:0.5rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 192 512" class="css-5x4yj0" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M20 424.229h20V279.771H20c-11.046 0-20-8.954-20-20V212c0-11.046 8.954-20 20-20h112c11.046 0 20 8.954 20 20v212.229h20c11.046 0 20 8.954 20 20V492c0 11.046-8.954 20-20 20H20c-11.046 0-20-8.954-20-20v-47.771c0-11.046 8.954-20 20-20zM96 0C56.235 0 24 32.235 24 72s32.235 72 72 72 72-32.235 72-72S135.764 0 96 0z"></path></svg><style data-emotion-css="1f2k2gl">.css-1f2k2gl{margin-left:0.5rem;}</style><div class="css-1f2k2gl">Please enable JavaScript to use this site.<br/>JavaScript를 활성화 시켜주세요.</div></div></noscript><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><style data-emotion-css="f6s0ma">.css-f6s0ma{-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#333333;}</style><style data-emotion-css="acifd">.css-acifd{min-height:100vh;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#333333;}</style><div class="css-acifd e60ayux0"><style data-emotion-css="8ezs2g">.css-8ezs2g{min-height:calc(100vh - 100px);}</style><div class="css-8ezs2g"><style data-emotion-css="1yxw6gp">.css-1yxw6gp{background:linear-gradient( 90deg,#7f7fd5,#86a8e7 );}</style><div class="css-1yxw6gp"><style data-emotion-css="1mqm4zt">.css-1mqm4zt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;max-width:1280px;margin-left:auto;margin-right:auto;padding:1.25rem;}</style><nav class="css-1mqm4zt e1czdvww0"><style data-emotion-css="1usmgm5">.css-1usmgm5{font-size:1.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));font-weight:700;}</style><a class="css-1usmgm5" href="/">Young Jin Ahn&#x27;s Blog</a><a aria-label="search page" href="/search"><style data-emotion-css="47445j">.css-47445j{--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));margin-top:auto;margin-bottom:auto;width:2rem;height:2rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-47445j" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0 0 11.6 0l43.6-43.5a8.2 8.2 0 0 0 0-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></a></nav></div><style data-emotion-css="aod07n">.css-aod07n{background:linear-gradient( 90deg,#7f7fd5,#86a8e7 );position:fixed;width:100%;box-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px 0 rgba(0,0,0,0.06);z-index:100;-webkit-transition:all 300ms cubic-bezier(0,0,0.2,1);transition:all 300ms cubic-bezier(0,0,0.2,1);top:-100px;}</style><div class="css-aod07n"><nav class="css-1mqm4zt e1czdvww0"><a class="css-1usmgm5" href="/">Young Jin Ahn&#x27;s Blog</a><a aria-label="search page" href="/search"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-47445j" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0 0 11.6 0l43.6-43.5a8.2 8.2 0 0 0 0-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></a></nav></div><style data-emotion-css="w27u98">.css-w27u98{margin-top:1rem;padding-left:1rem;padding-right:1rem;}</style><div class="blog-post-container css-w27u98"><div class="blog-post"><style data-emotion-css="1bdwg0l">.css-1bdwg0l{width:100%;max-width:768px;margin-left:auto;margin-right:auto;}</style><div class="css-1bdwg0l eyldt480"><style data-emotion-css="1abxlfd">.css-1abxlfd{font-size:2.25rem;font-weight:700;margin-bottom:1rem;}@media (min-width:768px){.css-1abxlfd{font-size:3rem;}}</style><h1 class="blog-title css-1abxlfd">VGG Implementation with Trial and Error</h1><style data-emotion-css="cpn9zx">.css-cpn9zx{font-size:1rem;margin-bottom:1rem;}</style><h2 class="blog-date css-cpn9zx">2022-10-03</h2><style data-emotion-css="cet0rr">.css-cet0rr{margin-bottom:0.5rem;}</style><div class="blog-tags css-cet0rr"><style data-emotion-css="1ak4bcm">.css-1ak4bcm{white-space:nowrap;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);font-size:1rem;font-weight:700;border-radius:9999px;margin-right:0.5rem;margin-top:0.25rem;margin-bottom:0.25rem;padding-top:0.25rem;padding-bottom:0.25rem;padding-left:0.75rem;padding-right:0.75rem;background-color:#edf2f7;color:#3737B9;}</style><button class="css-1ak4bcm">ComputerVision</button><button class="css-1ak4bcm">Pytorch</button><button class="css-1ak4bcm">VGG</button></div><style data-emotion-css="1l4w6pd">.css-1l4w6pd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}</style><div class="css-1l4w6pd"><style data-emotion-css="yapsbb">.css-yapsbb{border-radius:9999px;width:100%;height:1px;--bg-opacity:1;background-color:rgba(247,250,252,var(--bg-opacity));background:linear-gradient( 270deg,#7f7fd5,#86a8e7,#91eac9 );}</style><div class="css-yapsbb"></div></div></div><div class="blog-content"><style data-emotion-css="19vk1qv">.css-19vk1qv{-webkit-scrollbar-width:thin;-moz-scrollbar-width:thin;-ms-scrollbar-width:thin;scrollbar-width:thin;-webkit-scrollbar-color:gray transparent;-moz-scrollbar-color:gray transparent;-ms-scrollbar-color:gray transparent;scrollbar-color:gray transparent;display:none;}.css-19vk1qv::-webkit-scrollbar{width:4px;}.css-19vk1qv::-webkit-scrollbar-track{background-color:transparent;}.css-19vk1qv::-webkit-scrollbar-thumb{border-radius:9999px;background-color:gray;}.css-19vk1qv::-webkit-scrollbar-button{width:0;height:0;}@media screen and (min-width:1280px){.css-19vk1qv{float:right;position:-webkit-sticky;position:sticky;top:100px;width:calc((100vw - 720px) / 2 - 80px);max-width:250px;margin-right:1rem;overflow:auto;word-break:break-word;max-height:calc(100vh - 200px);fontsize:1rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;border-left-width:4px;border-image:linear-gradient( 180deg,#7f7fd5,#86a8e7,#91eac9 );border-image-slice:1;}}</style><div class="css-19vk1qv"><style data-emotion-css="13af3fo">.css-13af3fo{margin-left:1rem;margin-right:1rem;}</style><div class="css-13af3fo"><style data-emotion-css="17i5xbf">.css-17i5xbf{font-weight:700;margin-bottom:0.5rem;font-size:1.125rem;--text-opacity:1;color:rgba(74,85,104,var(--text-opacity));}</style><h3 class="css-17i5xbf">TOC</h3><style data-emotion-css="1me4zjn">.css-1me4zjn ul{margin-left:0.5rem;}.css-1me4zjn ul > li a:hover{color:#555555;}.css-1me4zjn ul > li a{-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);--text-opacity:1;color:rgba(160,174,192,var(--text-opacity));font-size:0.875rem;}.css-1me4zjn ul > li a[href=""]{font-size:0.95rem;color:#555555;}</style><div class="css-1me4zjn"><ul>
<li><a href="/Researching/Friendly-VGG-Implementation/#personal-tips-for-reading-paper">Personal Tips for Reading Paper</a></li>
<li><a href="/Researching/Friendly-VGG-Implementation/#personal-tips-for-implementing-papers-into-code">Personal Tips for Implementing Papers into Code</a></li>
<li><a href="/Researching/Friendly-VGG-Implementation/#review-on-very-deep-convolutional-networks-for-large-scale-image-recognition">Review on Very Deep Convolutional Networks for Large-Scale Image Recognition</a></li>
<li>
<p><a href="/Researching/Friendly-VGG-Implementation/#implementing-vgg-on-imagenet-subset">Implementing VGG on ImageNet Subset</a></p>
<ul>
<li><a href="/Researching/Friendly-VGG-Implementation/#trouble-encountered">Trouble Encountered</a></li>
<li><a href="/Researching/Friendly-VGG-Implementation/#adaptiveavgpool">AdaptiveAvgPool</a></li>
<li><a href="/Researching/Friendly-VGG-Implementation/#weight-initialization">Weight Initialization</a></li>
<li><a href="/Researching/Friendly-VGG-Implementation/#batch-normalization">Batch normalization</a></li>
<li><a href="/Researching/Friendly-VGG-Implementation/#weight-vs-bias">Weight vs Bias</a></li>
<li><a href="/Researching/Friendly-VGG-Implementation/#references">References</a></li>
</ul>
</li>
</ul></div></div></div><div class="css-1bdwg0l eyldt480"><div><style data-emotion-css="c0q8g3">.css-c0q8g3{font-size:1rem;word-break:break-word;}.css-c0q8g3 h1 > a > svg,.css-c0q8g3 h2 > a > svg,.css-c0q8g3 h3 > a > svg,.css-c0q8g3 h4 > a > svg,.css-c0q8g3 h5 > a > svg,.css-c0q8g3 h6 > a > svg{fill:#000;}.css-c0q8g3 h1,.css-c0q8g3 h2{font-size:1.25rem;font-weight:600;margin-top:1.5rem;margin-bottom:1.5rem;}.css-c0q8g3 h3,.css-c0q8g3 h4,.css-c0q8g3 h5,.css-c0q8g3 h6{font-size:1.125rem;margin-top:1.5rem;margin-bottom:1.5rem;font-weight:600;}@media (min-width:640px){.css-c0q8g3 h1,.css-c0q8g3 h2{font-size:1.5rem;}.css-c0q8g3 h3,.css-c0q8g3 h4,.css-c0q8g3 h5,.css-c0q8g3 h6{font-size:1.25rem;}}.css-c0q8g3 a{color:#3737B9;}.css-c0q8g3 a:hover{-webkit-text-decoration:underline;text-decoration:underline;}.css-c0q8g3 p{margin:0.3rem;margin-top:0.75rem;margin-bottom:0.75rem;}.css-c0q8g3 ul,.css-c0q8g3 ol{margin:0.3rem;margin-left:2rem;}.css-c0q8g3 li > p,.css-c0q8g3 li > ul,.css-c0q8g3 li > ol{margin-bottom:0;}.css-c0q8g3 ol{list-style-type:decimal;}.css-c0q8g3 ul{list-style-type:disc;}.css-c0q8g3 blockquote{padding:0.5rem;background-color:#eee;margin:0.3rem;margin-top:0.5rem;margin-bottom:0.5rem;border-left-width:4px;border-color:#86a8e7;}.css-c0q8g3 blockquote > p{margin:0.5rem;}.css-c0q8g3 blockquote > h1,.css-c0q8g3 blockquote > h2,.css-c0q8g3 blockquote > h3,.css-c0q8g3 blockquote > h4,.css-c0q8g3 blockquote > h5{margin-top:0.5rem;margin-bottom:0.5rem;}.css-c0q8g3 td,.css-c0q8g3 th{padding-left:0.5rem;padding-right:0.5rem;padding-top:0.25rem;padding-bottom:0.25rem;border-width:1px;border-color:#86a8e7;}.css-c0q8g3 tr:nth-of-type(even){background-color:#eee;}.css-c0q8g3 th{background-color:#eee;}.css-c0q8g3 table{margin-bottom:1.5rem;display:block;max-width:-webkit-fit-content;max-width:-moz-fit-content;max-width:fit-content;margin:0 auto;overflow-x:auto;white-space:nowrap;}.css-c0q8g3 p > code,.css-c0q8g3 li > code{padding-top:0.1rem;padding-bottom:0.1rem;padding-right:0.25rem;padding-left:0.25rem;border-radius:0.25rem;color:#3737B9;background-color:#eee;white-space:pre-line;}.css-c0q8g3 pre.grvsc-container{margin-top:24px;margin-bottom:24px;}.css-c0q8g3 hr{margin-top:24px;margin-bottom:24px;height:2px;border:none;background:linear-gradient( 270deg,#7f7fd5,#86a8e7,#91eac9 );}</style><div class="markdown css-c0q8g3"><h2 id="personal-tips-for-reading-paper" style="position:relative;"><a href="#personal-tips-for-reading-paper" aria-label="personal tips for reading paper permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Personal Tips for Reading Paper</h2>
<ul>
<li><strong>Read Tables and Figures first</strong>: Most of the papers summarizes important findings on the tables and figures. Often times, most of the text on the papers are peripheral explication of such tables and figures.</li>
<li><strong>Read Methodology or Architecture before the Introduction</strong>: introduction 1) is either relatively repetetive or 2) summary of preceding research.</li>
<li><strong>Prior to reading the paper thoroughly, find which research are crucial to understand in the ongoing discourse in the Introduction part.</strong></li>
</ul>
<h2 id="personal-tips-for-implementing-papers-into-code" style="position:relative;"><a href="#personal-tips-for-implementing-papers-into-code" aria-label="personal tips for implementing papers into code permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Personal Tips for Implementing Papers into Code</h2>
<ul>
<li><strong>Implement an experiment what seems to represent the novel findings of the paper.</strong> Implementing all of the experiments in the paper is nearly impossible without the help of the others.  </li>
<li><strong>Open-source the code if and only if the paper is already open to the public.</strong> Most of the code requires refactoring. Being aware of the audience, public code under the personal authorship is more likely to be proofreaded again even without feedbacks from the others.</li>
<li><strong>Develop the official implementations or other people's implementations which are likely to be imperfect.</strong> Surprisingly, many of the official implementations lack details. This is probably because of lack of time for version management where private code remains covert.</li>
</ul>
<h2 id="review-on-very-deep-convolutional-networks-for-large-scale-image-recognition" style="position:relative;"><a href="#review-on-very-deep-convolutional-networks-for-large-scale-image-recognition" aria-label="review on very deep convolutional networks for large scale image recognition permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Review on <a href="https://arxiv.org/pdf/1409.1556.pdf">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></h2>
<p>Convolutional neural network's purpose is to extract representative features from the given input.</p>
<p>Historically, simply stacking up multiple blocks of [3 x 3 convolution, activation, max-pooling] to achieve desired performance was gargantuan contribution.</p>
<ol>
<li><strong>Compared to prior neural networks, numbers of layers in VGG was considered to be "very deep".</strong> Convolutional layers + fully connected layers totaled 19 layers for VGG19. However, in the following year, numbers of layers shoots up to 152 layers in ResNet architecture.
<span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 43.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB0klEQVQoz02SW2/TQBBG+8+REC8gqBDlCcQDlIcC7Q9AwBNITSnhopI0cS4ktuM4cezYjhPi2x7G6zR0rd2xv/EefzPeA6WAMkOVBTcjCAIWiwXL5RLf9wnDkCiKiCTGcYzSm0CtV6heB+VORKv3H1TLh/MhPTOgLDImzow0TcnzXM/qPk0zsqyelabKUkNVnlHOLFQS7T+igQ9Puly0fRwv4f7rligFm3jJVl68Pao9GiSz1FHA+qpz1aKBT88Mml0fa77m3qvrqgdMLJso8Cm2CXHgSVe2O6jauZEoFamiuKXtHD45NfjW8bEr4MuWThyddvluBKhsg+NMKdONgOdsVyH5dk28XJCuY3GKdlu5UzfAo7OeOAxqoHYIj94YXA1C/jgrDt92tWZaU5JVQvp3je860vNct4eq9NpgDTw8ueay7WHPEu48/6UTD45/c9UP6FsRd1/U2uPjJr2xaCOPZ+9+aq31Y0wcbvbt0MBGs49puniez+fzNrmU17g0sO0Z06nHl0aHXHr4qTHEnkqvpyEfv8rfLVLeX5hYbvgfWJ2vQd9gPB4J0GNim6ykrMGgx8x1WcqZtMwRqyTBdSx5FqA5ptdtyVn1GQ8NifM98B+MiaPa+r90WQAAAABJRU5ErkJggg=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20221004030750679"
        title="image-20221004030750679"
        src="/static/d6f6cb2e837b9faf23af74076f4de40d/c1b63/image-20221004030750679.png"
        srcset="/static/d6f6cb2e837b9faf23af74076f4de40d/5a46d/image-20221004030750679.png 300w,
/static/d6f6cb2e837b9faf23af74076f4de40d/0a47e/image-20221004030750679.png 600w,
/static/d6f6cb2e837b9faf23af74076f4de40d/c1b63/image-20221004030750679.png 1200w,
/static/d6f6cb2e837b9faf23af74076f4de40d/d61c2/image-20221004030750679.png 1800w,
/static/d6f6cb2e837b9faf23af74076f4de40d/3c2d4/image-20221004030750679.png 2092w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></li>
<li>
<p>Compared to GoogleNet, VGG's architecture was simple. Googlenet which acheived SOTA performance consisted of 1) inception modules and 2) intermediate classifier branches in the middle of the architecture.</p>
<p>Inception modules illustrated below uses heterogeneous sizes of convolutional layers, ranging from 1x1 to 5x5, which are concatenated at the end.
<span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 62.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACCklEQVQ4y21T2ZLaMBDk/78nP7B5DNSGbF7CesEcvm9bkmXLR2dGrFkgUdWUBDPT02q1V0VRQgiBvu9hjME8z5imCbySOEZVlvbM/y+5JcZxtMHnJbdyHAfrH2tst1vweWkWYYhot0Pw9hum6zFwI8X8CfawPsG4b1XXNX6+viIIAlRVhZnyNbHKfd/WFq4L0TRotUZDN1mgfM+D6x5xOBygaSAvy7CkZo+SbdsiiiJ0XQdNZ5mmME0NScA8ZCZ22fmM8uIhOgeI0hINkRFSom1KdKKwoKuGpidJAt4v1DAMg030NHW9/oUsr+1vHqCzDMFuj/MpQZS4wHjB1J2ROt+gitMVkK+cUjEz3ZFmfW+gpMDJi3D0MjhuaAtbyjPL1I8Rhjn84EhS+OhViPjjBUMvWEqsWDeXdGINGZyDV1kpFJVGGFfoyAGdUpB5jiYmdmGMoqwxkqBCSLp686WhokLWkG3DK88LSNlgGioE/jtNzqA1WUsqEr+DYn1JN1KVdFekub6B2Vf+enn22QQzTIhDB0a7GExE+x5augRq6LEUmADX8iNq/QhmGd4bdUlo3RIQXSXak/fMzW5LDYNxPINZwGf3s3FHEtd7f0MdfFgLta22zBiE9/8xu135/pO67uNVS/8A7/AHGVmFP8n7z+we7L73AfA5OQwGm80GLy/fbw/27/DpAYzjL//m7BG0y3GVAAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20221004032254634"
        title="image-20221004032254634"
        src="/static/e71e2007ca4b9a5602ab0af045b4c832/c1b63/image-20221004032254634.png"
        srcset="/static/e71e2007ca4b9a5602ab0af045b4c832/5a46d/image-20221004032254634.png 300w,
/static/e71e2007ca4b9a5602ab0af045b4c832/0a47e/image-20221004032254634.png 600w,
/static/e71e2007ca4b9a5602ab0af045b4c832/c1b63/image-20221004032254634.png 1200w,
/static/e71e2007ca4b9a5602ab0af045b4c832/1d499/image-20221004032254634.png 1632w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<p>Moreover, GoogleNet had intermediate auxiliary classifier, represented as the yellow block in the diagram below, used during the training. The architecture was computationally efficient but the structure was less intuitive.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 22.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA6ElEQVQY042P20rDUBBF8/9/0gdBRFQUfNGCMdWqTXpoY02bq03SNCUx95xl7IPgmwPDwGb22myFf0zbwVcFSS5Jh91EEuEkGFbGtdhzKw74tkWVblC6TlKUBVndUdUFwq1ZbiuWQcnuUDFzau7NnLNpyOl0y8lTyOjRZ2zYvGkrrjSPG83F9xzKH2C8q5kLnbGdoQ/3/C4YDC4Xz2smqsnoweFSdXk1XPRFxIsRINQZ84+GPDQHSEqV179tlD/d+hbXioicmHAIyuOUz3XIavKOHea0yfz41iR7vLilyDyQzVGTfY+Ukm89Kyp4/jNY1QAAAABJRU5ErkJggg=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20221004032046216"
        title="image-20221004032046216"
        src="/static/ac17bfafdd00df3ecc0ec4772e40d0ee/c1b63/image-20221004032046216.png"
        srcset="/static/ac17bfafdd00df3ecc0ec4772e40d0ee/5a46d/image-20221004032046216.png 300w,
/static/ac17bfafdd00df3ecc0ec4772e40d0ee/0a47e/image-20221004032046216.png 600w,
/static/ac17bfafdd00df3ecc0ec4772e40d0ee/c1b63/image-20221004032046216.png 1200w,
/static/ac17bfafdd00df3ecc0ec4772e40d0ee/d61c2/image-20221004032046216.png 1800w,
/static/ac17bfafdd00df3ecc0ec4772e40d0ee/97a96/image-20221004032046216.png 2400w,
/static/ac17bfafdd00df3ecc0ec4772e40d0ee/3a4f1/image-20221004032046216.png 2588w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<p><strong>On the other hand, VGG is monotonous repetition of [3 x 3 convolution, activation, max-pooling] before the classifier.</strong></p>
<p><img src="https://miro.medium.com/max/1400/1*NNifzsJ7tD2kAfBXt3AzEg.png" alt="An overview of VGG16 and NiN models | by Khuyen Le | MLearning.ai | Medium"></p>
</li>
</ol>
<h2 id="implementing-vgg-on-imagenet-subset" style="position:relative;"><a href="#implementing-vgg-on-imagenet-subset" aria-label="implementing vgg on imagenet subset permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Implementing VGG on ImageNet Subset</h2>
<p>In order to replicate the experiment, <a href="https://huggingface.co/datasets/imagenet-1k">ImageNet1K dataset</a> should be used. However, ImageNet training dataset takes up more than 130GB of storage which makes it a great benchmark to compare between the models but a bad testing bed for trial and errors.</p>
<p>Thus for this blog post, 10 subset classes of ImageNet is used as the dataset. <a href="https://github.com/fastai/imagenette">Imagenette Dataset by FastAI</a> allows us to test the models on easy classification task(Imagenette) and difficult classification task(imagewoof). Former one is classifying distinctive classes of objects/animals and the latter one is classifying species of dog.</p>
<ol>
<li>
<p>3 x 3 convolution is relatively small-sized filter.</p>
<ul>
<li>Small is good enough</li>
<li>Better to stack up 3 x (3 x 3) than 1 x (7 x 7)</li>
</ul>
</li>
<li>Consequent max-pooling operations reduces resolution into half. e.g (224 x 224) -> (112 x 112)</li>
</ol>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="0"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># unzip .tgz file</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Subset of ImageNet: 1000 class -&gt; 10 class and 130GB -&gt; 300MB: https://github.com/fastai/imagenette</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># !tar -xvzf /home/ubuntu/imagenet/imagenette2-320.tgz # easy classification task for 10 classes</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># !tar -xvzf /home/ubuntu/imagenet/imagewoof2-320.tgz # hard classification task for 10 classes</span></span></span></code></pre>
<h3 id="trouble-encountered" style="position:relative;"><a href="#trouble-encountered" aria-label="trouble encountered permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Trouble Encountered</h3>
<ul>
<li>
<p>Implemented VGG16 underperforms torchvision vgg16</p>
<ul>
<li>Top1 Acc 44% vs 9.7%</li>
<li>Loss 2.3 vs 6.8</li>
</ul>
</li>
<li>Loss is reluctant to be updated as training progresses</li>
</ul>
<h3 id="adaptiveavgpool" style="position:relative;"><a href="#adaptiveavgpool" aria-label="adaptiveavgpool permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>AdaptiveAvgPool</h3>
<ul>
<li>Why is there AdaptiveAvgPool at the torchvision implementation whereas none-existent in paper?</li>
</ul>
<h3 id="weight-initialization" style="position:relative;"><a href="#weight-initialization" aria-label="weight initialization permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Weight Initialization</h3>
<ul>
<li>Why initialization increases performance?</li>
<li>Difference between each Weight Initialization methods</li>
<li>
<p>How to initialize weights in Pytorch </p>
<ul>
<li><a href="https://jh-bk.tistory.com/10">Loss Intialization</a></li>
<li><a href="https://pytorch.org/docs/stable/nn.init.html">torch.nn.init documentation</a></li>
<li><a href="https://wandb.ai/wandb_fc/tips/reports/How-to-Initialize-Weights-in-PyTorch--VmlldzoxNjcwOTg1">How to Initialize Weights in PyTorch</a></li>
</ul>
</li>
</ul>
<p>-> Slight performance increase to 10%</p>
<h3 id="batch-normalization" style="position:relative;"><a href="#batch-normalization" aria-label="batch normalization permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Batch normalization</h3>
<ul>
<li>location of batch normalization?</li>
<li>function of batch normalization?</li>
<li>Why does batch normalization does not appear in torch summary?</li>
<li>Why does batch normalization increase memory space of the model?</li>
</ul>
<p>-> Batch normalization didn't make any differences</p>
<h3 id="weight-vs-bias" style="position:relative;"><a href="#weight-vs-bias" aria-label="weight vs bias permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Weight vs Bias</h3>
<ul>
<li>Difference between weight and bias</li>
</ul>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="1"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch.nn </span><span class="mtk10 mtki">as</span><span class="mtk1"> nn </span><span class="mtk5 mtki"># import basic components</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch.nn.functional </span><span class="mtk10 mtki">as</span><span class="mtk1"> F </span><span class="mtk5 mtki"># import functions</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> torchsummary </span><span class="mtk10 mtki">import</span><span class="mtk1"> summary</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># VGG16, Configuration D</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">class</span><span class="mtk1"> </span><span class="mtk11">VGG16</span><span class="mtk1">(</span><span class="mtk11">nn</span><span class="mtk1">.</span><span class="mtk11">Module</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk8">__init__</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11 mtki">self</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk7 mtki">dropout_ratio</span><span class="mtk1">=</span><span class="mtk7">0.5</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk7 mtki">input_channels</span><span class="mtk1">=</span><span class="mtk7">3</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk7 mtki">input_resolution</span><span class="mtk1">=</span><span class="mtk7">224</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk7 mtki">num_classes</span><span class="mtk1">=</span><span class="mtk7">1000</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    ):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        https://arxiv.org/pdf/1409.1556.pdf</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        - Implementation of Table 1&#39;s ConvNet D Configuration</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        - Each of the layers&#39; output notated as channel@heightxwidth on the comments</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">        &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk8">super</span><span class="mtk1">(</span><span class="mtk7">VGG16</span><span class="mtk1">, </span><span class="mtk11">self</span><span class="mtk1">).</span><span class="mtk8">__init__</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk11">self</span><span class="mtk1">._initialize_weights)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># instantiate input variables as class attributes</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.dropout_ratio </span><span class="mtk8">=</span><span class="mtk1"> dropout_ratio</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.input_channels </span><span class="mtk8">=</span><span class="mtk1"> input_channels</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.input_resolution </span><span class="mtk8">=</span><span class="mtk1"> input_resolution</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.num_classes </span><span class="mtk8">=</span><span class="mtk1"> num_classes</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># convolutional layers configuration</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.conv_size </span><span class="mtk8">=</span><span class="mtk1"> (</span><span class="mtk7">3</span><span class="mtk1">, </span><span class="mtk7">3</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.conv_stride </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">1</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.conv_padding </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">1</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># max-pooling operations configuration</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.pool_size </span><span class="mtk8">=</span><span class="mtk1"> (</span><span class="mtk7">2</span><span class="mtk1">, </span><span class="mtk7">2</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.pool_stride </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">2</span><span class="mtk1">  </span><span class="mtk5 mtki"># max pooling halves the image&#39;s resolution</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.num_pooling </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">5</span><span class="mtk1">  </span><span class="mtk5 mtki"># number of max-pooling operations</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># fully-connected layers configuration</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.final_conv_output_resolution </span><span class="mtk8">=</span><span class="mtk1"> (</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk11">self</span><span class="mtk1">.input_resolution </span><span class="mtk8">//</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.pool_stride </span><span class="mtk8">**</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.num_pooling</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.fc_size </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">4096</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.conv1 </span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">Sequential</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.input_channels,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">64</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 64@224x224</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">64</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">64</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 64@224x224</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">MaxPool2d</span><span class="mtk1">(</span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.pool_size, </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.pool_stride),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )  </span><span class="mtk5 mtki"># 64@112x112</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.conv2 </span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">Sequential</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">64</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">128</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 128@112x112</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">128</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">128</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 128@112x112</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">MaxPool2d</span><span class="mtk1">(</span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.pool_size, </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.pool_stride),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )  </span><span class="mtk5 mtki"># 128@56x56</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.conv3 </span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">Sequential</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">128</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">256</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 256@56x56</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">256</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">256</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 256@56x56</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">256</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">256</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 256@56x56</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">MaxPool2d</span><span class="mtk1">(</span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.pool_size, </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.pool_stride),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )  </span><span class="mtk5 mtki"># 256@28x28</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.conv4 </span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">Sequential</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">256</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 512@28x28</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 512@28x28</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 512@28x28</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">MaxPool2d</span><span class="mtk1">(</span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.pool_size, </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.pool_stride),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )  </span><span class="mtk5 mtki"># 512@14x14</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.conv5 </span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">Sequential</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 512@14x14</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 512@14x14</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Conv2d</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">in_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">out_channels</span><span class="mtk8">=</span><span class="mtk7">512</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_size,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_stride,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.conv_padding,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            ),  </span><span class="mtk5 mtki"># 512@14x14</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">MaxPool2d</span><span class="mtk1">(</span><span class="mtk4 mtki">kernel_size</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.pool_size, </span><span class="mtk4 mtki">stride</span><span class="mtk8">=</span><span class="mtk11">self</span><span class="mtk1">.pool_stride),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )  </span><span class="mtk5 mtki"># 512@7x7</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># count number of nn.maxpool2d layers</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk11">self</span><span class="mtk1">.fc_module </span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">Sequential</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Linear</span><span class="mtk1">(</span><span class="mtk7">512</span><span class="mtk1"> </span><span class="mtk8">*</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.final_conv_output_resolution </span><span class="mtk8">**</span><span class="mtk1"> </span><span class="mtk7">2</span><span class="mtk1">, </span><span class="mtk11">self</span><span class="mtk1">.fc_size),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Dropout</span><span class="mtk1">(</span><span class="mtk11">self</span><span class="mtk1">.dropout_ratio),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Linear</span><span class="mtk1">(</span><span class="mtk11">self</span><span class="mtk1">.fc_size, </span><span class="mtk11">self</span><span class="mtk1">.fc_size),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Dropout</span><span class="mtk1">(</span><span class="mtk11">self</span><span class="mtk1">.dropout_ratio),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">ReLU</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.</span><span class="mtk3">Linear</span><span class="mtk1">(</span><span class="mtk11">self</span><span class="mtk1">.fc_size, </span><span class="mtk11">self</span><span class="mtk1">.num_classes),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">forward</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">, </span><span class="mtk7 mtki">x</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># forward pass through convolutional layers</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        out </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">conv1</span><span class="mtk1">(x)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        out </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">conv2</span><span class="mtk1">(out)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        out </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">conv3</span><span class="mtk1">(out)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        out </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">conv4</span><span class="mtk1">(out)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        out </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">conv5</span><span class="mtk1">(out)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># flatten the output</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        out </span><span class="mtk8">=</span><span class="mtk1"> out.</span><span class="mtk3">flatten</span><span class="mtk1">(</span><span class="mtk4 mtki">start_dim</span><span class="mtk8">=</span><span class="mtk7">1</span><span class="mtk1">)  </span><span class="mtk5 mtki"># assuming batch size is first dimension</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># forward pass through fully connected layers</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        out </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk11">self</span><span class="mtk1">.</span><span class="mtk3">fc_module</span><span class="mtk1">(out)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># yield prediction probabilities for each class using softmax</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">return</span><span class="mtk1"> F.</span><span class="mtk3">softmax</span><span class="mtk1">(out, </span><span class="mtk4 mtki">dim</span><span class="mtk8">=</span><span class="mtk7">1</span><span class="mtk1">)  </span><span class="mtk5 mtki"># assuming batch size is first dimension</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">_initialize_weights</span><span class="mtk1">(</span><span class="mtk11 mtki">self</span><span class="mtk1">, </span><span class="mtk7 mtki">module</span><span class="mtk1">):    </span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> </span><span class="mtk8">isinstance</span><span class="mtk1">(module, nn.Conv2d):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.init.</span><span class="mtk3">kaiming_normal_</span><span class="mtk1">(module.weight, </span><span class="mtk4 mtki">mode</span><span class="mtk8">=</span><span class="mtk6">&quot;fan_out&quot;</span><span class="mtk1">, </span><span class="mtk4 mtki">nonlinearity</span><span class="mtk8">=</span><span class="mtk6">&quot;relu&quot;</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk10 mtki">if</span><span class="mtk1"> module.bias </span><span class="mtk10">is</span><span class="mtk1"> </span><span class="mtk10">not</span><span class="mtk1"> </span><span class="mtk7">None</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                nn.init.</span><span class="mtk3">constant_</span><span class="mtk1">(module.bias, </span><span class="mtk7">0</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">elif</span><span class="mtk1"> </span><span class="mtk8">isinstance</span><span class="mtk1">(module, nn.Linear):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.init.</span><span class="mtk3">normal_</span><span class="mtk1">(module.weight, </span><span class="mtk7">0</span><span class="mtk1">, </span><span class="mtk7">0.01</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            nn.init.</span><span class="mtk3">constant_</span><span class="mtk1">(module.bias, </span><span class="mtk7">0</span><span class="mtk1">)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="2"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> torchvision.models </span><span class="mtk10 mtki">import</span><span class="mtk1"> vgg16</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Setting device</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">is_cuda </span><span class="mtk8">=</span><span class="mtk1"> torch.cuda.</span><span class="mtk3">is_available</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">device </span><span class="mtk8">=</span><span class="mtk1"> torch.</span><span class="mtk3">device</span><span class="mtk1">(</span><span class="mtk6">&#39;cuda:0&#39;</span><span class="mtk1"> </span><span class="mtk10 mtki">if</span><span class="mtk1"> is_cuda </span><span class="mtk10 mtki">else</span><span class="mtk1"> </span><span class="mtk6">&#39;cpu&#39;</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1"> (</span><span class="mtk6">&#39;Current cuda device is&#39;</span><span class="mtk1">, device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Both are VGG16, Configuration D</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">custom_vgg_model </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">VGG16</span><span class="mtk1">() </span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">torch_vgg_model </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">vgg16</span><span class="mtk1">(</span><span class="mtk4 mtki">pretrained</span><span class="mtk8">=</span><span class="mtk7">False</span><span class="mtk1">) </span><span class="mtk5 mtki"># pretrained=False for random initialization</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&quot;--------------------Custom VGG16--------------------&quot;</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk3">summary</span><span class="mtk1">(custom_vgg_model.</span><span class="mtk3">to</span><span class="mtk1">(device), (</span><span class="mtk7">3</span><span class="mtk1">, </span><span class="mtk7">224</span><span class="mtk1">, </span><span class="mtk7">224</span><span class="mtk1">)))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&quot;--------------------Torch VGG16--------------------&quot;</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk3">summary</span><span class="mtk1">(torch_vgg_model.</span><span class="mtk3">to</span><span class="mtk1">(device), (</span><span class="mtk7">3</span><span class="mtk1">, </span><span class="mtk7">224</span><span class="mtk1">, </span><span class="mtk7">224</span><span class="mtk1">)))</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="3"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">Current cuda device is cuda:0</span></span>
<span class="grvsc-line"><span class="grvsc-source">--------------------Custom VGG16--------------------</span></span>
<span class="grvsc-line"><span class="grvsc-source">----------------------------------------------------------------</span></span>
<span class="grvsc-line"><span class="grvsc-source">        Layer (type)               Output Shape         Param #</span></span>
<span class="grvsc-line"><span class="grvsc-source">================================================================</span></span>
<span class="grvsc-line"><span class="grvsc-source">            Conv2d-1         [-1, 64, 224, 224]           1,792</span></span>
<span class="grvsc-line"><span class="grvsc-source">              ReLU-2         [-1, 64, 224, 224]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">            Conv2d-3         [-1, 64, 224, 224]          36,928</span></span>
<span class="grvsc-line"><span class="grvsc-source">              ReLU-4         [-1, 64, 224, 224]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">         MaxPool2d-5         [-1, 64, 112, 112]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">            Conv2d-6        [-1, 128, 112, 112]          73,856</span></span>
<span class="grvsc-line"><span class="grvsc-source">              ReLU-7        [-1, 128, 112, 112]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">            Conv2d-8        [-1, 128, 112, 112]         147,584</span></span>
<span class="grvsc-line"><span class="grvsc-source">              ReLU-9        [-1, 128, 112, 112]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">        MaxPool2d-10          [-1, 128, 56, 56]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Conv2d-11          [-1, 256, 56, 56]         295,168</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-12          [-1, 256, 56, 56]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Conv2d-13          [-1, 256, 56, 56]         590,080</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-14          [-1, 256, 56, 56]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Conv2d-15          [-1, 256, 56, 56]         590,080</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-16          [-1, 256, 56, 56]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">        MaxPool2d-17          [-1, 256, 28, 28]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Conv2d-18          [-1, 512, 28, 28]       1,180,160</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-19          [-1, 512, 28, 28]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Conv2d-20          [-1, 512, 28, 28]       2,359,808</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-21          [-1, 512, 28, 28]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Conv2d-22          [-1, 512, 28, 28]       2,359,808</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-23          [-1, 512, 28, 28]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">        MaxPool2d-24          [-1, 512, 14, 14]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Conv2d-25          [-1, 512, 14, 14]       2,359,808</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-26          [-1, 512, 14, 14]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Conv2d-27          [-1, 512, 14, 14]       2,359,808</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-28          [-1, 512, 14, 14]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Conv2d-29          [-1, 512, 14, 14]       2,359,808</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-30          [-1, 512, 14, 14]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">        MaxPool2d-31            [-1, 512, 7, 7]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Linear-32                 [-1, 4096]     102,764,544</span></span>
<span class="grvsc-line"><span class="grvsc-source">          Dropout-33                 [-1, 4096]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-34                 [-1, 4096]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Linear-35                 [-1, 4096]      16,781,312</span></span>
<span class="grvsc-line"><span class="grvsc-source">          Dropout-36                 [-1, 4096]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">             ReLU-37                 [-1, 4096]               0</span></span>
<span class="grvsc-line"><span class="grvsc-source">           Linear-38                 [-1, 1000]       4,097,000</span></span>
<span class="grvsc-line"><span class="grvsc-source">================================================================</span></span>
<span class="grvsc-line"><span class="grvsc-source">Total params: 138,357,544</span></span>
<span class="grvsc-line"><span class="grvsc-source">Trainable params: 138,357,544</span></span>
<span class="grvsc-line"><span class="grvsc-source">Non-trainable params: 0</span></span>
<span class="grvsc-line"><span class="grvsc-source">----------------------------------------------------------------</span></span>
<span class="grvsc-line"><span class="grvsc-source">Input size (MB): 0.57</span></span>
<span class="grvsc-line"><span class="grvsc-source">Forward/backward pass size (MB): 218.59</span></span>
<span class="grvsc-line"><span class="grvsc-source">Params size (MB): 527.79</span></span>
<span class="grvsc-line"><span class="grvsc-source">Estimated Total Size (MB): 746.96</span></span>
<span class="grvsc-line"><span class="grvsc-source">----------------------------------------------------------------</span></span></code></pre>
<p>​<br>
--------------------Torch VGG16--------------------
----------------------------------------------------------------
Layer (type)               Output Shape         Param #
================================================================
Conv2d-1         [-1, 64, 224, 224]           1,792
ReLU-2         [-1, 64, 224, 224]               0
Conv2d-3         [-1, 64, 224, 224]          36,928
ReLU-4         [-1, 64, 224, 224]               0
MaxPool2d-5         [-1, 64, 112, 112]               0
Conv2d-6        [-1, 128, 112, 112]          73,856
ReLU-7        [-1, 128, 112, 112]               0
Conv2d-8        [-1, 128, 112, 112]         147,584
ReLU-9        [-1, 128, 112, 112]               0
MaxPool2d-10          [-1, 128, 56, 56]               0
Conv2d-11          [-1, 256, 56, 56]         295,168
ReLU-12          [-1, 256, 56, 56]               0
Conv2d-13          [-1, 256, 56, 56]         590,080
ReLU-14          [-1, 256, 56, 56]               0
Conv2d-15          [-1, 256, 56, 56]         590,080
ReLU-16          [-1, 256, 56, 56]               0
MaxPool2d-17          [-1, 256, 28, 28]               0
Conv2d-18          [-1, 512, 28, 28]       1,180,160
ReLU-19          [-1, 512, 28, 28]               0
Conv2d-20          [-1, 512, 28, 28]       2,359,808
ReLU-21          [-1, 512, 28, 28]               0
Conv2d-22          [-1, 512, 28, 28]       2,359,808
ReLU-23          [-1, 512, 28, 28]               0
MaxPool2d-24          [-1, 512, 14, 14]               0
Conv2d-25          [-1, 512, 14, 14]       2,359,808
ReLU-26          [-1, 512, 14, 14]               0
Conv2d-27          [-1, 512, 14, 14]       2,359,808
ReLU-28          [-1, 512, 14, 14]               0
Conv2d-29          [-1, 512, 14, 14]       2,359,808
ReLU-30          [-1, 512, 14, 14]               0
MaxPool2d-31            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0
Linear-33                 [-1, 4096]     102,764,544
ReLU-34                 [-1, 4096]               0
Dropout-35                 [-1, 4096]               0
Linear-36                 [-1, 4096]      16,781,312
ReLU-37                 [-1, 4096]               0
Dropout-38                 [-1, 4096]               0
Linear-39                 [-1, 1000]       4,097,000
================================================================
Total params: 138,357,544
Trainable params: 138,357,544
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 218.78
Params size (MB): 527.79
Estimated Total Size (MB): 747.15
----------------------------------------------------------------
None</p>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="4"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk7">MINI_BATCH_SIZE</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">256</span><span class="mtk1"> </span><span class="mtk5 mtki"># numbers of images in a mini-batch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk7">VALID_BATCH_SIZE</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">64</span><span class="mtk1"> </span><span class="mtk5 mtki"># numbers of images in a mini-batch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk7">LEARNING_RATE</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">1e-4</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk7">EPOCHS</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">100</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk7">RESOLUTION</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> (</span><span class="mtk7">224</span><span class="mtk1">, </span><span class="mtk7">224</span><span class="mtk1">)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="5"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># import dataset structuring and image transformation modules</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> torchvision.datasets </span><span class="mtk10 mtki">import</span><span class="mtk1"> ImageFolder </span><span class="mtk5 mtki"># Load dataset</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> torchvision </span><span class="mtk10 mtki">import</span><span class="mtk1"> transforms</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk7">DATA_PATH</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk6">&quot;imagenette2-320&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">imagenet_transforms </span><span class="mtk8">=</span><span class="mtk1"> transforms.</span><span class="mtk3">Compose</span><span class="mtk1">([</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    transforms.</span><span class="mtk3">Resize</span><span class="mtk1">(</span><span class="mtk7">RESOLUTION</span><span class="mtk1">),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    transforms.</span><span class="mtk3">ToTensor</span><span class="mtk1">(),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    transforms.</span><span class="mtk3">Normalize</span><span class="mtk1">(</span><span class="mtk4 mtki">mean</span><span class="mtk8">=</span><span class="mtk1">[</span><span class="mtk7">0.485</span><span class="mtk1">, </span><span class="mtk7">0.456</span><span class="mtk1">, </span><span class="mtk7">0.406</span><span class="mtk1">], </span><span class="mtk4 mtki">std</span><span class="mtk8">=</span><span class="mtk1">[</span><span class="mtk7">0.229</span><span class="mtk1">, </span><span class="mtk7">0.224</span><span class="mtk1">, </span><span class="mtk7">0.225</span><span class="mtk1">])</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">])</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_data </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">ImageFolder</span><span class="mtk1">(</span><span class="mtk4 mtki">root</span><span class="mtk8">=</span><span class="mtk10">f</span><span class="mtk6">&#39;./</span><span class="mtk7">{DATA_PATH}</span><span class="mtk6">/train&#39;</span><span class="mtk1">, </span><span class="mtk4 mtki">transform</span><span class="mtk8">=</span><span class="mtk1">imagenet_transforms)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;number of training data: &#39;</span><span class="mtk1">, </span><span class="mtk8">len</span><span class="mtk1">(train_data))</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="6"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">number of training data:  9469</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="7"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">valid_data </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">ImageFolder</span><span class="mtk1">(</span><span class="mtk4 mtki">root</span><span class="mtk8">=</span><span class="mtk10">f</span><span class="mtk6">&#39;./</span><span class="mtk7">{DATA_PATH}</span><span class="mtk6">/val&#39;</span><span class="mtk1">, </span><span class="mtk4 mtki">transform</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> imagenet_transforms)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;number of test data: &#39;</span><span class="mtk1">, </span><span class="mtk8">len</span><span class="mtk1">(valid_data))</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="8"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">number of test data:  3925</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="9"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">sample_idx </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">1001</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">sample_img, sample_label </span><span class="mtk8">=</span><span class="mtk1"> train_data[sample_idx]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;sample image shape: &#39;</span><span class="mtk1">, sample_img.</span><span class="mtk3">size</span><span class="mtk1">())</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;sample image label: &#39;</span><span class="mtk1">, sample_label)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="10"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">sample image shape:  torch.Size([3, 224, 224])</span></span>
<span class="grvsc-line"><span class="grvsc-source">sample image label:  1</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="11"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> matplotlib </span><span class="mtk10 mtki">import</span><span class="mtk1"> pyplot </span><span class="mtk10 mtki">as</span><span class="mtk1"> plt</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># show image from training data</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">plt.</span><span class="mtk3">imshow</span><span class="mtk1">(sample_img.</span><span class="mtk3">numpy</span><span class="mtk1">().</span><span class="mtk3">transpose</span><span class="mtk1">(</span><span class="mtk7">1</span><span class="mtk1">,</span><span class="mtk7">2</span><span class="mtk1">,</span><span class="mtk7">0</span><span class="mtk1">))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">plt.</span><span class="mtk3">title</span><span class="mtk1">(</span><span class="mtk10">f</span><span class="mtk6">&#39;label is </span><span class="mtk7">{</span><span class="mtk1">sample_label</span><span class="mtk7">}</span><span class="mtk6">&#39;</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">plt.</span><span class="mtk3">show</span><span class="mtk1">()</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="12"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).</span></span></code></pre>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 257px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 102.7237354085603%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFW0lEQVQ4y0WVeUxUVxSHz9tmH2DYZpxBGPZVhhnKIhVlZBAQi4oLAgFsQXFBLEZrrdZYSVxSaaUmbkgiBUvrvktLq0ldusbqn7VNW1pbWyVGCMwMznBP79zB9ibnnfPuu/d7v3PeuXkAdEzJ04H1YhKYTtgg8iIPmV8kQUyXFUzbZL7HCmomagHUfBNCm6cX9uJaKLmvgdrrtdD0fQ7UD2RC8icG33qQgi2BEZbuVLvxkMUR8aFYmH46zhH1rsURtU9pt+yOqgqrD1sf/rr0auyWyCrb8fzFbe7js1v/qnTYr6od5cdfcSy7YClc3JdenNQZEQzyDfSVxZCbeD1yIuNeGZpvxWDM7WhMvJGClv4UDO0KxPhLUd78B3FY/EcVJhyowIzaY1h68BqmHm3Akl9LsOZxIc67G4+GUzCHClQFqStghnVA50z91ojGrw0T+v5oEnYlnOTdiydpl7NIRNc01PVoMH3vHAIQT81IZpX3EUnZTjT1dmLqM3gCP5Ihvx8cFGjnuDbInDYQ5NKfl6F8P0wEHuQI1PMkoEtLEu4kkcSbcUTKV1AQT3gOqAeyZPUlYoyppnEQgRjRA2sApRquCFixG/hC6STvFPo4jO9QkPRdKtSuDMfk0yloPRuPUiUgL3BI1yIvCswvrNuJ0WmLfDHhgPdCHiBXC0UwFSNBWCJkyTo5p7JXjrMGY4l+ZwDOPJOPzbeqsPOHDgS1jEGApwZ+sC50KsplCuSAKfbyNgHFLTxTGASJkA8rwMlv5TH0lJrEn4vDqP4IXHp3Bm4/VuFXxvlBwCmZ5yQd9UwtAwrZEspr1EWg3qEFyS6zSjNFN1fOodDIEfU7KpT2hWNiTzYWNub5Afxkyhwwv6ejD1e17mJAHjgvBNK9xXKmMFowQIG8VO+UWuVYeKOaVLSvwRBrKnK6BJRUZr+yyVR5XsQVm3uxZ2AML9wZQnNCGlMoRggYsFFWBGW4CUQQbFAB7vL+Wpy7qIFIoJiE+I2jqkSRZ/G8eYuwt/sKisaVOL3kPZy/YKkfaOFRuUcqAg4kM61ijmq+yZ1ZuOFFTegHoIo4niryQX0wf+3OX/oOW6paWWyOzsWq2q0MGLtAi0n7VL6U1RwFWukJdLONrM+4/5T5fEFJEza1tGFNUwuWLOvC2aU72XxYRDY2busj+iS911adimAEVsMYannUXJMA8n+6gRiX6sCHT56jbzx1TeCqd3oxxJyDSm0A5tjtWLpuOcltTPHmrQvB5LV+IBXEZdCrexJEeN7fvPbi13B4FNEzQXDwyTgOO5/j4IgL3z93A7/66Qnef3AZGzYYyexKnbfmDROu3JHLgCZB0uSqAk3uyVQJL/iBZQtrmDL3uAcpk41Hwx7824n4cBjx2cPreKQ7h7x99GVve89cbDu0yQdU8RwPNm2YwaUJZS0yIQgCO6/rN+/1YYjX6yWPn42x+Ld/RsjvQy4WbzuxheRsNJDKWwWe+vsJWHc7nymM08zi7epMcMnUISgq5KyGQcF6/PPREFM1NDaKTq+HxSOjY/hgcBQP//wxBp+KQtOhEAzo0ExEnlVh9k169KLm5IB1TWWaYlqAGyTauEqRqaxb/RZLcsw1jiPjY96DX3aTk9eu4Tc/PiWHz3zuDV1mRnG7gPL1AlE3B7jNHelo6IwrgtS8hRCTURCmnqrPAi2k8RoxmQKLquqWT7/66WfJ+z84YG1Z11ymtOlyIUSV3Ly9PXt6YcFcusbGJfEpQoKYReNy5UzVS5UX31TD5FD+glSYhnaiSgSFUqH1/TuOdHYC+uYBwqiJEKJ5cR/KdsWyqyAAbwjqmgIzd1fDv8uVfsXn1i89AAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="output_8_1"
        title="output_8_1"
        src="/static/af4e3cb524c3d3840498a3d4e936c8b7/96e35/output_8_1.png"
        srcset="/static/af4e3cb524c3d3840498a3d4e936c8b7/96e35/output_8_1.png 257w"
        sizes="(max-width: 257px) 100vw, 257px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="13"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># using torch dataloader to divide dataset into mini-batch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># https://pytorch.org/docs/stable/data.html</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">train_loader </span><span class="mtk8">=</span><span class="mtk1"> torch.utils.data.</span><span class="mtk3">DataLoader</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk4 mtki">dataset</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> train_data, </span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk4 mtki">batch_size</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">MINI_BATCH_SIZE</span><span class="mtk1">, </span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk4 mtki">shuffle</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">True</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">eval_loader  </span><span class="mtk8">=</span><span class="mtk1"> torch.utils.data.</span><span class="mtk3">DataLoader</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk4 mtki">dataset</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> valid_data, </span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk4 mtki">batch_size</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">VALID_BATCH_SIZE</span><span class="mtk1">, </span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk4 mtki">shuffle</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">True</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">first_batch </span><span class="mtk8">=</span><span class="mtk1"> train_loader.</span><span class="mtk8">__iter__</span><span class="mtk1">().</span><span class="mtk8">__next__</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;</span><span class="mtk7">{</span><span class="mtk10">:&lt;21s</span><span class="mtk7">}</span><span class="mtk6"> | </span><span class="mtk7">{</span><span class="mtk10">:&lt;25s</span><span class="mtk7">}</span><span class="mtk6"> | </span><span class="mtk7">{}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(</span><span class="mtk6">&#39;name&#39;</span><span class="mtk1">, </span><span class="mtk6">&#39;type&#39;</span><span class="mtk1">, </span><span class="mtk6">&#39;size&#39;</span><span class="mtk1">))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;</span><span class="mtk7">{</span><span class="mtk10">:&lt;21s</span><span class="mtk7">}</span><span class="mtk6"> | </span><span class="mtk7">{</span><span class="mtk10">:&lt;25s</span><span class="mtk7">}</span><span class="mtk6"> | </span><span class="mtk7">{}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(</span><span class="mtk6">&#39;Number of Mini-Batchs&#39;</span><span class="mtk1">, </span><span class="mtk6">&#39;&#39;</span><span class="mtk1">, </span><span class="mtk8">len</span><span class="mtk1">(train_loader)))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;</span><span class="mtk7">{</span><span class="mtk10">:&lt;21s</span><span class="mtk7">}</span><span class="mtk6"> | </span><span class="mtk7">{</span><span class="mtk10">:&lt;25s</span><span class="mtk7">}</span><span class="mtk6"> | </span><span class="mtk7">{}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(</span><span class="mtk6">&#39;first_batch&#39;</span><span class="mtk1">, </span><span class="mtk8">str</span><span class="mtk1">(</span><span class="mtk8">type</span><span class="mtk1">(first_batch)), </span><span class="mtk8">len</span><span class="mtk1">(first_batch)))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;</span><span class="mtk7">{</span><span class="mtk10">:&lt;21s</span><span class="mtk7">}</span><span class="mtk6"> | </span><span class="mtk7">{</span><span class="mtk10">:&lt;25s</span><span class="mtk7">}</span><span class="mtk6"> | </span><span class="mtk7">{}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(</span><span class="mtk6">&#39;first_batch[0]&#39;</span><span class="mtk1">, </span><span class="mtk8">str</span><span class="mtk1">(</span><span class="mtk8">type</span><span class="mtk1">(first_batch[</span><span class="mtk7">0</span><span class="mtk1">])), first_batch[</span><span class="mtk7">0</span><span class="mtk1">].shape))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;</span><span class="mtk7">{</span><span class="mtk10">:&lt;21s</span><span class="mtk7">}</span><span class="mtk6"> | </span><span class="mtk7">{</span><span class="mtk10">:&lt;25s</span><span class="mtk7">}</span><span class="mtk6"> | </span><span class="mtk7">{}</span><span class="mtk6">&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(</span><span class="mtk6">&#39;first_batch[1]&#39;</span><span class="mtk1">, </span><span class="mtk8">str</span><span class="mtk1">(</span><span class="mtk8">type</span><span class="mtk1">(first_batch[</span><span class="mtk7">1</span><span class="mtk1">])), first_batch[</span><span class="mtk7">1</span><span class="mtk1">].shape))</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="14"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">name                  | type                      | size</span></span>
<span class="grvsc-line"><span class="grvsc-source">Number of Mini-Batchs |                           | 37</span></span>
<span class="grvsc-line"><span class="grvsc-source">first_batch           | &lt;class &#39;list&#39;&gt;            | 2</span></span>
<span class="grvsc-line"><span class="grvsc-source">first_batch[0]        | &lt;class &#39;torch.Tensor&#39;&gt;    | torch.Size([256, 3, 224, 224])</span></span>
<span class="grvsc-line"><span class="grvsc-source">first_batch[1]        | &lt;class &#39;torch.Tensor&#39;&gt;    | torch.Size([256])</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="15"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># bring optimizers from torch</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">import</span><span class="mtk1"> torch.optim </span><span class="mtk10 mtki">as</span><span class="mtk1"> optim</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Hyperparameter Setting</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model </span><span class="mtk8">=</span><span class="mtk1"> custom_vgg_model.</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Defining optimizer</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">optimizer </span><span class="mtk8">=</span><span class="mtk1"> optim.</span><span class="mtk3">Adam</span><span class="mtk1">(model.</span><span class="mtk3">parameters</span><span class="mtk1">(), </span><span class="mtk4 mtki">lr</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">LEARNING_RATE</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Using Cross entropy loss function</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">criterion </span><span class="mtk8">=</span><span class="mtk1"> nn.</span><span class="mtk3">CrossEntropyLoss</span><span class="mtk1">()</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="16"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Print model&#39;s architecture</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(model)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="17"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">VGG16(</span></span>
<span class="grvsc-line"><span class="grvsc-source">  (conv1): Sequential(</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (1): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (3): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)</span></span>
<span class="grvsc-line"><span class="grvsc-source">  )</span></span>
<span class="grvsc-line"><span class="grvsc-source">  (conv2): Sequential(</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (1): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (3): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)</span></span>
<span class="grvsc-line"><span class="grvsc-source">  )</span></span>
<span class="grvsc-line"><span class="grvsc-source">  (conv3): Sequential(</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (1): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (3): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (5): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)</span></span>
<span class="grvsc-line"><span class="grvsc-source">  )</span></span>
<span class="grvsc-line"><span class="grvsc-source">  (conv4): Sequential(</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (1): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (3): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (5): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)</span></span>
<span class="grvsc-line"><span class="grvsc-source">  )</span></span>
<span class="grvsc-line"><span class="grvsc-source">  (conv5): Sequential(</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (1): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (3): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (5): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)</span></span>
<span class="grvsc-line"><span class="grvsc-source">  )</span></span>
<span class="grvsc-line"><span class="grvsc-source">  (fc_module): Sequential(</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (0): Linear(in_features=25088, out_features=4096, bias=True)</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (1): Dropout(p=0.5, inplace=False)</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (2): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (3): Linear(in_features=4096, out_features=4096, bias=True)</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (4): Dropout(p=0.5, inplace=False)</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (5): ReLU()</span></span>
<span class="grvsc-line"><span class="grvsc-source">    (6): Linear(in_features=4096, out_features=1000, bias=True)</span></span>
<span class="grvsc-line"><span class="grvsc-source">  )</span></span>
<span class="grvsc-line"><span class="grvsc-source">)</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="18"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">from</span><span class="mtk1"> tqdm </span><span class="mtk10 mtki">import</span><span class="mtk1"> tqdm</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">&quot;&quot;&quot; Training the model &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Change the model to training mode</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model.</span><span class="mtk3">train</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># A training step is one gradient update. In one step batch_size many examples are processed.</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># training step = dataset size / mini-batch size</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Updating Gradient in each training steps</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">for</span><span class="mtk1"> epoch </span><span class="mtk10">in</span><span class="mtk1"> </span><span class="mtk8">range</span><span class="mtk1">(</span><span class="mtk7">EPOCHS</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">for</span><span class="mtk1"> training_step, (data, target_tensor) </span><span class="mtk10">in</span><span class="mtk1"> </span><span class="mtk8">enumerate</span><span class="mtk1">(</span><span class="mtk3">tqdm</span><span class="mtk1">(train_loader)): </span><span class="mtk5 mtki"># bringing dataset from train_loader() function</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># data is [Batch Size = 50, Channel Size = 1, Height = 28, Width = 28] tensor</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        data </span><span class="mtk8">=</span><span class="mtk1"> data.</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># Tagets is label [Labels = 50] tensor</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        target_tensor </span><span class="mtk8">=</span><span class="mtk1"> target_tensor.</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># Gradient Descent process</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        optimizer.</span><span class="mtk3">zero_grad</span><span class="mtk1">() </span><span class="mtk5 mtki"># initializing previously saved gradient&#39;s value to zero # https://jaeyung1001.tistory.com/115</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        output </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">model</span><span class="mtk1">(data) </span><span class="mtk5 mtki"># feed forward to get one-hot-encoded output probabilities</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        loss </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">criterion</span><span class="mtk1">(output, target_tensor) </span><span class="mtk5 mtki"># comparing prediction and ground truth to get loss</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        loss.</span><span class="mtk3">backward</span><span class="mtk1">() </span><span class="mtk5 mtki"># backpropagating loss</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        optimizer.</span><span class="mtk3">step</span><span class="mtk1">() </span><span class="mtk5 mtki"># updating weights with single optimization step</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk5 mtki"># print status every 1000 training steps</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk10 mtki">if</span><span class="mtk1"> training_step </span><span class="mtk8">%</span><span class="mtk1"> </span><span class="mtk7">500</span><span class="mtk1"> </span><span class="mtk8">==</span><span class="mtk1"> </span><span class="mtk7">0</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            loss_rounded_to_3 </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk8">round</span><span class="mtk1">(loss.</span><span class="mtk3">item</span><span class="mtk1">() </span><span class="mtk8">*</span><span class="mtk1"> </span><span class="mtk7">1000</span><span class="mtk1">) </span><span class="mtk8">/</span><span class="mtk1"> </span><span class="mtk7">1000</span><span class="mtk1"> </span><span class="mtk5 mtki"># loss is a single value, so we need to round it to 3 digits</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk10">f</span><span class="mtk6">&#39;Train Step: </span><span class="mtk7">{</span><span class="mtk1">training_step</span><span class="mtk7">}</span><span class="mtk6"> </span><span class="mtk8">\t</span><span class="mtk6"> Loss: </span><span class="mtk7">{</span><span class="mtk1">loss_rounded_to_3</span><span class="mtk7">}</span><span class="mtk6">&#39;</span><span class="mtk1">)</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="19"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">  3%|▎         | 1/37 [00:03&lt;01:49,  3.03s/it]</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">Train Step: 0 	 Loss: 6.908</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">100%|██████████| 37/37 [00:56&lt;00:00,  1.53s/it]</span></span>
<span class="grvsc-line"><span class="grvsc-source">  3%|▎         | 1/37 [00:02&lt;01:26,  2.40s/it]</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">Train Step: 0 	 Loss: 6.792</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">100%|██████████| 37/37 [00:53&lt;00:00,  1.46s/it]</span></span>
<span class="grvsc-line"><span class="grvsc-source">  3%|▎         | 1/37 [00:02&lt;01:29,  2.50s/it]</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">Train Step: 0 	 Loss: 6.8</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">100%|██████████| 37/37 [00:53&lt;00:00,  1.45s/it]</span></span>
<span class="grvsc-line"><span class="grvsc-source">  3%|▎         | 1/37 [00:02&lt;01:29,  2.48s/it]</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">Train Step: 0 	 Loss: 6.773</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"> 78%|███████▊  | 29/37 [00:42&lt;00:11,  1.44s/it]</span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="20"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">&quot;&quot;&quot; Evaluating the model &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk5 mtki"># Switching to evaluation mode</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">model.</span><span class="mtk3">eval</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">correct </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">0</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10 mtki">for</span><span class="mtk1"> data, target_labels </span><span class="mtk10">in</span><span class="mtk1"> </span><span class="mtk3">tqdm</span><span class="mtk1">(eval_loader):    </span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># data is [Batch Size = 50, Channel Size = 1, Height = 28, Width = 28] tensor</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    data </span><span class="mtk8">=</span><span class="mtk1"> data.</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># Tagets is label [Labels = 50] tensor</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    target_labels </span><span class="mtk8">=</span><span class="mtk1"> target_labels.</span><span class="mtk3">to</span><span class="mtk1">(device)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># getting predicted output label out of maximum probabilities&#39; output in the tensor</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    output </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">model</span><span class="mtk1">(data)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    predicted_output_labels </span><span class="mtk8">=</span><span class="mtk1"> output.data.</span><span class="mtk3">max</span><span class="mtk1">(</span><span class="mtk7">1</span><span class="mtk1">)[</span><span class="mtk7">1</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk5 mtki"># add numbers of correct predictions</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    correct </span><span class="mtk8">+=</span><span class="mtk1"> predicted_output_labels.</span><span class="mtk3">eq</span><span class="mtk1">(target_labels.data).</span><span class="mtk3">sum</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk8">print</span><span class="mtk1">(</span><span class="mtk6">&#39;Test set: Accuracy: </span><span class="mtk7">{</span><span class="mtk10">:.2f</span><span class="mtk7">}</span><span class="mtk6">%&#39;</span><span class="mtk1">.</span><span class="mtk3">format</span><span class="mtk1">(</span><span class="mtk7">100</span><span class="mtk1">. </span><span class="mtk8">*</span><span class="mtk1"> correct </span><span class="mtk8">/</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(eval_loader.dataset)))</span></span></span></code></pre>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="21"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">100%|██████████| 62/62 [00:21&lt;00:00,  2.84it/s]</span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source">Test set: Accuracy: 9.91%</span></span></code></pre>
<h3 id="references" style="position:relative;"><a href="#references" aria-label="references permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>References</h3>
<p><a href="https://www.geeksforgeeks.org/understanding-googlenet-model-cnn-architecture/">https://www.geeksforgeeks.org/understanding-googlenet-model-cnn-architecture/</a></p>
<style class="grvsc-styles">
  .grvsc-container {
    overflow: auto;
    position: relative;
    -webkit-overflow-scrolling: touch;
    padding-top: 1rem;
    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));
    padding-bottom: 1rem;
    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));
    border-radius: 8px;
    border-radius: var(--grvsc-border-radius, 8px);
    font-feature-settings: normal;
    line-height: 1.4;
  }
  
  .grvsc-code {
    display: table;
  }
  
  .grvsc-line {
    display: table-row;
    box-sizing: border-box;
    width: 100%;
    position: relative;
  }
  
  .grvsc-line > * {
    position: relative;
  }
  
  .grvsc-gutter-pad {
    display: table-cell;
    padding-left: 0.75rem;
    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);
  }
  
  .grvsc-gutter {
    display: table-cell;
    -webkit-user-select: none;
    -moz-user-select: none;
    user-select: none;
  }
  
  .grvsc-gutter::before {
    content: attr(data-content);
  }
  
  .grvsc-source {
    display: table-cell;
    padding-left: 1.5rem;
    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));
    padding-right: 1.5rem;
    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));
  }
  
  .grvsc-source:empty::after {
    content: ' ';
    -webkit-user-select: none;
    -moz-user-select: none;
    user-select: none;
  }
  
  .grvsc-gutter + .grvsc-source {
    padding-left: 0.75rem;
    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);
  }
  
  /* Line transformer styles */
  
  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {
    content: ' ';
    position: absolute;
    width: 100%;
  }
  
  .grvsc-line-diff-add::before {
    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));
  }
  
  .grvsc-line-diff-del::before {
    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));
  }
  
  .grvsc-line-number {
    padding: 0 2px;
    text-align: right;
    opacity: 0.7;
  }
  
  .one-dark-pro {
    background-color: #282c34;
    color: #abb2bf;
  }
  .one-dark-pro .mtki { font-style: italic; }
  .one-dark-pro .mtk5 { color: #7F848E; }
  .one-dark-pro .mtk10 { color: #C678DD; }
  .one-dark-pro .mtk1 { color: #ABB2BF; }
  .one-dark-pro .mtk11 { color: #E5C07B; }
  .one-dark-pro .mtk8 { color: #56B6C2; }
  .one-dark-pro .mtk7 { color: #D19A66; }
  .one-dark-pro .mtk6 { color: #98C379; }
  .one-dark-pro .mtk3 { color: #61AFEF; }
  .one-dark-pro .mtk4 { color: #E06C75; }
  .one-dark-pro .grvsc-line-highlighted::before {
    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));
    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));
  }
</style></div></div></div></div><div class="css-1bdwg0l eyldt480"><div><style data-emotion-css="17t5ffy">.css-17t5ffy{margin-top:1rem;margin-bottom:1rem;}</style><div class="css-17t5ffy"><div class="css-1l4w6pd"><div class="css-yapsbb"></div></div></div><style data-emotion-css="i1cgbm">.css-i1cgbm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;margin-top:1rem;padding-left:0.5rem;padding-right:0.5rem;}</style><div class="css-i1cgbm"><style data-emotion-css="9nr5sz">.css-9nr5sz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;margin-left:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#1CA1F2;}</style><button class="css-9nr5sz"><style data-emotion-css="u7tj59">.css-u7tj59{fill:currentColor;margin-top:auto;margin-bottom:auto;margin-right:0.25rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-u7tj59" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>Share with <!-- -->Twitter</button><style data-emotion-css="rk0yc0">.css-rk0yc0{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;margin-left:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#6E7783;}</style><button class="css-rk0yc0"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-u7tj59" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg>Share with <!-- -->URL</button></div></div></div></div></div><div class="css-1bdwg0l eyldt480"><style data-emotion-css="17t1oy1">.css-17t1oy1{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap-reverse;-ms-flex-wrap:wrap-reverse;flex-wrap:wrap-reverse;margin-left:0.5rem;margin-right:0.5rem;margin-top:1rem;}@media (min-width:768px){.css-17t1oy1{-webkit-flex-wrap:nowrap;-ms-flex-wrap:nowrap;flex-wrap:nowrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}}</style><div class="css-17t1oy1 e816y8n0"><style data-emotion-css="1pwr1ry">.css-1pwr1ry{width:100%;margin:0.5rem;}@media (min-width:768px){.css-1pwr1ry{width:50%;margin:1rem;}}</style><div class="css-1pwr1ry e816y8n1"><style data-emotion-css="vl2eok">.css-vl2eok{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);text-align:left;width:100%;height:100%;padding:0.5rem;background-color:#eee;border-radius:0.25rem;border-left-width:4px;border-color:#86a8e7;}.css-vl2eok:hover{background-color:#ddd;}</style><a rel="prev" class="css-vl2eok" href="/Researching/Python-language-structure/"><style data-emotion-css="19o7xeo">.css-19o7xeo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;margin-right:1rem;margin-left:0.5rem;height:100%;}</style><div class="css-19o7xeo"><style data-emotion-css="11za1ik">.css-11za1ik{width:2rem;height:2rem;margin-top:auto;margin-bottom:auto;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-11za1ik" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M872 474H286.9l350.2-304c5.6-4.9 2.2-14-5.2-14h-88.5c-3.9 0-7.6 1.4-10.5 3.9L155 487.8a31.96 31.96 0 0 0 0 48.3L535.1 866c1.5 1.3 3.3 2 5.2 2h91.5c7.4 0 10.8-9.2 5.2-14L286.9 550H872c4.4 0 8-3.6 8-8v-60c0-4.4-3.6-8-8-8z"></path></svg></div><style data-emotion-css="v38or">.css-v38or{display:inline-block;margin-top:0.5rem;margin-bottom:0.5rem;}</style><div class="css-v38or"><style data-emotion-css="2m7hin">.css-2m7hin{color:#3737B9;}</style><p class="css-2m7hin">Previous Post</p><p>Python Language Structure</p></div></a></div><div class="css-1pwr1ry e816y8n1"></div></div><style data-emotion-css="14yohw7">.css-14yohw7{width:100%;max-width:768px;padding-left:1rem;padding-right:1rem;margin-left:auto;margin-right:auto;padding-top:2rem;margin-top:0.5rem;margin-bottom:1rem;}@media (min-width:768px){.css-14yohw7{padding-left:0;padding-right:0;padding-top:3rem;}}</style><div class="css-14yohw7 e16bs3iv0"><style data-emotion-css="180ky7f">.css-180ky7f{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:0.5rem;padding-right:0.5rem;}@media (min-width:768px){.css-180ky7f{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}</style><div class="css-180ky7f e16bs3iv1"><style data-emotion-css="p5b1u1">.css-p5b1u1{border-radius:9999px;border-width:1px;--border-opacity:1;border-color:rgba(214,188,250,var(--border-opacity));margin-right:2rem;margin-bottom:0.5rem;}@media (min-width:768px){.css-p5b1u1{margin-bottom:1rem;}}</style><div class="css-p5b1u1 gatsby-image-wrapper" style="position:relative;overflow:hidden;display:inline-block;width:128px;height:128px"><img aria-hidden="true" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAQBBf/EABYBAQEBAAAAAAAAAAAAAAAAAAECA//aAAwDAQACEAMQAAABynZIqtSk4c5qdwD/AP/EABgQAAMBAQAAAAAAAAAAAAAAAAABAgMR/9oACAEBAAEFApTIkuNHXZgjWK2bZvTM6b1P/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAEQEf/aAAgBAwEBPwFiK//EABURAQEAAAAAAAAAAAAAAAAAAAEg/9oACAECAQE/ASP/xAAdEAACAQQDAAAAAAAAAAAAAAAAASECEBFRIjGB/9oACAEBAAY/AvCZ2QoMsw5TOJ2Up7t//8QAHRAAAgICAwEAAAAAAAAAAAAAAAERIUFhMVFxkf/aAAgBAQABPyGQ1UIIVo1dtoaHoXgWF10MklGMEvhCEYta+DAJgvw//9oADAMBAAIAAwAAABBYODz/xAAYEQEBAQEBAAAAAAAAAAAAAAABABEhQf/aAAgBAwEBPxB279ksrt//xAAXEQEBAQEAAAAAAAAAAAAAAAABABAx/9oACAECAQE/EI9kM//EAB4QAQEAAgICAwAAAAAAAAAAAAERACFRYTFBoeHw/9oACAEBAAE/ENiSENW+VTiZpVWrCLvvKMeEnTGARaXZevjBBRTTtdPnjWuccCRSa1+JjqKA/TCoCwoW324ixDPbn//Z" alt="profileImg" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/584d7a912ca03da16698aea724815677/6dc0c/profile.jpg 1x,
/static/584d7a912ca03da16698aea724815677/cc017/profile.jpg 1.5x,
/static/584d7a912ca03da16698aea724815677/0c30b/profile.jpg 2x" /><img loading="lazy" width="128" height="128" srcset="/static/584d7a912ca03da16698aea724815677/6dc0c/profile.jpg 1x,
/static/584d7a912ca03da16698aea724815677/cc017/profile.jpg 1.5x,
/static/584d7a912ca03da16698aea724815677/0c30b/profile.jpg 2x" src="/static/584d7a912ca03da16698aea724815677/6dc0c/profile.jpg" alt="profileImg" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div><div><span>Written by </span><style data-emotion-css="1t4jyca">.css-1t4jyca{display:inline-block;font-size:1.25rem;font-weight:700;border-radius:9999px;margin-bottom:0.5rem;padding-left:0.75rem;padding-right:0.75rem;--bg-opacity:1;background-color:rgba(237,242,247,var(--bg-opacity));color:#3737B9;}</style><p class="css-1t4jyca"><a class="author-name-content" href="/about"><span>@<!-- -->Young Jin Ahn</span></a></p><style data-emotion-css="vg2p6i">.css-vg2p6i{font-size:0.875rem;font-weight:400;margin-bottom:0.5rem;}</style><div class="css-vg2p6i">break, compose, display</div></div></div><style data-emotion-css="1air669">.css-1air669{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-left:0.5rem;margin-right:0.5rem;}</style><div class="css-1air669"><div class="css-yapsbb"></div></div><style data-emotion-css="1baulvz">.css-1baulvz{display:inline-block;}</style><a title="github Link" href="https://github.com/snoop2head" class="css-1baulvz"><style data-emotion-css="vnd1fq">.css-vnd1fq{width:2rem;height:2rem;margin-top:1rem;margin-left:1rem;-webkit-transition:all 300ms cubic-bezier(0,0,0.2,1);transition:all 300ms cubic-bezier(0,0,0.2,1);color:#888;}.css-vnd1fq:hover{color:#000;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="css-vnd1fq" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="facebook Link" href="https://www.facebook.com/profile.php?id=100009133042568" class="css-1baulvz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-vnd1fq" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"></path></svg></a></div><style data-emotion-css="18jj1tc">.css-18jj1tc{margin-top:1.25rem;margin-left:0.5rem;margin-right:0.5rem;}</style><div class="css-18jj1tc"><div class="utterances"></div></div></div></div><style data-emotion-css="xgi74q">.css-xgi74q{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:fixed;bottom:0;right:0;padding-right:1.5rem;padding-bottom:1.5rem;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}</style><div class="css-xgi74q e8huvi00"><style data-emotion-css="1a68u">.css-1a68u{box-shadow:0 2px 2px 0 rgba(0,0,0,0.15);-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#636363;font-size:0.75rem;padding-left:0.5rem;padding-right:0.5rem;padding-top:0.5rem;padding-bottom:0.5rem;border-radius:9999px;--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;-webkit-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));-ms-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-content:flex-end;-ms-flex-line-pack:end;align-content:flex-end;z-index:100;}.css-1a68u:hover{background-color:#404040;color:#FFFFFF;}.css-1a68u:hover{--transform-scale-x:1.05;--transform-scale-y:1.05;}</style><button title="change to darkmode" class="css-1a68u"><style data-emotion-css="1alqh2e">.css-1alqh2e{fill:currentColor;--text-opacity:1;color:rgba(246,224,94,var(--text-opacity));width:1rem;height:1rem;margin-top:auto;margin-bottom:auto;margin-left:0;margin-right:0;}@media (min-width:768px){.css-1alqh2e{display:inline-block;margin-left:0.25rem;margin-right:0.25rem;}}</style><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="css-1alqh2e" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg><style data-emotion-css="flxr9x">.css-flxr9x{display:none;margin-right:0;}@media (min-width:768px){.css-flxr9x{display:inline-block;margin-right:0.25rem;}}</style><span class="css-flxr9x">Use Dark Mode</span></button><style data-emotion-css="15afv4q">.css-15afv4q{box-shadow:0 2px 2px 0 rgba(0,0,0,0.15);-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#636363;font-size:0.75rem;padding-left:0.5rem;padding-right:0.5rem;padding-top:0.5rem;padding-bottom:0.5rem;border-radius:9999px;--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;-webkit-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));-ms-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));cursor:pointer;margin-left:0.5rem;margin-top:auto;margin-bottom:auto;z-index:100;}.css-15afv4q:hover{background-color:#404040;color:#FFFFFF;}.css-15afv4q:hover{--transform-scale-x:1.05;--transform-scale-y:1.05;}</style><button title="top page" class="css-15afv4q"><style data-emotion-css="13htjwu">.css-13htjwu{width:1rem;height:1rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-13htjwu" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M868 545.5L536.1 163a31.96 31.96 0 0 0-48.3 0L156 545.5a7.97 7.97 0 0 0 6 13.2h81c4.6 0 9-2 12.1-5.5L474 300.9V864c0 4.4 3.6 8 8 8h60c4.4 0 8-3.6 8-8V300.9l218.9 252.3c3 3.5 7.4 5.5 12.1 5.5h81c6.8 0 10.5-8 6-13.2z"></path></svg></button></div><style data-emotion-css="1k8xcyw">.css-1k8xcyw{text-align:center;padding-top:2rem;padding-bottom:2rem;bottom:0;}</style><footer class="css-1k8xcyw"><style data-emotion-css="1xju3od">.css-1xju3od{font-size:0.75rem;font-weight:700;}</style><a href="https://github.com/snoop2head" class="css-1xju3od">©snoop2head</a></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-186254784-2', 'auto', {});
      
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/Researching/Friendly-VGG-Implementation/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-efbe87ab08854460e1b4.js"],"app":["/app-6b37a0275bc86b56e034.js"],"component---src-pages-404-js":["/component---src-pages-404-js-23314e5a1122284127b1.js"],"component---src-pages-about-js":["/component---src-pages-about-js-78029fb8e6dade72d83f.js"],"component---src-pages-index-js":["/component---src-pages-index-js-81659046284b3feb90f5.js"],"component---src-pages-search-js":["/component---src-pages-search-js-6bfc09fa0dcf8ea3b63d.js"],"component---src-templates-blog-post-js":["/component---src-templates-blog-post-js-5f317a7779dd1baa19f9.js"],"component---src-templates-category-js":["/component---src-templates-category-js-5fbfac713624a9c1ac35.js"]};/*]]>*/</script><script src="/polyfill-efbe87ab08854460e1b4.js" nomodule=""></script><script src="/component---src-templates-blog-post-js-5f317a7779dd1baa19f9.js" async=""></script><script src="/7a297f752dcfe258c0b0106d89edb3a916af916e-d921dc7587d10ed55da7.js" async=""></script><script src="/b1bda0e5b3305dd279ac60c39e10b0f82af56c10-cca622a04473b7e5e8b2.js" async=""></script><script src="/commons-33df4d3f9aa201d0ec4c.js" async=""></script><script src="/1bfc9850-103202d7f810115a42e7.js" async=""></script><script src="/5e2a4920-da90abce4a08c86a094c.js" async=""></script><script src="/d7eeaac4-dcbe97e7a5aa158c9d08.js" async=""></script><script src="/app-6b37a0275bc86b56e034.js" async=""></script><script src="/dc6a8720040df98778fe970bf6c000a41750d3ae-4121d07143daec1f6e61.js" async=""></script><script src="/styles-e8fd4555a67a3390b64e.js" async=""></script><script src="/framework-c8d3a5345e3f321d7da5.js" async=""></script><script src="/webpack-runtime-2d2e6eca74f66222a671.js" async=""></script></body></html>