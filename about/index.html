<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=0"/><style data-href="/styles.d53766664f3eaba3db40.css" id="gatsby-global-css">/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden],template{display:none}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}button{background-color:transparent;background-image:none}button:focus{outline:1px dotted;outline:5px auto -webkit-focus-ring-color}fieldset,ol,ul{margin:0;padding:0}ol,ul{list-style:none}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;line-height:1.5}*,:after,:before{box-sizing:border-box;border:0 solid #e2e8f0}hr{border-top-width:1px}img{border-style:solid}textarea{resize:vertical}input::-webkit-input-placeholder,textarea::-webkit-input-placeholder{color:#a0aec0}input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#a0aec0}input::placeholder,textarea::placeholder{color:#a0aec0}[role=button],button{cursor:pointer}table{border-collapse:collapse}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit}code,kbd,pre,samp{font-family:Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}</style><meta name="generator" content="Gatsby 2.32.13"/><style type="text/css">
    .toc-header.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .toc-header.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .toc-header svg,
    h2 .toc-header svg,
    h3 .toc-header svg,
    h4 .toc-header svg,
    h5 .toc-header svg,
    h6 .toc-header svg {
      visibility: hidden;
    }
    h1:hover .toc-header svg,
    h2:hover .toc-header svg,
    h3:hover .toc-header svg,
    h4:hover .toc-header svg,
    h5:hover .toc-header svg,
    h6:hover .toc-header svg,
    h1 .toc-header:focus svg,
    h2 .toc-header:focus svg,
    h3 .toc-header:focus svg,
    h4 .toc-header:focus svg,
    h5 .toc-header:focus svg,
    h6 .toc-header:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="preconnect" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><link rel="icon" href="/favicon-32x32-1c5857f550ca5d27138682501fbd1e0a.png" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><meta name="theme-color" content="#3F4145"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><title data-react-helmet="true"></title><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link as="script" rel="preload" href="/webpack-runtime-a15e1610686fb2064048.js"/><link as="script" rel="preload" href="/framework-c8d3a5345e3f321d7da5.js"/><link as="script" rel="preload" href="/styles-e8fd4555a67a3390b64e.js"/><link as="script" rel="preload" href="/dc6a8720040df98778fe970bf6c000a41750d3ae-4121d07143daec1f6e61.js"/><link as="script" rel="preload" href="/app-6b37a0275bc86b56e034.js"/><link as="script" rel="preload" href="/d7eeaac4-dcbe97e7a5aa158c9d08.js"/><link as="script" rel="preload" href="/5e2a4920-da90abce4a08c86a094c.js"/><link as="script" rel="preload" href="/commons-33df4d3f9aa201d0ec4c.js"/><link as="script" rel="preload" href="/component---src-pages-about-js-3c0cba9242c81692c359.js"/><link as="fetch" rel="preload" href="/page-data/about/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><noscript><style data-emotion-css="1vyo7ug">.css-1vyo7ug{position:fixed;bottom:0;left:0;margin-left:0.5rem;margin-bottom:0.5rem;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;box-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px 0 rgba(0,0,0,0.06);-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));font-size:0.875rem;font-weight:700;padding-left:1rem;padding-right:1rem;padding-top:0.75rem;padding-bottom:0.75rem;background-color:#86a8e7;z-index:9999;}</style><div class="css-1vyo7ug"><style data-emotion-css="5x4yj0">.css-5x4yj0{fill:currentColor;width:1.5rem;height:1.5rem;margin-right:0.5rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 192 512" class="css-5x4yj0" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M20 424.229h20V279.771H20c-11.046 0-20-8.954-20-20V212c0-11.046 8.954-20 20-20h112c11.046 0 20 8.954 20 20v212.229h20c11.046 0 20 8.954 20 20V492c0 11.046-8.954 20-20 20H20c-11.046 0-20-8.954-20-20v-47.771c0-11.046 8.954-20 20-20zM96 0C56.235 0 24 32.235 24 72s32.235 72 72 72 72-32.235 72-72S135.764 0 96 0z"></path></svg><style data-emotion-css="1f2k2gl">.css-1f2k2gl{margin-left:0.5rem;}</style><div class="css-1f2k2gl">Please enable JavaScript to use this site.<br/>JavaScript를 활성화 시켜주세요.</div></div></noscript><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><style data-emotion-css="f6s0ma">.css-f6s0ma{-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#333333;}</style><style data-emotion-css="acifd">.css-acifd{min-height:100vh;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#333333;}</style><div class="css-acifd e60ayux0"><style data-emotion-css="8ezs2g">.css-8ezs2g{min-height:calc(100vh - 100px);}</style><div class="css-8ezs2g"><style data-emotion-css="1yxw6gp">.css-1yxw6gp{background:linear-gradient( 90deg,#7f7fd5,#86a8e7 );}</style><div class="css-1yxw6gp"><style data-emotion-css="1mqm4zt">.css-1mqm4zt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;max-width:1280px;margin-left:auto;margin-right:auto;padding:1.25rem;}</style><nav class="css-1mqm4zt e1czdvww0"><style data-emotion-css="1usmgm5">.css-1usmgm5{font-size:1.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));font-weight:700;}</style><a class="css-1usmgm5" href="/">Young Jin Ahn&#x27;s Blog</a><a aria-label="search page" href="/search"><style data-emotion-css="47445j">.css-47445j{--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));margin-top:auto;margin-bottom:auto;width:2rem;height:2rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-47445j" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0 0 11.6 0l43.6-43.5a8.2 8.2 0 0 0 0-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></a></nav></div><style data-emotion-css="aod07n">.css-aod07n{background:linear-gradient( 90deg,#7f7fd5,#86a8e7 );position:fixed;width:100%;box-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px 0 rgba(0,0,0,0.06);z-index:100;-webkit-transition:all 300ms cubic-bezier(0,0,0.2,1);transition:all 300ms cubic-bezier(0,0,0.2,1);top:-100px;}</style><div class="css-aod07n"><nav class="css-1mqm4zt e1czdvww0"><a class="css-1usmgm5" href="/">Young Jin Ahn&#x27;s Blog</a><a aria-label="search page" href="/search"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-47445j" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0 0 11.6 0l43.6-43.5a8.2 8.2 0 0 0 0-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></a></nav></div><style data-emotion-css="w27u98">.css-w27u98{margin-top:1rem;padding-left:1rem;padding-right:1rem;}</style><div class="blog-post-container css-w27u98"><div class="blog-post"><style data-emotion-css="1bdwg0l">.css-1bdwg0l{width:100%;max-width:768px;margin-left:auto;margin-right:auto;}</style><div class="css-1bdwg0l enx0fvl0"><style data-emotion-css="1abxlfd">.css-1abxlfd{font-size:2.25rem;font-weight:700;margin-bottom:1rem;}@media (min-width:768px){.css-1abxlfd{font-size:3rem;}}</style><h1 class="blog-title css-1abxlfd">Portfolio</h1><style data-emotion-css="cpn9zx">.css-cpn9zx{font-size:1rem;margin-bottom:1rem;}</style><h2 class="blog-date css-cpn9zx">September 25th 2022</h2><style data-emotion-css="1l4w6pd">.css-1l4w6pd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}</style><div class="css-1l4w6pd"><style data-emotion-css="yapsbb">.css-yapsbb{border-radius:9999px;width:100%;height:1px;--bg-opacity:1;background-color:rgba(247,250,252,var(--bg-opacity));background:linear-gradient( 270deg,#7f7fd5,#86a8e7,#91eac9 );}</style><div class="css-yapsbb"></div></div></div></div></div><div class="blog-content css-w27u98"><div class="css-1bdwg0l enx0fvl0"><div><style data-emotion-css="c0q8g3">.css-c0q8g3{font-size:1rem;word-break:break-word;}.css-c0q8g3 h1 > a > svg,.css-c0q8g3 h2 > a > svg,.css-c0q8g3 h3 > a > svg,.css-c0q8g3 h4 > a > svg,.css-c0q8g3 h5 > a > svg,.css-c0q8g3 h6 > a > svg{fill:#000;}.css-c0q8g3 h1,.css-c0q8g3 h2{font-size:1.25rem;font-weight:600;margin-top:1.5rem;margin-bottom:1.5rem;}.css-c0q8g3 h3,.css-c0q8g3 h4,.css-c0q8g3 h5,.css-c0q8g3 h6{font-size:1.125rem;margin-top:1.5rem;margin-bottom:1.5rem;font-weight:600;}@media (min-width:640px){.css-c0q8g3 h1,.css-c0q8g3 h2{font-size:1.5rem;}.css-c0q8g3 h3,.css-c0q8g3 h4,.css-c0q8g3 h5,.css-c0q8g3 h6{font-size:1.25rem;}}.css-c0q8g3 a{color:#3737B9;}.css-c0q8g3 a:hover{-webkit-text-decoration:underline;text-decoration:underline;}.css-c0q8g3 p{margin:0.3rem;margin-top:0.75rem;margin-bottom:0.75rem;}.css-c0q8g3 ul,.css-c0q8g3 ol{margin:0.3rem;margin-left:2rem;}.css-c0q8g3 li > p,.css-c0q8g3 li > ul,.css-c0q8g3 li > ol{margin-bottom:0;}.css-c0q8g3 ol{list-style-type:decimal;}.css-c0q8g3 ul{list-style-type:disc;}.css-c0q8g3 blockquote{padding:0.5rem;background-color:#eee;margin:0.3rem;margin-top:0.5rem;margin-bottom:0.5rem;border-left-width:4px;border-color:#86a8e7;}.css-c0q8g3 blockquote > p{margin:0.5rem;}.css-c0q8g3 blockquote > h1,.css-c0q8g3 blockquote > h2,.css-c0q8g3 blockquote > h3,.css-c0q8g3 blockquote > h4,.css-c0q8g3 blockquote > h5{margin-top:0.5rem;margin-bottom:0.5rem;}.css-c0q8g3 td,.css-c0q8g3 th{padding-left:0.5rem;padding-right:0.5rem;padding-top:0.25rem;padding-bottom:0.25rem;border-width:1px;border-color:#86a8e7;}.css-c0q8g3 tr:nth-of-type(even){background-color:#eee;}.css-c0q8g3 th{background-color:#eee;}.css-c0q8g3 table{margin-bottom:1.5rem;display:block;max-width:-webkit-fit-content;max-width:-moz-fit-content;max-width:fit-content;margin:0 auto;overflow-x:auto;white-space:nowrap;}.css-c0q8g3 p > code,.css-c0q8g3 li > code{padding-top:0.1rem;padding-bottom:0.1rem;padding-right:0.25rem;padding-left:0.25rem;border-radius:0.25rem;color:#3737B9;background-color:#eee;white-space:pre-line;}.css-c0q8g3 pre.grvsc-container{margin-top:24px;margin-bottom:24px;}.css-c0q8g3 hr{margin-top:24px;margin-bottom:24px;height:2px;border:none;background:linear-gradient( 270deg,#7f7fd5,#86a8e7,#91eac9 );}</style><div class="markdown css-c0q8g3"><h2 id="-education" style="position:relative;"><a href="#-education" aria-label=" education permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>📖 Education</h2>
<h3 id="yonsei-university" style="position:relative;"><a href="#yonsei-university" aria-label="yonsei university permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Yonsei University</h3>
<details>
<summary> Bachelor of Economics (Major) & Applied Statistics (Minor)</summary>
  <ul>
    <li>INTRODUCTION TO STATISTICS (A0)</li>
    <li>STATISTICAL METHOD (A+)</li>
    <li>CALCULUS (TBD)</li>
    <li>LINEAR ALGEBRA (B+)</li>
    <li>MATHEMATICAL STATISTICS 1 (A+)</li>
    <li>LINEAR REGRESSION (B+)</li>
    <li>R AND PYTHON PROGRAMMING (A+)</li>
    <li>DATA STRUCTURE (TBD)</li>
    <li>SPECIAL PROBLEMS IN COMPUTING (A0)</li>
    <li>SOCIAL INFORMATICS (A+)</li>
    <li>TIME SERIES ANALYSIS (A+)</li>
  </ul>
</details>
<h2 id="-competition-awards" style="position:relative;"><a href="#-competition-awards" aria-label=" competition awards permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>🏆 Competition Awards</h2>
<table>
<thead>
<tr>
<th align="center">Topic / Task</th>
<th align="center">Result</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://github.com/QuoQA-NLP/MRC_Baseline">Machine Reading <br />Compehension</a></td>
<td align="center">🥈 2nd <br />(2/26)</td>
</tr>
<tr>
<td align="center"><a href="https://data.kostat.go.kr/sbchome/bbs/boardList.do?boardId=SBCSBBS_000000025000&#x26;curMenuNo=OPT_09_02_00_0">Korean Standard <br />Industry Classification</a></td>
<td align="center">🎖 7th <br />(7/311)</td>
</tr>
<tr>
<td align="center"><a href="https://dacon.io/competitions/official/235875/codeshare/4589">KLUE benchmark <br />Natural Language Inference</a></td>
<td align="center">🥇 1st <br />(1/468)</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/sangHa0411/CloneDetection">Python Code<br />Clone Detection</a></td>
<td align="center">🥉 3rd <br />(3/337)</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/snoop2head/elastic-stock-prediction">Stock Price Forecast<br />on KOSPI &#x26; KOSDAQ</a></td>
<td align="center">🎖 6th <br />(6/205)</td>
</tr>
</tbody>
</table>
<p>**Dacon is Kaggle alike competition platform in Korea.</p>
<hr>
<h2 id="-multimodal-projects" style="position:relative;"><a href="#-multimodal-projects" aria-label=" multimodal projects permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>🛠 Multimodal Projects</h2>
<h3 id="kodalle-text-to-fashion-2021" style="position:relative;"><a href="#kodalle-text-to-fashion-2021" aria-label="kodalle text to fashion 2021 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/KR-HappyFace/KoDALLE">KoDALLE: Text to Fashion (2021)</a></h3>
<p><a href="https://github.com/KR-HappyFace/KoDALLE"><img width="700" alt="image" src="https://github.com/KR-HappyFace/KoDALLE/raw/main/assets/README/image-20211227151557604.png"></a></p>
<p><strong>Generating dress outfit images based on given input text</strong> | <a href="https://github.com/KR-HappyFace/KoDALLE/blob/main/README.pdf">📄 Presentation</a></p>
<ul>
<li><strong>Created training pipeline from VQGAN through DALLE</strong></li>
<li><strong>Maintained versions of 1 million pairs image-caption dataset.</strong></li>
<li>Trained VQGAN and DALLE model from the scratch.</li>
<li>Established live demo for the KoDALLE on Huggingface Space via FastAPI.</li>
</ul>
<h2 id="-deep-learning-security-projects" style="position:relative;"><a href="#-deep-learning-security-projects" aria-label=" deep learning security projects permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>🔐 Deep Learning Security Projects</h2>
<h3 id="language-model-memorization-2022" style="position:relative;"><a href="#language-model-memorization-2022" aria-label="language model memorization 2022 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/yonsei-cysec/Language_Model_Memorization">Language Model Memorization (2022)</a></h3>
<p><strong>Implementation of Carlini et al(2020) <a href="https://arxiv.org/abs/2012.07805">Extracting Training Data from Large Language Models</a></strong></p>
<ul>
<li>Accelerated inference speed with parallel Multi-GPU usage.</li>
<li>Ruled out 'low-quality repeated generations' problem of the paper with repetition penalty and with ngram restriction.</li>
</ul>
<h3 id="membership-inference-attack-2022" style="position:relative;"><a href="#membership-inference-attack-2022" aria-label="membership inference attack 2022 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/yonsei-cysec/Membership_Inference_Attack">Membership Inference Attack (2022)</a></h3>
<p><strong>Implementation of Shokri et al(2016) <a href="https://arxiv.org/pdf/1610.05820.pdf">Membership Inference Attacks Against Machine Learning Models</a></strong></p>
<ul>
<li>Prevented overfitting of shadow models' by adding early stop, regularizing with weight decay and allocating train/val/test datasets.</li>
<li>Referenced <a href="https://arxiv.org/abs/2112.03570">Carlini et al(2021)</a> to conduct further research on different types of models and metrics.</li>
<li>Reproduced attack metrics as the following.</li>
</ul>
<table>
<thead>
<tr>
<th align="center">MIA Attack Metrics</th>
<th align="center">Accuracy</th>
<th align="center">Precision</th>
<th align="center">Recall</th>
<th align="center">F1 Score</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">CIFAR10</td>
<td align="center">0.7761</td>
<td align="center">0.7593</td>
<td align="center">0.8071</td>
<td align="center">0.7825</td>
</tr>
<tr>
<td align="center">CIFAR100</td>
<td align="center">0.9746</td>
<td align="center">0.9627</td>
<td align="center">0.9875</td>
<td align="center">0.9749</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th align="center">MIA ROC Curve CIFAR10</th>
<th align="center">MIA ROC Curve CIFAR100</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><img src="https://raw.githubusercontent.com/snoop2head/Membership_Inference_Attack/main/assets/roc_cifar10.png" alt="roc_curve CIFAR10"></td>
<td align="center"><img src="https://raw.githubusercontent.com/snoop2head/Membership_Inference_Attack/main/assets/roc_cifar100.png" alt="roc_curve CIFAR100"></td>
</tr>
</tbody>
</table>
<h2 id="-natural-language-processing-projects" style="position:relative;"><a href="#-natural-language-processing-projects" aria-label=" natural language processing projects permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>💬 Natural Language Processing Projects</h2>
<h3 id="koquillbot-2022--t5-translation-2022" style="position:relative;"><a href="#koquillbot-2022--t5-translation-2022" aria-label="koquillbot 2022  t5 translation 2022 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/QuoQA-NLP/KoQuillBot">KoQuillBot (2022)</a> &#x26; <a href="https://github.com/QuoQA-NLP/T5_Translation">T5 Translation (2022)</a></h3>
<p><strong>Paraphrasing tool with round trip translation utilizing T5 Machine Translation.</strong> | <a href="https://huggingface.co/spaces/QuoQA-NLP/KoQuillBot">🤗 KoQuillBot Demo</a> &#x26; <a href="https://huggingface.co/spaces/QuoQA-NLP/QuoQaGo">🤗 Translator Demo</a></p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">BLEU Score</th>
<th align="center">Translation Result</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Korean ➡️ English</td>
<td align="center">45.15</td>
<td align="center"><a href="https://huggingface.co/datasets/QuoQA-NLP/KE-T5-Ko2En-Base-Inference-Result">🔗 Inference Result</a></td>
</tr>
<tr>
<td align="center">English ➡️ Korean</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
</tbody>
</table>
<h3 id="deep-encoder-shallow-decoder-2022" style="position:relative;"><a href="#deep-encoder-shallow-decoder-2022" aria-label="deep encoder shallow decoder 2022 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/Deep-Encoder-Shallow-Decoder">Deep Encoder Shallow Decoder (2022)</a></h3>
<p><strong>Implementation of Kasai et al(2020) <a href="https://arxiv.org/abs/2006.10369">Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation</a></strong> | <a href="https://docs.google.com/spreadsheets/d/1IqEuRuEpphPEX3ni1m0EwqYuOU4E4t4-jC6uullpJhE/edit#gid=204599913">📄 Translation Output</a></p>
<ul>
<li>Composed custom dataset, trainer, inference code in pytorch and huggingface.</li>
<li>Trained and hosted encoder-decoder transformers model using huggingface.</li>
</ul>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">BLEU Score</th>
<th align="center">Translation Result</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Korean ➡️ English</td>
<td align="center">35.82</td>
<td align="center"><a href="https://docs.google.com/spreadsheets/d/1IqEuRuEpphPEX3ni1m0EwqYuOU4E4t4-jC6uullpJhE/edit#gid=204599913">🔗 Inference Result</a></td>
</tr>
<tr>
<td align="center">English ➡️ Korean</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
</tbody>
</table>
<h3 id="klue-rbert-2021" style="position:relative;"><a href="#klue-rbert-2021" aria-label="klue rbert 2021 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/KLUE-RBERT">KLUE-RBERT (2021)</a></h3>
<p><strong>Extracting relations between subject and object entity in KLUE Benchmark dataset</strong> | <a href="https://snoop2head.github.io/Relation-Extraction-Code/">✍️ Blog Post</a></p>
<ul>
<li>Finetuned RoBERTa model according to RBERT structure in pytorch.</li>
<li>Applied stratified k-fold cross validation for the custom trainer.</li>
</ul>
<h3 id="conditional-generation-with-kogpt-2021" style="position:relative;"><a href="#conditional-generation-with-kogpt-2021" aria-label="conditional generation with kogpt 2021 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/KoGPT-Joong-2">Conditional Generation with KoGPT (2021)</a></h3>
<p><strong>Sentence generation with given emotion conditions</strong> | <a href="https://huggingface.co/spaces/snoop2head/KoGPT-Conditional-Generation">🤗 Huggingface Demo</a></p>
<ul>
<li>Finetuned KoGPT-Trinity with conditional emotion labels.</li>
<li>Maintained huggingface hosted model and live demo.</li>
</ul>
<h3 id="machine-reading-comprehension-in-naver-boostcamp-2021" style="position:relative;"><a href="#machine-reading-comprehension-in-naver-boostcamp-2021" aria-label="machine reading comprehension in naver boostcamp 2021 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://snoop2head.github.io/Custom-MRC-Reader/">Machine Reading Comprehension in Naver Boostcamp (2021)</a></h3>
<p><strong>Retrieved and extracted answers from wikipedia texts for given question</strong> | <a href="https://snoop2head.github.io/Custom-MRC-Reader/">✍️ Blog Post</a></p>
<ul>
<li>Attached bidirectional LSTM layers to the backbone transformers model to extract answers.</li>
<li>Divided benchmark into start token prediction accuracy and end token prediction accuracy.</li>
</ul>
<h3 id="mathpresso-corporation-joint-project-2020" style="position:relative;"><a href="#mathpresso-corporation-joint-project-2020" aria-label="mathpresso corporation joint project 2020 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/Mathpresso_Classification">Mathpresso Corporation Joint Project (2020)</a></h3>
<p><strong>Corporate joint project for mathematics problems classification task</strong> | <a href="https://github.com/snoop2head/Mathpresso_Classification/blob/main/YBIGTA_%EB%A7%A4%EC%93%B0%ED%94%84%EB%A0%88%EC%86%8C_%EB%AA%BD%EB%8D%B0%EC%9D%B4%ED%81%AC_Final.pdf">📄 Presentation</a></p>
<ul>
<li>Preprocessed Korean mathematics problems dataset based on EDA.</li>
<li>Maintained version of preprocessing module.</li>
</ul>
<h3 id="constructing-emotional-instagram-posts-dataset-2019" style="position:relative;"><a href="#constructing-emotional-instagram-posts-dataset-2019" aria-label="constructing emotional instagram posts dataset 2019 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/Keracorn/geulstagram">Constructing Emotional Instagram Posts Dataset (2019)</a></h3>
<p><strong>Created Emotional Instagram Posts(글스타그램) dataset</strong> | <a href="https://github.com/Keracorn/geulstagram/blob/master/README.pdf">📄 Presentation</a></p>
<ul>
<li>Managed version control for the project Github Repository.</li>
<li>Converted Korean texts on image file into text file using Google Cloud Vision API.</li>
</ul>
<h2 id="-computer-vision-projects" style="position:relative;"><a href="#-computer-vision-projects" aria-label=" computer vision projects permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>👀 Computer Vision Projects</h2>
<h3 id="elimnet-2021" style="position:relative;"><a href="#elimnet-2021" aria-label="elimnet 2021 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/ELimNet">ElimNet (2021)</a></h3>
<p><strong>Elimination based Lightweight Neural Net with Pretrained Weights</strong> | <a href="https://github.com/snoop2head/ELimNet/blob/main/README.pdf">📄 Presentation</a></p>
<ul>
<li>Constructed lightweight CNN model with less than 1M #params by removing top layers from pretrained CNN models.</li>
<li>Assessed on Trash Annotations in Context(TACO) Dataset sampled for 6 classes with 20,851 images.</li>
<li>Compared metrics accross VGG11, MobileNetV3 and EfficientNetB0.</li>
</ul>
<h3 id="face-mask-age-gender-classification-in-naver-boostcamp-2021" style="position:relative;"><a href="#face-mask-age-gender-classification-in-naver-boostcamp-2021" aria-label="face mask age gender classification in naver boostcamp 2021 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/boostcampaitech2/image-classification-level1-23">Face Mask, Age, Gender Classification in Naver Boostcamp (2021)</a></h3>
<p><strong>Identifying 18 classes from given images: Age Range(3 classes), Biological Sex(2 classes), Face Mask(3 classes)</strong> | <a href="https://snoop2head.github.io/Mask-Age-Gender-Classification-Competition/">✍️ Blog Post</a></p>
<ul>
<li>Optimized combination of backbone models, losses and optimizers.</li>
<li>Created additional dataset with labels(age, sex, mask) to resolve class imbalance.</li>
<li>Cropped facial characteristics with MTCNN and RetinaFace to reduce noise in the image.</li>
</ul>
<h3 id="realtime-desktop-posture-classification-2020" style="position:relative;"><a href="#realtime-desktop-posture-classification-2020" aria-label="realtime desktop posture classification 2020 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/ml_classification_tutorial">Realtime Desktop Posture Classification (2020)</a></h3>
<p><strong>Real-time desk posture classification through webcam</strong> | <a href="https://www.youtube.com/watch?v=6z_TJaj71io&#x26;t=459s">📷 Demo Video</a></p>
<ul>
<li>Created real-time detection window using opencv-python.</li>
<li>Converted image dataset into Yaw/Pitch/Roll numerical dataset using RetinaFace model.</li>
<li>Trained and optimized random forest classification model with precision rate of 93%.</li>
</ul>
<h2 id="-web-projects" style="position:relative;"><a href="#-web-projects" aria-label=" web projects permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>🕸 Web Projects</h2>
<h3 id="exchange-program-overview-website-2020" style="position:relative;"><a href="#exchange-program-overview-website-2020" aria-label="exchange program overview website 2020 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/yonsei-exchange-program">Exchange Program Overview Website (2020)</a></h3>
<p><strong>Overview for student life in foreign universities</strong> | <a href="https://yonsei-exchange.netlify.app/">✈️ Website Demo</a></p>
<ul>
<li><strong>3400 Visitors within a year (2021.07 ~ 2022.07)</strong></li>
<li><strong>22000 Pageviews within a year (2021.07 ~ 2022.07)</strong></li>
<li><strong>3 minutes+ of Average Retention Time</strong></li>
<li>Collected and preprocessed 11200 text review data from the Yonsei website using pandas.</li>
<li>Visualized department distribution and weather information using matplotlib.</li>
<li>Sentiment analysis on satisfaction level for foreign universities with pretrained BERT model.</li>
<li>Clustered universities with provided curriculum with K-means clustering.</li>
<li>Hosted reports on universities using Gatsby.js, GraphQL, and Netlify.</li>
</ul>
<h3 id="fitcuration-website-2020" style="position:relative;"><a href="#fitcuration-website-2020" aria-label="fitcuration website 2020 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/fitcuration-django">fitcuration website (2020)</a></h3>
<p><strong>Search-based exercise retrieval web service</strong> | <a href="https://youtu.be/kef0CxzMANo?t=38">📷 Demo Video</a></p>
<ul>
<li>Built retrieval algorithm based on search keyword using TF-IDF.</li>
<li>Deployed website using Docker, AWS RDS, AWS S3, AWS EBS</li>
<li>Constructed backend using Django, Django ORM &#x26; PostgreSQL.</li>
<li>Composed client-side using Sass, Tailwind, HTML5.</li>
</ul>
<h2 id="-quantitative-finance-projects" style="position:relative;"><a href="#-quantitative-finance-projects" aria-label=" quantitative finance projects permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>💰 Quantitative Finance Projects</h2>
<h3 id="forecasting-federal-rate-with-lasso-regression-model-2022" style="position:relative;"><a href="#forecasting-federal-rate-with-lasso-regression-model-2022" aria-label="forecasting federal rate with lasso regression model 2022 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/Federal-Rate-Prediction">Forecasting Federal Rate with Lasso Regression Model (2022)</a></h3>
<p><strong>Federal Rate Prediction for the next FOMC Meeting</strong></p>
<ul>
<li>Wrangled quantitative dataset with Finance Data Reader.</li>
<li>Yielded metrics and compared candidate regression models for the adaquate fit.</li>
<li>Hyperparameter optimization for the candidate models.</li>
</ul>
<h3 id="korean-spinoff-event-tracker-2020" style="position:relative;"><a href="#korean-spinoff-event-tracker-2020" aria-label="korean spinoff event tracker 2020 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/spinoff_hunter_kor">Korean Spinoff Event Tracker (2020)</a></h3>
<p><strong>Get financial data of public companies involved in spinoff events on Google Spreadsheet</strong> | <a href="https://docs.google.com/spreadsheets/d/1chJ2NKHVc0gKjsMaQI1UHEPxdjneV1ZWaTGHseQvxP4/edit?usp=sharing">🧩 Dataset Demo</a></p>
<ul>
<li>Wrangled finance dataset which are displayed on Google Sheets</li>
</ul>
<hr>
<h2 id="-opensource-contributions" style="position:relative;"><a href="#-opensource-contributions" aria-label=" opensource contributions permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>🏷 Opensource Contributions</h2>
<h3 id="nvlabsstylegan2-ada-pytorch-2021" style="position:relative;"><a href="#nvlabsstylegan2-ada-pytorch-2021" aria-label="nvlabsstylegan2 ada pytorch 2021 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/NVlabs/stylegan2-ada-pytorch">NVlabs/stylegan2-ada-pytorch (2021)</a></h3>
<p><strong>Fixed torch version comparison fallback error for source repo of NVIDIA Research</strong> | <a href="https://github.com/NVlabs/stylegan2-ada-pytorch/pull/197">✍️ Pull Request</a></p>
<ul>
<li>Skills: torch, torchvision</li>
</ul>
<h3 id="dockerdockergithubio-2020" style="position:relative;"><a href="#dockerdockergithubio-2020" aria-label="dockerdockergithubio 2020 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/docker/docker.github.io">docker/docker.github.io (2020)</a></h3>
<p><strong>Updated PostgreSQL initialization for "Quickstart: dockerizing django" documentation</strong> | <a href="https://github.com/docker/docker.github.io/pull/10624">🐳 Pull Request</a></p>
<ul>
<li>Skills: Docker, docker-compose, Django</li>
</ul>
<h2 id="-etcs" style="position:relative;"><a href="#-etcs" aria-label=" etcs permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>🗄 ETCs</h2>
<h3 id="covid19-confirmed-cases-prediction-2020" style="position:relative;"><a href="#covid19-confirmed-cases-prediction-2020" aria-label="covid19 confirmed cases prediction 2020 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/Rank23/COVID19">Covid19 Confirmed Cases Prediction (2020)</a></h3>
<p><strong>Predict the spread of COVID-19 in early stage after its entrance to country.</strong></p>
<ul>
<li>Fixed existing errors on Github Repository.</li>
<li>Wrote footnotes in both English and Korean.</li>
<li>±5% accuracy for one-day prediction.</li>
<li>±10% accuracy for 30-day prediction.</li>
</ul>
<h3 id="indigo-2019" style="position:relative;"><a href="#indigo-2019" aria-label="indigo 2019 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a href="https://github.com/snoop2head/indigo">Indigo (2019)</a></h3>
<p><strong>Don't miss concerts for your favorite artists with KakaoTalk Chatbot</strong> | <a href="https://www.youtube.com/watch?v=uIOWqumaOD4">📷 Demo Video</a></p>
<ul>
<li>Created API server for KakaoTalk chatbot with Flask, Pymongo and MongoDB.</li>
<li>Deployed the API server on AWS EC2.</li>
<li>Visualized concert schedules on user's Google Calendar.</li>
<li>Created / Updated events in Google Calendar.</li>
</ul>
<hr>
<h2 id="-skillsets" style="position:relative;"><a href="#-skillsets" aria-label=" skillsets permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>🛠 Skillsets</h2>
<p><strong>Data Analysis and Machine Learning</strong></p>
<ul>
<li>Data Analysis Library: pandas, numpy</li>
<li>Deep Learning: pytorch, transformers</li>
<li>Machine Learning: scikit-learn, gensim, xgboost</li>
</ul>
<p><strong>Backend</strong></p>
<ul>
<li>Python / Django - Django ORM, CRUD, OAuth</li>
<li>Python / FastAPI(uvicorn) - CRUD API</li>
<li>Python / Flask - CRUD API</li>
</ul>
<p><strong>Client</strong></p>
<ul>
<li>HTML / Pug.js</li>
<li>CSS / Sass, Tailwind, Bulma</li>
<li>JavaScript / ES6</li>
</ul>
<p><strong>Deployment</strong></p>
<ul>
<li>Docker, docker-compose</li>
<li>AWS EC2, Google Cloud App Engine</li>
<li>AWS S3, RDS (PostgreSQL)</li>
<li>AWS Elastic Beanstalk, CodePipeline;</li>
</ul>
<style class="grvsc-styles">
  .grvsc-container {
    overflow: auto;
    position: relative;
    -webkit-overflow-scrolling: touch;
    padding-top: 1rem;
    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));
    padding-bottom: 1rem;
    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));
    border-radius: 8px;
    border-radius: var(--grvsc-border-radius, 8px);
    font-feature-settings: normal;
    line-height: 1.4;
  }
  
  .grvsc-code {
    display: table;
  }
  
  .grvsc-line {
    display: table-row;
    box-sizing: border-box;
    width: 100%;
    position: relative;
  }
  
  .grvsc-line > * {
    position: relative;
  }
  
  .grvsc-gutter-pad {
    display: table-cell;
    padding-left: 0.75rem;
    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);
  }
  
  .grvsc-gutter {
    display: table-cell;
    -webkit-user-select: none;
    -moz-user-select: none;
    user-select: none;
  }
  
  .grvsc-gutter::before {
    content: attr(data-content);
  }
  
  .grvsc-source {
    display: table-cell;
    padding-left: 1.5rem;
    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));
    padding-right: 1.5rem;
    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));
  }
  
  .grvsc-source:empty::after {
    content: ' ';
    -webkit-user-select: none;
    -moz-user-select: none;
    user-select: none;
  }
  
  .grvsc-gutter + .grvsc-source {
    padding-left: 0.75rem;
    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);
  }
  
  /* Line transformer styles */
  
  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {
    content: ' ';
    position: absolute;
    width: 100%;
  }
  
  .grvsc-line-diff-add::before {
    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));
  }
  
  .grvsc-line-diff-del::before {
    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));
  }
  
  .grvsc-line-number {
    padding: 0 2px;
    text-align: right;
    opacity: 0.7;
  }
  
</style></div></div></div></div></div><style data-emotion-css="xgi74q">.css-xgi74q{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:fixed;bottom:0;right:0;padding-right:1.5rem;padding-bottom:1.5rem;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}</style><div class="css-xgi74q e8huvi00"><style data-emotion-css="1a68u">.css-1a68u{box-shadow:0 2px 2px 0 rgba(0,0,0,0.15);-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#636363;font-size:0.75rem;padding-left:0.5rem;padding-right:0.5rem;padding-top:0.5rem;padding-bottom:0.5rem;border-radius:9999px;--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;-webkit-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));-ms-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-content:flex-end;-ms-flex-line-pack:end;align-content:flex-end;z-index:100;}.css-1a68u:hover{background-color:#404040;color:#FFFFFF;}.css-1a68u:hover{--transform-scale-x:1.05;--transform-scale-y:1.05;}</style><button title="change to darkmode" class="css-1a68u"><style data-emotion-css="1alqh2e">.css-1alqh2e{fill:currentColor;--text-opacity:1;color:rgba(246,224,94,var(--text-opacity));width:1rem;height:1rem;margin-top:auto;margin-bottom:auto;margin-left:0;margin-right:0;}@media (min-width:768px){.css-1alqh2e{display:inline-block;margin-left:0.25rem;margin-right:0.25rem;}}</style><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="css-1alqh2e" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg><style data-emotion-css="flxr9x">.css-flxr9x{display:none;margin-right:0;}@media (min-width:768px){.css-flxr9x{display:inline-block;margin-right:0.25rem;}}</style><span class="css-flxr9x">Use Dark Mode</span></button><style data-emotion-css="15afv4q">.css-15afv4q{box-shadow:0 2px 2px 0 rgba(0,0,0,0.15);-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#636363;font-size:0.75rem;padding-left:0.5rem;padding-right:0.5rem;padding-top:0.5rem;padding-bottom:0.5rem;border-radius:9999px;--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;-webkit-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));-ms-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));cursor:pointer;margin-left:0.5rem;margin-top:auto;margin-bottom:auto;z-index:100;}.css-15afv4q:hover{background-color:#404040;color:#FFFFFF;}.css-15afv4q:hover{--transform-scale-x:1.05;--transform-scale-y:1.05;}</style><button title="top page" class="css-15afv4q"><style data-emotion-css="13htjwu">.css-13htjwu{width:1rem;height:1rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-13htjwu" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M868 545.5L536.1 163a31.96 31.96 0 0 0-48.3 0L156 545.5a7.97 7.97 0 0 0 6 13.2h81c4.6 0 9-2 12.1-5.5L474 300.9V864c0 4.4 3.6 8 8 8h60c4.4 0 8-3.6 8-8V300.9l218.9 252.3c3 3.5 7.4 5.5 12.1 5.5h81c6.8 0 10.5-8 6-13.2z"></path></svg></button></div><style data-emotion-css="1k8xcyw">.css-1k8xcyw{text-align:center;padding-top:2rem;padding-bottom:2rem;bottom:0;}</style><footer class="css-1k8xcyw"><style data-emotion-css="1xju3od">.css-1xju3od{font-size:0.75rem;font-weight:700;}</style><a href="https://github.com/snoop2head" class="css-1xju3od">©snoop2head</a></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-186254784-2', 'auto', {});
      
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/about/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-efbe87ab08854460e1b4.js"],"app":["/app-6b37a0275bc86b56e034.js"],"component---src-pages-404-js":["/component---src-pages-404-js-23314e5a1122284127b1.js"],"component---src-pages-about-js":["/component---src-pages-about-js-3c0cba9242c81692c359.js"],"component---src-pages-index-js":["/component---src-pages-index-js-81659046284b3feb90f5.js"],"component---src-pages-search-js":["/component---src-pages-search-js-6bfc09fa0dcf8ea3b63d.js"],"component---src-templates-blog-post-js":["/component---src-templates-blog-post-js-5f317a7779dd1baa19f9.js"],"component---src-templates-category-js":["/component---src-templates-category-js-5fbfac713624a9c1ac35.js"]};/*]]>*/</script><script src="/polyfill-efbe87ab08854460e1b4.js" nomodule=""></script><script src="/component---src-pages-about-js-3c0cba9242c81692c359.js" async=""></script><script src="/commons-33df4d3f9aa201d0ec4c.js" async=""></script><script src="/5e2a4920-da90abce4a08c86a094c.js" async=""></script><script src="/d7eeaac4-dcbe97e7a5aa158c9d08.js" async=""></script><script src="/app-6b37a0275bc86b56e034.js" async=""></script><script src="/dc6a8720040df98778fe970bf6c000a41750d3ae-4121d07143daec1f6e61.js" async=""></script><script src="/styles-e8fd4555a67a3390b64e.js" async=""></script><script src="/framework-c8d3a5345e3f321d7da5.js" async=""></script><script src="/webpack-runtime-a15e1610686fb2064048.js" async=""></script></body></html>