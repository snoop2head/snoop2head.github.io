<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=0"/><style data-href="/styles.d53766664f3eaba3db40.css" id="gatsby-global-css">/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden],template{display:none}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}button{background-color:transparent;background-image:none}button:focus{outline:1px dotted;outline:5px auto -webkit-focus-ring-color}fieldset,ol,ul{margin:0;padding:0}ol,ul{list-style:none}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;line-height:1.5}*,:after,:before{box-sizing:border-box;border:0 solid #e2e8f0}hr{border-top-width:1px}img{border-style:solid}textarea{resize:vertical}input::-webkit-input-placeholder,textarea::-webkit-input-placeholder{color:#a0aec0}input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#a0aec0}input::placeholder,textarea::placeholder{color:#a0aec0}[role=button],button{cursor:pointer}table{border-collapse:collapse}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit}code,kbd,pre,samp{font-family:Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}</style><meta name="generator" content="Gatsby 2.32.13"/><style type="text/css">
    .toc-header.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .toc-header.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .toc-header svg,
    h2 .toc-header svg,
    h3 .toc-header svg,
    h4 .toc-header svg,
    h5 .toc-header svg,
    h6 .toc-header svg {
      visibility: hidden;
    }
    h1:hover .toc-header svg,
    h2:hover .toc-header svg,
    h3:hover .toc-header svg,
    h4:hover .toc-header svg,
    h5:hover .toc-header svg,
    h6:hover .toc-header svg,
    h1 .toc-header:focus svg,
    h2 .toc-header:focus svg,
    h3 .toc-header:focus svg,
    h4 .toc-header:focus svg,
    h5 .toc-header:focus svg,
    h6 .toc-header:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="preconnect" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><link rel="icon" href="/favicon-32x32-1c5857f550ca5d27138682501fbd1e0a.png" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><meta name="theme-color" content="#3F4145"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512-1c5857f550ca5d27138682501fbd1e0a.png"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><title data-react-helmet="true">KLUE Relation Extraction: Subject Entity and Object Entity | Young Jin&#x27;s Blog</title><meta data-react-helmet="true" name="description" content="ğŸ¥‡ AUPRC score of 83.2 ranked the 1st place / 19 teams ğŸ¥‰ F1 score of 73.9 ranked 3rd place / 19 teams KLUE(Korean Language Understanding Evaluation) Benchmark is newly introduced Korean NLP Benchmark.â€¦"/><meta data-react-helmet="true" property="og:title" content="KLUE Relation Extraction: Subject Entity and Object Entity"/><meta data-react-helmet="true" property="og:image" content="/static/social-image-6de40f09193cda71c4536687c1f81234.png"/><meta data-react-helmet="true" property="og:description" content="ğŸ¥‡ AUPRC score of 83.2 ranked the 1st place / 19 teams ğŸ¥‰ F1 score of 73.9 ranked 3rd place / 19 teams KLUE(Korean Language Understanding Evaluation) Benchmark is newly introduced Korean NLP Benchmark.â€¦"/><meta data-react-helmet="true" property="og:type" content="website"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:image" content="/static/social-image-6de40f09193cda71c4536687c1f81234.png"/><meta data-react-helmet="true" name="twitter:creator" content="Young Jin Ahn"/><meta data-react-helmet="true" name="twitter:title" content="KLUE Relation Extraction: Subject Entity and Object Entity"/><meta data-react-helmet="true" name="twitter:description" content="ğŸ¥‡ AUPRC score of 83.2 ranked the 1st place / 19 teams ğŸ¥‰ F1 score of 73.9 ranked 3rd place / 19 teams KLUE(Korean Language Understanding Evaluation) Benchmark is newly introduced Korean NLP Benchmark.â€¦"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link as="script" rel="preload" href="/webpack-runtime-3d93945ad234d2f13d98.js"/><link as="script" rel="preload" href="/framework-eb684e3e828ad13b3940.js"/><link as="script" rel="preload" href="/styles-84a9bc99193fe5828ffe.js"/><link as="script" rel="preload" href="/dc6a8720040df98778fe970bf6c000a41750d3ae-17eb047fb821ccbad0b0.js"/><link as="script" rel="preload" href="/app-97235b1800926a9fde68.js"/><link as="script" rel="preload" href="/d7eeaac4-dcbe97e7a5aa158c9d08.js"/><link as="script" rel="preload" href="/5e2a4920-da90abce4a08c86a094c.js"/><link as="script" rel="preload" href="/1bfc9850-409296e666dade882413.js"/><link as="script" rel="preload" href="/commons-193e8d98dacc19f3118d.js"/><link as="script" rel="preload" href="/7a297f752dcfe258c0b0106d89edb3a916af916e-cedd3fd12e7e0b393ad2.js"/><link as="script" rel="preload" href="/component---src-templates-blog-post-js-2da73b992f9a5d5d1c33.js"/><link as="fetch" rel="preload" href="/page-data/DL&amp;ML/Relation-Extraction/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/1081905842.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3911196313.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><noscript><style data-emotion-css="1vyo7ug">.css-1vyo7ug{position:fixed;bottom:0;left:0;margin-left:0.5rem;margin-bottom:0.5rem;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;box-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px 0 rgba(0,0,0,0.06);-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));font-size:0.875rem;font-weight:700;padding-left:1rem;padding-right:1rem;padding-top:0.75rem;padding-bottom:0.75rem;background-color:#86a8e7;z-index:9999;}</style><div class="css-1vyo7ug"><style data-emotion-css="5x4yj0">.css-5x4yj0{fill:currentColor;width:1.5rem;height:1.5rem;margin-right:0.5rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 192 512" class="css-5x4yj0" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M20 424.229h20V279.771H20c-11.046 0-20-8.954-20-20V212c0-11.046 8.954-20 20-20h112c11.046 0 20 8.954 20 20v212.229h20c11.046 0 20 8.954 20 20V492c0 11.046-8.954 20-20 20H20c-11.046 0-20-8.954-20-20v-47.771c0-11.046 8.954-20 20-20zM96 0C56.235 0 24 32.235 24 72s32.235 72 72 72 72-32.235 72-72S135.764 0 96 0z"></path></svg><style data-emotion-css="1f2k2gl">.css-1f2k2gl{margin-left:0.5rem;}</style><div class="css-1f2k2gl">Please enable JavaScript to use this site.<br/>JavaScriptë¥¼ í™œì„±í™” ì‹œì¼œì£¼ì„¸ìš”.</div></div></noscript><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><style data-emotion-css="f6s0ma">.css-f6s0ma{-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#333333;}</style><style data-emotion-css="acifd">.css-acifd{min-height:100vh;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#333333;}</style><div class="css-acifd e60ayux0"><style data-emotion-css="8ezs2g">.css-8ezs2g{min-height:calc(100vh - 100px);}</style><div class="css-8ezs2g"><style data-emotion-css="1yxw6gp">.css-1yxw6gp{background:linear-gradient( 90deg,#7f7fd5,#86a8e7 );}</style><div class="css-1yxw6gp"><style data-emotion-css="1mqm4zt">.css-1mqm4zt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;max-width:1280px;margin-left:auto;margin-right:auto;padding:1.25rem;}</style><nav class="css-1mqm4zt e1czdvww0"><style data-emotion-css="1usmgm5">.css-1usmgm5{font-size:1.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));font-weight:700;}</style><a class="css-1usmgm5" href="/">Young Jin Ahn&#x27;s Blog</a><a aria-label="search page" href="/search"><style data-emotion-css="47445j">.css-47445j{--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));margin-top:auto;margin-bottom:auto;width:2rem;height:2rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-47445j" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0 0 11.6 0l43.6-43.5a8.2 8.2 0 0 0 0-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></a></nav></div><style data-emotion-css="aod07n">.css-aod07n{background:linear-gradient( 90deg,#7f7fd5,#86a8e7 );position:fixed;width:100%;box-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px 0 rgba(0,0,0,0.06);z-index:100;-webkit-transition:all 300ms cubic-bezier(0,0,0.2,1);transition:all 300ms cubic-bezier(0,0,0.2,1);top:-100px;}</style><div class="css-aod07n"><nav class="css-1mqm4zt e1czdvww0"><a class="css-1usmgm5" href="/">Young Jin Ahn&#x27;s Blog</a><a aria-label="search page" href="/search"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-47445j" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0 0 11.6 0l43.6-43.5a8.2 8.2 0 0 0 0-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></a></nav></div><style data-emotion-css="w27u98">.css-w27u98{margin-top:1rem;padding-left:1rem;padding-right:1rem;}</style><div class="blog-post-container css-w27u98"><div class="blog-post"><style data-emotion-css="1bdwg0l">.css-1bdwg0l{width:100%;max-width:768px;margin-left:auto;margin-right:auto;}</style><div class="css-1bdwg0l eyldt480"><style data-emotion-css="1abxlfd">.css-1abxlfd{font-size:2.25rem;font-weight:700;margin-bottom:1rem;}@media (min-width:768px){.css-1abxlfd{font-size:3rem;}}</style><h1 class="blog-title css-1abxlfd">KLUE Relation Extraction: Subject Entity and Object Entity</h1><style data-emotion-css="cpn9zx">.css-cpn9zx{font-size:1rem;margin-bottom:1rem;}</style><h2 class="blog-date css-cpn9zx">2021-10-08</h2><style data-emotion-css="cet0rr">.css-cet0rr{margin-bottom:0.5rem;}</style><div class="blog-tags css-cet0rr"><style data-emotion-css="1ak4bcm">.css-1ak4bcm{white-space:nowrap;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);font-size:1rem;font-weight:700;border-radius:9999px;margin-right:0.5rem;margin-top:0.25rem;margin-bottom:0.25rem;padding-top:0.25rem;padding-bottom:0.25rem;padding-left:0.75rem;padding-right:0.75rem;background-color:#edf2f7;color:#3737B9;}</style><button class="css-1ak4bcm">DL&amp;ML</button><button class="css-1ak4bcm">NLP</button><button class="css-1ak4bcm">Competition</button></div><style data-emotion-css="1l4w6pd">.css-1l4w6pd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}</style><div class="css-1l4w6pd"><style data-emotion-css="yapsbb">.css-yapsbb{border-radius:9999px;width:100%;height:1px;--bg-opacity:1;background-color:rgba(247,250,252,var(--bg-opacity));background:linear-gradient( 270deg,#7f7fd5,#86a8e7,#91eac9 );}</style><div class="css-yapsbb"></div></div></div><div class="blog-content"><style data-emotion-css="19vk1qv">.css-19vk1qv{-webkit-scrollbar-width:thin;-moz-scrollbar-width:thin;-ms-scrollbar-width:thin;scrollbar-width:thin;-webkit-scrollbar-color:gray transparent;-moz-scrollbar-color:gray transparent;-ms-scrollbar-color:gray transparent;scrollbar-color:gray transparent;display:none;}.css-19vk1qv::-webkit-scrollbar{width:4px;}.css-19vk1qv::-webkit-scrollbar-track{background-color:transparent;}.css-19vk1qv::-webkit-scrollbar-thumb{border-radius:9999px;background-color:gray;}.css-19vk1qv::-webkit-scrollbar-button{width:0;height:0;}@media screen and (min-width:1280px){.css-19vk1qv{float:right;position:-webkit-sticky;position:sticky;top:100px;width:calc((100vw - 720px) / 2 - 80px);max-width:250px;margin-right:1rem;overflow:auto;word-break:break-word;max-height:calc(100vh - 200px);fontsize:1rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;border-left-width:4px;border-image:linear-gradient( 180deg,#7f7fd5,#86a8e7,#91eac9 );border-image-slice:1;}}</style><div class="css-19vk1qv"><style data-emotion-css="13af3fo">.css-13af3fo{margin-left:1rem;margin-right:1rem;}</style><div class="css-13af3fo"><style data-emotion-css="17i5xbf">.css-17i5xbf{font-weight:700;margin-bottom:0.5rem;font-size:1.125rem;--text-opacity:1;color:rgba(74,85,104,var(--text-opacity));}</style><h3 class="css-17i5xbf">TOC</h3><style data-emotion-css="1me4zjn">.css-1me4zjn ul{margin-left:0.5rem;}.css-1me4zjn ul > li a:hover{color:#555555;}.css-1me4zjn ul > li a{-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);--text-opacity:1;color:rgba(160,174,192,var(--text-opacity));font-size:0.875rem;}.css-1me4zjn ul > li a[href=""]{font-size:0.95rem;color:#555555;}</style><div class="css-1me4zjn"><ul>
<li>
<p><a href="/DL&#x26;ML/Relation-Extraction/#dataset--dataloader">Dataset &#x26; Dataloader</a></p>
<ul>
<li><a href="/DL&#x26;ML/Relation-Extraction/#entity-representation">Entity Representation</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#1-typed-entity-marker-dataset-creation">(1) Typed Entity Marker Dataset Creation</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#2-typed-entity-marker-punctuation-dataset-creation">(2) Typed Entity Marker Punctuation Dataset Creation</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#fixing-preprocessor">Fixing Preprocessor</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#setting-maximum-token-length-for-roberta-tokenizer">Setting maximum token length for RoBERTa tokenizer</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#data-augmentation">Data Augmentation</a></li>
</ul>
</li>
<li>
<p><a href="/DL&#x26;ML/Relation-Extraction/#model--finetuning">Model &#x26; Finetuning</a></p>
<ul>
<li><a href="/DL&#x26;ML/Relation-Extraction/#how-to-select-pretrained-model">How to select pretrained model</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#how-we-fine-tuned-the-model-according-to-the-relation-extraction-task">How we Fine-tuned the model according to the relation extraction task</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#findings-from-fine-tuning-methods">Findings from fine-tuning methods</a></li>
</ul>
</li>
<li>
<p><a href="/DL&#x26;ML/Relation-Extraction/#training">Training</a></p>
<ul>
<li><a href="/DL&#x26;ML/Relation-Extraction/#why-we-selected-focalloss-as-the-criterion">Why we selected FocalLoss as the criterion</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#how-we-selected-the-gamma-parameter-for-focal-loss">How we selected the gamma parameter for Focal Loss</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#how-we-selected-the-optimizer-adamp-vs-adamw">How we selected the optimizer AdamP vs AdamW</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#other-important-details">Other important details</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#inferencing">Inferencing</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#other-details-to-try-next-time">Other details to try Next time</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#teamwork-">Teamwork ğŸ‘¨â€ğŸ’»</a></li>
<li><a href="/DL&#x26;ML/Relation-Extraction/#reference">Reference</a></li>
</ul>
</li>
</ul></div></div></div><div class="css-1bdwg0l eyldt480"><div><style data-emotion-css="c0q8g3">.css-c0q8g3{font-size:1rem;word-break:break-word;}.css-c0q8g3 h1 > a > svg,.css-c0q8g3 h2 > a > svg,.css-c0q8g3 h3 > a > svg,.css-c0q8g3 h4 > a > svg,.css-c0q8g3 h5 > a > svg,.css-c0q8g3 h6 > a > svg{fill:#000;}.css-c0q8g3 h1,.css-c0q8g3 h2{font-size:1.25rem;font-weight:600;margin-top:1.5rem;margin-bottom:1.5rem;}.css-c0q8g3 h3,.css-c0q8g3 h4,.css-c0q8g3 h5,.css-c0q8g3 h6{font-size:1.125rem;margin-top:1.5rem;margin-bottom:1.5rem;font-weight:600;}@media (min-width:640px){.css-c0q8g3 h1,.css-c0q8g3 h2{font-size:1.5rem;}.css-c0q8g3 h3,.css-c0q8g3 h4,.css-c0q8g3 h5,.css-c0q8g3 h6{font-size:1.25rem;}}.css-c0q8g3 a{color:#3737B9;}.css-c0q8g3 a:hover{-webkit-text-decoration:underline;text-decoration:underline;}.css-c0q8g3 p{margin:0.3rem;margin-top:0.75rem;margin-bottom:0.75rem;}.css-c0q8g3 ul,.css-c0q8g3 ol{margin:0.3rem;margin-left:2rem;}.css-c0q8g3 li > p,.css-c0q8g3 li > ul,.css-c0q8g3 li > ol{margin-bottom:0;}.css-c0q8g3 ol{list-style-type:decimal;}.css-c0q8g3 ul{list-style-type:disc;}.css-c0q8g3 blockquote{padding:0.5rem;background-color:#eee;margin:0.3rem;margin-top:0.5rem;margin-bottom:0.5rem;border-left-width:4px;border-color:#86a8e7;}.css-c0q8g3 blockquote > p{margin:0.5rem;}.css-c0q8g3 blockquote > h1,.css-c0q8g3 blockquote > h2,.css-c0q8g3 blockquote > h3,.css-c0q8g3 blockquote > h4,.css-c0q8g3 blockquote > h5{margin-top:0.5rem;margin-bottom:0.5rem;}.css-c0q8g3 td,.css-c0q8g3 th{padding-left:0.5rem;padding-right:0.5rem;padding-top:0.25rem;padding-bottom:0.25rem;border-width:1px;border-color:#86a8e7;}.css-c0q8g3 tr:nth-of-type(even){background-color:#eee;}.css-c0q8g3 th{background-color:#eee;}.css-c0q8g3 table{margin-bottom:1.5rem;display:block;max-width:-webkit-fit-content;max-width:-moz-fit-content;max-width:fit-content;margin:0 auto;overflow-x:auto;white-space:nowrap;}.css-c0q8g3 p > code,.css-c0q8g3 li > code{padding-top:0.1rem;padding-bottom:0.1rem;padding-right:0.25rem;padding-left:0.25rem;border-radius:0.25rem;color:#3737B9;background-color:#eee;white-space:pre-line;}.css-c0q8g3 pre.grvsc-container{margin-top:24px;margin-bottom:24px;}.css-c0q8g3 hr{margin-top:24px;margin-bottom:24px;height:2px;border:none;background:linear-gradient( 270deg,#7f7fd5,#86a8e7,#91eac9 );}</style><div class="markdown css-c0q8g3"><p><strong>ğŸ¥‡ AUPRC score of 83.2 ranked the 1st place / 19 teams</strong></p>
<p><strong>ğŸ¥‰ F1 score of 73.9 ranked 3rd place / 19 teams</strong></p>
<p><a href="https://paperswithcode.com/dataset/klue">KLUE(Korean Language Understanding Evaluation) Benchmark</a> is newly introduced Korean NLP Benchmark. In Naver Boostcamp, the team solved Relation Extraction task from KLUE Benchmark dataset within the span of 12 days.</p>
<h2 id="dataset--dataloader" style="position:relative;"><a href="#dataset--dataloader" aria-label="dataset  dataloader permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Dataset &#x26; Dataloader</h2>
<h3 id="entity-representation" style="position:relative;"><a href="#entity-representation" aria-label="entity representation permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Entity Representation</h3>
<p><strong>Putting labels(or entity markers) around the target entity has boosted the performance.</strong></p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Sentence</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Origianal</td>
<td align="center">ì¡°ì§€ í•´ë¦¬ìŠ¨ì´ ì“°ê³  ë¹„í‹€ì¦ˆê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</td>
</tr>
<tr>
<td align="center">Entity Marker Method</td>
<td align="center">[E2]ì¡°ì§€ í•´ë¦¬ìŠ¨[/E2]ì´ ì“°ê³  [E1]ë¹„í‹€ì¦ˆ[/E1]ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</td>
</tr>
<tr>
<td align="center">Entity Marker Punctuation Method</td>
<td align="center">#ì¡°ì§€ í•´ë¦¬ìŠ¨#ì´ ì“°ê³  @ë¹„í‹€ì¦ˆ@ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤</td>
</tr>
<tr>
<td align="center">Entity Replacement Method</td>
<td align="center">[OBJ-ORG]ì´ ì“°ê³  [SUBJ-ORG]ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</td>
</tr>
<tr>
<td align="center">Typed Entity Marker Method</td>
<td align="center">[OBJ-ORG]ì¡°ì§€ í•´ë¦¬ìŠ¨[/OBJ-ORG]ì´ ì“°ê³  [SUBJ-ORG]ë¹„í‹€ì¦ˆ[/SUBJ-ORG]ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</td>
</tr>
<tr>
<td align="center"><strong>Typed Entity Marker Punctuation Method</strong></td>
<td align="center"><strong>#^ORG^ì¡°ì§€ í•´ë¦¬ìŠ¨#ì´ ì“°ê³  @<em>ORG</em>ë¹„í‹€ì¦ˆ@ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</strong></td>
</tr>
</tbody>
</table>
<p>How to annotate entity marker around the target entities was important point of discussion.The paper <a href="https://arxiv.org/pdf/2102.01373v3.pdf">An Improved Baseline for Sentence-level Relation Extraction(Zhou et al. 2021)</a> gives 5 types of composite entity information labelling technique as depicted above.</p>
<p>Typed entity marker method was good but required two additional steps. It required adding special token to the tokenizer and resizing the embedding layer accordingly.</p>
<p>Even though it is good idea, this has few shortcomings. <strong>Creating and importing new tokens with no pretrained hidden features might hinder the model's performance.</strong> <strong>Moreover, additional part of speech(POS) tagging information is not going in as the input to the pretrained model, but only regarded as special tokens.</strong></p>
<p>With such background, the paper Improved Baseline proposes "Typed entity marker punctioation method". <strong>Enclosing the entity with entity span(POS) and entity types(SUB/OBJ) without introducing new special tokens</strong>. This paper argues that enclosing the subject and object entities with â€œ@â€ and â€œ#â€ alone boosts the perfomance. Performance comparisions are given with the table below.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 20.333333333333332%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAtElEQVQY0z2QSQqEUAxEXSsqqIg4z7PgcP+zVfOy6EUIya96Sb6zLIuu61JVVWqaRsMw6L5vi77v1batuq6z4J38fZ+2bdPzPJbR0qvrWs40TVaUZSnf9xVFkdZ1NeE4jjqOw4YARxOGoeZ5VpIkBs+yTGmaCg5+ByomgscgCP5AAjNgAEVR2EDA6Kjpe55nXtd15XDSeZ5/AOZ93/W+r53Ed1CzJTq2wgOMZch5ntuGcRzrB4HUbvhk7M1gAAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211008223302060"
        title="image-20211008223302060"
        src="/static/2827eef5d8c6c1dc139a6170fa1839ff/c1b63/image-20211008223302060.png"
        srcset="/static/2827eef5d8c6c1dc139a6170fa1839ff/5a46d/image-20211008223302060.png 300w,
/static/2827eef5d8c6c1dc139a6170fa1839ff/0a47e/image-20211008223302060.png 600w,
/static/2827eef5d8c6c1dc139a6170fa1839ff/c1b63/image-20211008223302060.png 1200w,
/static/2827eef5d8c6c1dc139a6170fa1839ff/d61c2/image-20211008223302060.png 1800w,
/static/2827eef5d8c6c1dc139a6170fa1839ff/3c2d4/image-20211008223302060.png 2092w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<p>The team utilized <a href="https://kakaobrain.github.io/pororo/tagging/ner.html">Pororo NER POS Tagging function</a> for both train and test dataset. With Pororo POS tagger, the team experimented both (1) typed entity marker and (2) typed entity punctutation method. (1) Typed entity marked was fed into as an input of RBERT custom model, whereas (2) typed entity punctuation method was fed into its own custom model.</p>
<h3 id="1-typed-entity-marker-dataset-creation" style="position:relative;"><a href="#1-typed-entity-marker-dataset-creation" aria-label="1 typed entity marker dataset creation permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>(1) Typed Entity Marker Dataset Creation</h3>
<p>Instead of saving the tokenizer itself, the special tokens added with Pororo NER POS Tagging were saved as txt format file. It was later loaded as txt file, added to tokenizer with add<em>special</em>tokens() method. The embedding layer was resized accordingly. However, it is still remain unsolved that whether resizing embedding layer boosts the performance or harms the performance.</p>
<p>The following CSV files were created for time-saving purpose: Pororo POS tagging took 12+ hours for 40k train + test sentences.</p>
<ul>
<li><a href="https://raw.githubusercontent.com/boostcampaitech2/klue-level2-nlp-15/main/dataset/train_pororo_sub.csv?token=AG3HZNZI4TIT7XLSBIMJYHDBL4EVE">Pororo POS Tagging with [SUB-{POS}] [/SUB-{POS}] entity special tokens</a></li>
<li><a href="https://raw.githubusercontent.com/boostcampaitech2/klue-level2-nlp-15/main/dataset/train_typed_entity_marker_punct.csv?token=AG3HZN4TYFCN3HXLUWYQ7Y3BL4EVG">Pororo POS Tagging with improved baseline style <code>#^organization^ëŒ€ì•ˆì‹ ë‹¹#</code></a></li>
<li><a href="https://raw.githubusercontent.com/boostcampaitech2/klue-level2-nlp-15/main/dataset/train_punct_kor.csv?token=AG3HZN3VUMQMEUL337RH333BL4EVC">Pororo POS Tagging with improved baseline style translated into Korean <code>#^ì‚¬ëŒ^ì¡°ì§€ í•´ë¦¬ìŠ¨#</code></a></li>
</ul>
<h3 id="2-typed-entity-marker-punctuation-dataset-creation" style="position:relative;"><a href="#2-typed-entity-marker-punctuation-dataset-creation" aria-label="2 typed entity marker punctuation dataset creation permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>(2) Typed Entity Marker Punctuation Dataset Creation</h3>
<p>Teammate has created typed entity marker punctuation function as following:</p>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="0"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">tokenized_dataset</span><span class="mtk1">(</span><span class="mtk7 mtki">dataset</span><span class="mtk1">, </span><span class="mtk7 mtki">tokenizer</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk6">&quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">    Inserting typed entity markers to each sentences</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">    subject: @*type*subject word@ (e.g.  ê¹€í˜„ìˆ˜ -&gt; @*ì‚¬ëŒ*ê¹€í˜„ìˆ˜@)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">    object: #^type^object word# (e.g. #^ì§€ëª…^í•œêµ­#)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">    &lt;&lt;An Improved Baseline for Sentence-level Relation Extraction&gt;&gt;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">    &quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    type_dict </span><span class="mtk8">=</span><span class="mtk1"> {</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;PER&quot;</span><span class="mtk1">: </span><span class="mtk6">&quot;ì‚¬ëŒ&quot;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;LOC&quot;</span><span class="mtk1">: </span><span class="mtk6">&quot;ì§€ëª…&quot;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;ORG&quot;</span><span class="mtk1">: </span><span class="mtk6">&quot;ê¸°ê´€&quot;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;DAT&quot;</span><span class="mtk1">: </span><span class="mtk6">&quot;ë‚ ì§œ&quot;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;TIM&quot;</span><span class="mtk1">: </span><span class="mtk6">&quot;ì‹œê°„&quot;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;DUR&quot;</span><span class="mtk1">: </span><span class="mtk6">&quot;ê¸°ê°„&quot;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;MNY&quot;</span><span class="mtk1">: </span><span class="mtk6">&quot;í†µí™”&quot;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;PNT&quot;</span><span class="mtk1">: </span><span class="mtk6">&quot;ë¹„ìœ¨&quot;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;NOH&quot;</span><span class="mtk1">: </span><span class="mtk6">&quot;ìˆ˜ëŸ‰&quot;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk6">&quot;POH&quot;</span><span class="mtk1">: </span><span class="mtk6">&quot;ê¸°íƒ€&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    }</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    sentences </span><span class="mtk8">=</span><span class="mtk1"> []</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    e01, e02, sent </span><span class="mtk8">=</span><span class="mtk1"> dataset[</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">], dataset[</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">], dataset[</span><span class="mtk6">&#39;sentence&#39;</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    subject_start, subject_end, sub_type </span><span class="mtk8">=</span><span class="mtk1"> e01</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    object_start, object_end, obj_type </span><span class="mtk8">=</span><span class="mtk1"> e02</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    subj </span><span class="mtk8">=</span><span class="mtk1"> sent[e01[</span><span class="mtk7">0</span><span class="mtk1">]: e01[</span><span class="mtk7">1</span><span class="mtk1">] </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    obj </span><span class="mtk8">=</span><span class="mtk1"> sent[e02[</span><span class="mtk7">0</span><span class="mtk1">]: e02[</span><span class="mtk7">1</span><span class="mtk1">] </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">if</span><span class="mtk1"> subject_start </span><span class="mtk8">&lt;</span><span class="mtk1"> object_start:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        sent_ </span><span class="mtk8">=</span><span class="mtk1"> sent[:subject_start] </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk10">f</span><span class="mtk6">&#39;@*</span><span class="mtk7">{</span><span class="mtk1">type_dict[sub_type]</span><span class="mtk7">}</span><span class="mtk6">*&#39;</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> subj </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk6">&#39;@&#39;</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> \</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                    sent[subject_end </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">:object_start] </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk10">f</span><span class="mtk6">&#39;&amp;^</span><span class="mtk7">{</span><span class="mtk1">type_dict[obj_type]</span><span class="mtk7">}</span><span class="mtk6">^&#39;</span><span class="mtk1"> \</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                    </span><span class="mtk8">+</span><span class="mtk1"> obj </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk6">&#39;&amp;&#39;</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> sent[object_end </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">:]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        ss </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(sent[:subject_start]))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        se </span><span class="mtk8">=</span><span class="mtk1"> ss </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">4</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(subj))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        es </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> se </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(sent[subject_end </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">:object_start]))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        ee </span><span class="mtk8">=</span><span class="mtk1"> es </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">4</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(obj))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">else</span><span class="mtk1">:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        sent_ </span><span class="mtk8">=</span><span class="mtk1"> sent[:object_start] </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk10">f</span><span class="mtk6">&#39;&amp;^</span><span class="mtk7">{</span><span class="mtk1">type_dict[obj_type]</span><span class="mtk7">}</span><span class="mtk6">^&#39;</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> obj </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk6">&#39;&amp;&#39;</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> \</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                sent[object_end </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">:subject_start] </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk10">f</span><span class="mtk6">&#39;@*</span><span class="mtk7">{</span><span class="mtk1">type_dict[sub_type]</span><span class="mtk7">}</span><span class="mtk6">*&#39;</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> subj </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk6">&#39;@&#39;</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> \</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">                sent[subject_end </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">:]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        es </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(sent[:object_start]))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        ee </span><span class="mtk8">=</span><span class="mtk1"> es </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">4</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(obj))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        ss </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> ee </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(sent[object_end </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">1</span><span class="mtk1">:subject_start]))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        se </span><span class="mtk8">=</span><span class="mtk1"> ss </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk7">4</span><span class="mtk1"> </span><span class="mtk8">+</span><span class="mtk1"> </span><span class="mtk8">len</span><span class="mtk1">(tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(subj))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    sentences.</span><span class="mtk3">append</span><span class="mtk1">(sent_)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    max_length </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">256</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    senttokens </span><span class="mtk8">=</span><span class="mtk1"> tokenizer.</span><span class="mtk3">tokenize</span><span class="mtk1">(sent_)[:max_length </span><span class="mtk8">-</span><span class="mtk1"> </span><span class="mtk7">2</span><span class="mtk1">]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    input_ids </span><span class="mtk8">=</span><span class="mtk1"> tokenizer.</span><span class="mtk3">convert_tokens_to_ids</span><span class="mtk1">(senttokens)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    input_ids </span><span class="mtk8">=</span><span class="mtk1"> tokenizer.</span><span class="mtk3">build_inputs_with_special_tokens</span><span class="mtk1">(input_ids)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">return</span><span class="mtk1"> input_ids, ss, se, es, ee</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">processor</span><span class="mtk1">(</span><span class="mtk7 mtki">tokenizer</span><span class="mtk1">, </span><span class="mtk7 mtki">dataset</span><span class="mtk1">, </span><span class="mtk7 mtki">train_mode</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk6">&#39;&#39;&#39;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">    train_dataset = processor(tokenizer, train_df))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">    --&gt; train_dataloader = Dataloader(train_dataset, batch_size = ...)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk6">    &#39;&#39;&#39;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    features </span><span class="mtk8">=</span><span class="mtk1"> []</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    labels </span><span class="mtk8">=</span><span class="mtk1"> dataset[</span><span class="mtk6">&#39;label&#39;</span><span class="mtk1">].values</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">if</span><span class="mtk1"> train_mode:</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        labels </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">label_to_num</span><span class="mtk1">(dataset[</span><span class="mtk6">&#39;label&#39;</span><span class="mtk1">].values)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">for</span><span class="mtk1"> i </span><span class="mtk10">in</span><span class="mtk1"> </span><span class="mtk8">range</span><span class="mtk1">(</span><span class="mtk8">len</span><span class="mtk1">(dataset)):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        input_ids, new_ss, new_se, new_es, new_ee </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">tokenized_dataset</span><span class="mtk1">(dataset.iloc[i], tokenizer)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        label </span><span class="mtk8">=</span><span class="mtk1"> labels[i]</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        feature </span><span class="mtk8">=</span><span class="mtk1"> {</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk6">&#39;input_ids&#39;</span><span class="mtk1"> : input_ids,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk6">&#39;labels&#39;</span><span class="mtk1"> : label,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk6">&#39;ss&#39;</span><span class="mtk1">: new_ss,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk6">&#39;se&#39;</span><span class="mtk1">: new_se,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk6">&#39;es&#39;</span><span class="mtk1"> : new_es,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">            </span><span class="mtk6">&#39;ee&#39;</span><span class="mtk1"> : new_ee,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        }</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        features.</span><span class="mtk3">append</span><span class="mtk1">(feature)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    </span><span class="mtk10 mtki">return</span><span class="mtk1"> features</span></span></span></code></pre>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Sentence</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><strong>Typed Entity Marker Punctuation Method</strong></td>
<td align="center"><strong>#^ORG^ì¡°ì§€ í•´ë¦¬ìŠ¨#ì´ ì“°ê³  @<em>ORG</em>ë¹„í‹€ì¦ˆ@ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</strong></td>
</tr>
<tr>
<td align="center"><strong>Typed Entity Marker Korean Punctuation Method</strong></td>
<td align="center"><strong>&#x26;^ë‹¨ì²´^ì¡°ì§€ í•´ë¦¬ìŠ¨&#x26;ì´ ì“°ê³  @<em>ë‹¨ì²´</em>ë¹„í‹€ì¦ˆ@ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</strong></td>
</tr>
</tbody>
</table>
<p>Rather than merely implementing the paper <a href="https://arxiv.org/pdf/2102.01373v3.pdf">An Improved Baseline for Sentence-level Relation Extraction(Zhou et al. 2021)</a>, the team went two steps further.</p>
<p>First, we translated the english entity marker punctuation into Korean word. This was because pretraind <code>klue/roberta-large</code> tokenizer's english vocabulary sets are more or less than 800 words out of 32000 token vocab sets. Thus the team decided that using Korean punctuation rather than english punctuation in order to boost performance.</p>
<p>Moreover, the team replaced <code>#</code> punctuation representation with <code>&#x26;</code> representation. Since the team is using pretrained RoBERTa, <code>#</code> is often found in tokenizers as sub-word representations(<code>ì•ˆë…•í•˜ì„¸ìš”</code> -> [<code>ì•ˆë…•</code>, <code>##í•˜ì„¸ìš”</code>]). Therefore we thought that <code>&#x26;</code> would be better for annotation for the punctuation representation.</p>
<h3 id="fixing-preprocessor" style="position:relative;"><a href="#fixing-preprocessor" aria-label="fixing preprocessor permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fixing Preprocessor</h3>
<p>Upon receiving baseline code, I encountered that the baseline's code has errors. For example, the baseline's preprocessing code splitted nested json as column value of the pandas dataframe as such.</p>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="1"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">preprocessing_dataset</span><span class="mtk1">(</span><span class="mtk7 mtki">dataset</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  subject_entity </span><span class="mtk8">=</span><span class="mtk1"> []</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  object_entity </span><span class="mtk8">=</span><span class="mtk1"> []</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk10 mtki">for</span><span class="mtk1"> i,j </span><span class="mtk10">in</span><span class="mtk1"> </span><span class="mtk8">zip</span><span class="mtk1">(dataset[</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">], dataset[</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">]):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    i </span><span class="mtk8">=</span><span class="mtk1"> i[</span><span class="mtk7">1</span><span class="mtk1">:</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">].</span><span class="mtk3">split</span><span class="mtk1">(</span><span class="mtk6">&#39;,&#39;</span><span class="mtk1">)[</span><span class="mtk7">0</span><span class="mtk1">].</span><span class="mtk3">split</span><span class="mtk1">(</span><span class="mtk6">&#39;:&#39;</span><span class="mtk1">)[</span><span class="mtk7">1</span><span class="mtk1">] </span><span class="mtk5 mtki"># &lt;- ERROR OCCURS</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    j </span><span class="mtk8">=</span><span class="mtk1"> j[</span><span class="mtk7">1</span><span class="mtk1">:</span><span class="mtk8">-</span><span class="mtk7">1</span><span class="mtk1">].</span><span class="mtk3">split</span><span class="mtk1">(</span><span class="mtk6">&#39;,&#39;</span><span class="mtk1">)[</span><span class="mtk7">0</span><span class="mtk1">].</span><span class="mtk3">split</span><span class="mtk1">(</span><span class="mtk6">&#39;:&#39;</span><span class="mtk1">)[</span><span class="mtk7">1</span><span class="mtk1">] </span><span class="mtk5 mtki"># &lt;- ERROR OCCURS</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    subject_entity.</span><span class="mtk3">append</span><span class="mtk1">(i)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">    object_entity.</span><span class="mtk3">append</span><span class="mtk1">(j)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  out_dataset </span><span class="mtk8">=</span><span class="mtk1"> pd.</span><span class="mtk3">DataFrame</span><span class="mtk1">({</span><span class="mtk6">&#39;id&#39;</span><span class="mtk1">:dataset[</span><span class="mtk6">&#39;id&#39;</span><span class="mtk1">], </span><span class="mtk6">&#39;sentence&#39;</span><span class="mtk1">:dataset[</span><span class="mtk6">&#39;sentence&#39;</span><span class="mtk1">],</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">:subject_entity,</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">:object_entity,</span><span class="mtk6">&#39;label&#39;</span><span class="mtk1">:dataset[</span><span class="mtk6">&#39;label&#39;</span><span class="mtk1">],})</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk10 mtki">return</span><span class="mtk1"> out_dataset</span></span></span></code></pre>
<p>When preprocessing CSV format dataset, handling the data's value with comma should be handled with care. According to the code above, numerical string <code>100,000</code> could be splitted into different columns.</p>
<p>So I fixed the code with the following code.</p>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="2"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">pull_out_dictionary</span><span class="mtk1">(</span><span class="mtk7 mtki">df_input</span><span class="mtk1">: pd.DataFrame):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk6">&quot;&quot;&quot; pull out str `{}` values from the pandas dataframe and shape it as a new column&quot;&quot;&quot;</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  df </span><span class="mtk8">=</span><span class="mtk1"> df_input.</span><span class="mtk3">copy</span><span class="mtk1">()</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk5 mtki"># assign subject_entity and object_entity column values type as dictionary</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  df[</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">] </span><span class="mtk8">=</span><span class="mtk1"> df[</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: </span><span class="mtk8">eval</span><span class="mtk1">(x))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  df[</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">] </span><span class="mtk8">=</span><span class="mtk1"> df[</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: </span><span class="mtk8">eval</span><span class="mtk1">(x))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk5 mtki"># parse item inside of subject_entity and object_entity&#39;s dictionary values as columns of dataframe</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk5 mtki"># word, start_idx, end_idx, type as new columns</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  df </span><span class="mtk8">=</span><span class="mtk1"> df.</span><span class="mtk3">assign</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">      </span><span class="mtk5 mtki"># subject_entity</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">      </span><span class="mtk4 mtki">subject_word</span><span class="mtk8">=</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;word&#39;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">      </span><span class="mtk4 mtki">subject_start_idx</span><span class="mtk8">=</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;start_idx&#39;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">      </span><span class="mtk4 mtki">subject_end_idx</span><span class="mtk8">=</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;end_idx&#39;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">      </span><span class="mtk4 mtki">subject_type</span><span class="mtk8">=</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;type&#39;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">      </span><span class="mtk5 mtki"># object_entity</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">      </span><span class="mtk4 mtki">object_word</span><span class="mtk8">=</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;word&#39;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">      </span><span class="mtk4 mtki">object_start_idx</span><span class="mtk8">=</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;start_idx&#39;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">      </span><span class="mtk4 mtki">object_end_idx</span><span class="mtk8">=</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;end_idx&#39;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">      </span><span class="mtk4 mtki">object_type</span><span class="mtk8">=</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">].</span><span class="mtk3">apply</span><span class="mtk1">(</span><span class="mtk10">lambda</span><span class="mtk1"> </span><span class="mtk7 mtki">x</span><span class="mtk1">: x[</span><span class="mtk6">&#39;type&#39;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  )</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk5 mtki"># drop subject_entity and object_entity column</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  df </span><span class="mtk8">=</span><span class="mtk1"> df.</span><span class="mtk3">drop</span><span class="mtk1">([</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">, </span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">], </span><span class="mtk4 mtki">axis</span><span class="mtk8">=</span><span class="mtk7">1</span><span class="mtk1">)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk10 mtki">return</span><span class="mtk1"> df</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk10">def</span><span class="mtk1"> </span><span class="mtk3">preprocessing_dataset</span><span class="mtk1">(</span><span class="mtk7 mtki">dataset</span><span class="mtk1">):</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk5 mtki"># pull out nested json into separate pandas columns</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  dataset </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">pull_out_dictionary</span><span class="mtk1">(dataset)</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk5 mtki"># rename columns subject_word as subject_entity, object_word as object_entity</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  dataset </span><span class="mtk8">=</span><span class="mtk1"> dataset.</span><span class="mtk3">rename</span><span class="mtk1">(</span><span class="mtk4 mtki">columns</span><span class="mtk8">=</span><span class="mtk1">{</span><span class="mtk6">&#39;subject_word&#39;</span><span class="mtk1">: </span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">, </span><span class="mtk6">&#39;object_word&#39;</span><span class="mtk1">: </span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">})</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  out_dataset </span><span class="mtk8">=</span><span class="mtk1"> pd.</span><span class="mtk3">DataFrame</span><span class="mtk1">({</span><span class="mtk6">&#39;id&#39;</span><span class="mtk1">:dataset[</span><span class="mtk6">&#39;id&#39;</span><span class="mtk1">], </span><span class="mtk6">&#39;sentence&#39;</span><span class="mtk1">:dataset[</span><span class="mtk6">&#39;sentence&#39;</span><span class="mtk1">],</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">:dataset[</span><span class="mtk6">&#39;subject_entity&#39;</span><span class="mtk1">],</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">:dataset[</span><span class="mtk6">&#39;object_entity&#39;</span><span class="mtk1">],</span><span class="mtk6">&#39;label&#39;</span><span class="mtk1">:dataset[</span><span class="mtk6">&#39;label&#39;</span><span class="mtk1">],})</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk3">display</span><span class="mtk1">(out_dataset.</span><span class="mtk3">head</span><span class="mtk1">(</span><span class="mtk7">2</span><span class="mtk1">))</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">  </span><span class="mtk10 mtki">return</span><span class="mtk1"> out_dataset</span></span></span></code></pre>
<h3 id="setting-maximum-token-length-for-roberta-tokenizer" style="position:relative;"><a href="#setting-maximum-token-length-for-roberta-tokenizer" aria-label="setting maximum token length for roberta tokenizer permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setting maximum token length for RoBERTa tokenizer</h3>
<p><a href="https://wandb.ai/danielkim30433/huggingface/reports/Comparison-through-changing-max_length-parameter--VmlldzoxMDc1NTE0?accessToken=4r9exwlxam05iy0u0aaexwxfpgl041hyno7gsxthwygf37hgq4xg2kbj66dtj1gf">ğŸ“ˆ wandb: Comparison through changing "max_length" parameter</a></p>
<p><a href="(https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/dev/v03/token_length%EA%B4%80%EB%A0%A8.ipynb)">ğŸ Jupyter Notebook for EDA for KLUE Relation Extraction dataset</a></p>
<p>There are only 460 sentences out of 32.5k train set that exceeded the token length of 128, using <code>klue/roberta-base</code> wordpiece tokenizers. Thus we set the maximum token length as 128.</p>
<p>Thanks for my teammate's concise inspection for finding optimal max<em>token</em>length in EDA, <strong>it is confirmed that each of the class label's token length distribution are uniform to one another</strong>. Therefore even if we drop 460 sentences which exceeds maximum<em>token</em>length, balance of data between the classes wouldn't be affected.</p>
<table>
<thead>
<tr>
<th align="center">Class 1</th>
<th align="center">Class 2</th>
<th align="center">Class 3</th>
<th align="center">...</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><img src="../assets/images/2021-10-08-Relation-Extraction/7E22FA0E-BBEC-4742-96C8-46E316D30CCA.png" alt="img"></td>
<td align="center"><img src="../assets/images/2021-10-08-Relation-Extraction/AE0C1743-6B50-4819-898D-D0500A671AEE.png" alt="img"></td>
<td align="center"><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 368px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 71.33333333333334%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAACkklEQVQ4y52SbUiTURTHr9EHIZQoC3Ss5RwaFftg1Ach6kNBfQgqJAgK9UNUaGo4tam9Q1HhC82YFVFRUKjzNedLsxdqFSW+IRo2p266uRl7fUr37Hnu6d6rPRiFSgf+cO95zvnd/zk8yGw2I7vdftrv938JBILt3RaHiZ/5YeK4oCkQCJiCweCSInUdHMd9nJiYuIwAAE06HPdhPtIefoZrxiH4nyCmjAxos9l0oijS3My+irfC1gttAjkLIsYCXp5CtNnr9dairq4u5PF4ysICZQB/6I4ZUq53shdJoaTFgnwPzwPrEImIb5aRKproHvfyyVc6YPet16xQXAbsL6DVakWTU+5ymsh51sOvOFENe0rfADcbloBLufwDSHdoHbNV0kR+TR+/Orse4jRNcLFxgBWTRUrjLxs4MjrOgJrqXgaMzWuCVP0H8P/kpdEX7nRRYH9/P3K4pstoIo8Ao7PqILHYCBR8s21Ickkliv8G/+VwaNiip4nC2j4+KsuAE7QtWFHYjJOKjbh9wEk7JYUJmTjGBM6E2Vn8DTQwIIS48rYBJyiLjLy84AVWnGuBjUSy/GacWNKKy18OQ6/dB8Ou4EK4ZJCIAX0+35zDkHdKd7dzEFadfC7Ea+phQ14dyIkURHFnDRCbawCFpgFv0jbCvVdfYcTpgZ5RN/SNuUEIzYLV6RHt3wPgcrnYf7jyvLZAVdnwLikmQ6+Sn3mqXLs/e9u6g1q1LPOJUpn5QCVLLVFHpxzdFXlMr0LJRYlputYE+d70ncmnSrfwPnfCpepP8ccLb2zPzslRz41MVFH/HkWlV6G4jNtoRy+gzY85tP7IVfpgJNEaIlkEQjFqcj+QX8F6Dj8aRNM2C8rV1bA7jV+nP4FINnePrwAAAABJRU5ErkJggg=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="img"
        title="img"
        src="/static/23e5f273927664d874a3750259602771/2b727/F4C5C509-3CA8-4FEB-8E91-A00F2E1BD7BA.png"
        srcset="/static/23e5f273927664d874a3750259602771/5a46d/F4C5C509-3CA8-4FEB-8E91-A00F2E1BD7BA.png 300w,
/static/23e5f273927664d874a3750259602771/2b727/F4C5C509-3CA8-4FEB-8E91-A00F2E1BD7BA.png 368w"
        sizes="(max-width: 368px) 100vw, 368px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>It was important to summate token length +4 in order to compensate for later added special entity tokens. For example, four entity tokens added to the sentence were <code>[SUB-ORGANIZATION]</code>, <code>[/SUB-ORGANIZATION]</code>, <code>[OBJ-LOCATION]</code>, <code>[/OBJ-LOCATION]</code>.</p>
<p>It should be careful that padding="max_length", not set as padding=True, so that the sentences are truncated(or sliced) properly.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 36.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAAsTAAALEwEAmpwYAAABjElEQVQY0zWQ60+CUBiH+bNrlWbZureurrV1UVAotEa21sXqQ9O0SIVWKy2oTE0QzjkcwDjWitp699uzd++XZ7+XQtgt3tbk+8alpMpVTWk4St16frdfmq7adJBZc6CCTdUGKjYVy3wlxPv+H0qumv00DMZRKGH1xUCAQYs7T3Q6x+6f53PJB3G5Ki48FiOPxaWKOFcp0V9fXQhAq9XqdDqUVNEHolqQ1gdpLRDTwwl9hNNDTHso3oxs360K0spOaSMtrQnSLFeK7d0Q8mljbBjGr/mmagxzYHQLjSdhmIMBBg6xcGQT9URxMIGFTHbv5EwW2fptRC0vKDLjmxFCf+YPqvzQ7l1vh+JGmDUG/zjMGqF4e4ZX0plMLsvns6yY58Q8W8gxhYvNK/HMNA3XdT3P8836RBJMb4N5AUylwGQSjPEoItR3TwvC6XUqU+YOyvyxlDqWfG4dyfyh+PbW0FoaIYQipGvZnh/s/BJiD/m77ZlWF1hdiAmwiH+0HNLUgFrTGhqyHdv/lt/5B6EfVhRD86w4AAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211008012353902"
        title="image-20211008012353902"
        src="/static/c1111961c4641d4965caada80c655045/c1b63/image-20211008012353902.png"
        srcset="/static/c1111961c4641d4965caada80c655045/5a46d/image-20211008012353902.png 300w,
/static/c1111961c4641d4965caada80c655045/0a47e/image-20211008012353902.png 600w,
/static/c1111961c4641d4965caada80c655045/c1b63/image-20211008012353902.png 1200w,
/static/c1111961c4641d4965caada80c655045/35890/image-20211008012353902.png 1582w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 36.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAAsTAAALEwEAmpwYAAABW0lEQVQY0z2OS0/CQBSF+6fdmGCRCohuJXFFDOXVSgy6cOUrPhJdGCKJkIiK0sjATDvtzBTolBa9xejNl8nJ5J57jhIuot7r6Lk/6vSsp96w3R2iCY6nH4GwpAziOA5DCYBY/M1yufxejTImPFunm3Wu1b28yRMMVDp+uLluTn0GG/+r/5oxhtAoiqLEnDpAqTJRdbxRxpkqztTstRJTdfvskdqow9Ct7w3BFMdLAMyz2YxSCocUhFneoFlTZE2+ZfBMg2sNnjOYWmPrun9x1WrfFd/796vY+DdZCDEZT+bzuYIdkdERpKUrBPJXFUgaqBCtBthqxS6ekMYl3T91q+fjQbflOl+c+2EYQrK3Y5LdJi2YFCoUDmmiV++2SXOGkzecnEG1mpOuulqd7h29DD5HBENyoCwWkSskZdLj0uWSeNL2EgE/CTxwWAITEjtsYOE3i/nTWRAE0P8HkKFi7+SOGusAAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211008012403171"
        title="image-20211008012403171"
        src="/static/35ae088a50c5bd178760f7f18d858092/c1b63/image-20211008012403171.png"
        srcset="/static/35ae088a50c5bd178760f7f18d858092/5a46d/image-20211008012403171.png 300w,
/static/35ae088a50c5bd178760f7f18d858092/0a47e/image-20211008012403171.png 600w,
/static/35ae088a50c5bd178760f7f18d858092/c1b63/image-20211008012403171.png 1200w,
/static/35ae088a50c5bd178760f7f18d858092/ddb6a/image-20211008012403171.png 1592w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<p>Batching strategies by <a href="https://huggingface.co/transformers/main_classes/data_collator.html">using huggingface's data collate class</a>, <a href="https://youtu.be/7q5NyFT8REg">applying dynamic padding</a>, or making custom <a href="https://mccormickml.com/2020/07/29/smart-batching-tutorial/">uniform length batching function</a> is known to decrease the train time significantly as following. <span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 28.333333333333332%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAABEUlEQVQY0zVQWZaDMAzjFNOyBcK+Q4HS6f0PppHc6UdeEluSJQfX68KyrrjHCXxRIs1yFGWF49iRuAzzssDlOaqmQdt1iJLU+t/eY9+xbRtWHkdu8H7/4rqeCCkoQNf3yLzH83kaeWFNQ6Z5wjiOJtQPA6LUYd8fxj3Ow456wcbiME0GmEiWkyjNUPKOCWg0oChQty1avp0vDJcxjThN16MfJ9a9/YOTTgQI5Ya2u//pGYkS9FWFNPfIyxKeUSWkmLrFUa2sP8NNcGCMmm5uYcTIM5u1vT0FblFszhQl5wDVYucsvtbwcw9REd+0na3sTnwgEbmSSMOla+FqJJwmkIjaZcy/zneHeguX8i/MRzDBH8l8qmB9ozH8AAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211008012609016"
        title="image-20211008012609016"
        src="/static/d013db1049e251de7dae7d521842ff6e/c1b63/image-20211008012609016.png"
        srcset="/static/d013db1049e251de7dae7d521842ff6e/5a46d/image-20211008012609016.png 300w,
/static/d013db1049e251de7dae7d521842ff6e/0a47e/image-20211008012609016.png 600w,
/static/d013db1049e251de7dae7d521842ff6e/c1b63/image-20211008012609016.png 1200w,
/static/d013db1049e251de7dae7d521842ff6e/d61c2/image-20211008012609016.png 1800w,
/static/d013db1049e251de7dae7d521842ff6e/c9d77/image-20211008012609016.png 1964w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<p>It is noteworthy that uniform length batching(or smart batching on the table) increased the model's performance. Due to time constraint, in this competition we applied dynamic padding only.</p>
<p>batch_size were selected to be bigger than 30 since we assumed batch numbers being bigger than class numbers would have reduced the bias towards certain classes.</p>
<h3 id="data-augmentation" style="position:relative;"><a href="#data-augmentation" aria-label="data augmentation permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data Augmentation</h3>
<p>Attempted KoEDA(Easy Data Augmentation implemented in Korean Language) for the dataset. Teammate applied Random Insertion, Random Deletion, Random Swap, Synonym Replacement but this have not led to notable increase in performance.</p>
<h2 id="model--finetuning" style="position:relative;"><a href="#model--finetuning" aria-label="model  finetuning permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Model &#x26; Finetuning</h2>
<h3 id="how-to-select-pretrained-model" style="position:relative;"><a href="#how-to-select-pretrained-model" aria-label="how to select pretrained model permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How to select pretrained model</h3>
<p>We fixed error entailed from using klue/roberta-large huggingface model <a href="https://github.com/KLUE-benchmark/KLUE/issues/33">and provided walk-through solution on this Github Issue</a>. This was fixed by setting <code>return_token_type_ids=False</code> argument on the tokenizer encoding function. Since RoBERTa didn't have token type mask, tokenizer should not return token<em>type</em>ids.</p>
<pre class="grvsc-container one-dark-pro" data-language="python" data-index="3"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">tokenized_sentences </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk3">tokenizer</span><span class="mtk1">(</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        concat_entity,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk8">list</span><span class="mtk1">(dataset[</span><span class="mtk6">&quot;sentence&quot;</span><span class="mtk1">]),</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">return_tensors</span><span class="mtk8">=</span><span class="mtk6">&quot;pt&quot;</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">padding</span><span class="mtk8">=</span><span class="mtk7">True</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">truncation</span><span class="mtk8">=</span><span class="mtk7">True</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">max_length</span><span class="mtk8">=</span><span class="mtk7">256</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">add_special_tokens</span><span class="mtk8">=</span><span class="mtk7">True</span><span class="mtk1">,</span></span></span>
<span class="grvsc-line"><span class="grvsc-source"><span class="mtk1">        </span><span class="mtk4 mtki">token_type_ids</span><span class="mtk1"> </span><span class="mtk8">=</span><span class="mtk1"> </span><span class="mtk7">False</span><span class="mtk1"> )</span><span class="mtk5 mtki"># for klue/roberta-large</span></span></span></code></pre>
<p>Pretrained model selection was based on given model benchmarks in fields of task. The task we focused on were relation extraction. If not given the corresponding performance for RE(relation extraction), we looked at Named Entity Recognition and Natural Language Inference.</p>
<p>Model Benchmarks given by <a href="https://github.com/KLUE-benchmark/KLUE#baseline-scores">KLUE's benchmark scores</a></p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Total Combined</th>
<th>Natural Language Inference</th>
<th>Named Entity Recognition</th>
<th></th>
<th>Relation Extraction</th>
<th></th>
<th>MRC</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Score</strong></td>
<td>F1</td>
<td>ACC</td>
<td>entity F1</td>
<td>char F1</td>
<td>F1</td>
<td>AUPRC</td>
<td>EM</td>
<td>ROUGE</td>
</tr>
<tr>
<td><strong>XLM-R-base</strong></td>
<td>83.52</td>
<td>77.33</td>
<td>80.73</td>
<td>91.37</td>
<td>57.46</td>
<td>54.98</td>
<td>27.48</td>
<td>53.93</td>
</tr>
<tr>
<td><strong>XLM-R-large</strong></td>
<td>86.06</td>
<td>85.93</td>
<td>81.81</td>
<td>92.49</td>
<td>58.39</td>
<td>61.15</td>
<td>35.99</td>
<td>66.77</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>KR-BERT-base</strong></td>
<td>84.58</td>
<td>77.17</td>
<td>75.37</td>
<td>90.42</td>
<td>62.74</td>
<td>60.94</td>
<td>48.28</td>
<td>58.54</td>
</tr>
<tr>
<td><strong>koELECTRA-base</strong></td>
<td>84.59</td>
<td><em>85.63</em></td>
<td><strong><em>86.82</em></strong></td>
<td><strong><em>92.79</em></strong></td>
<td>62.85</td>
<td>58.94</td>
<td>59.82</td>
<td>66.05</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>KLUE-BERT-base</strong></td>
<td><em>85.49</em></td>
<td>81.63</td>
<td>84.77</td>
<td>91.28</td>
<td>66.44</td>
<td>66.17</td>
<td>62.32</td>
<td>68.51</td>
</tr>
<tr>
<td><strong>KLUE-RoBERTa-base</strong></td>
<td>85.12</td>
<td>84.97</td>
<td>85.13</td>
<td>91.52</td>
<td><em>66.66</em></td>
<td><em>67.74</em></td>
<td><em>68.52</em></td>
<td><em>74.02</em></td>
</tr>
<tr>
<td><strong>KLUE-RoBERTa-large</strong></td>
<td><strong>86.42</strong></td>
<td><strong>89.43</strong></td>
<td>85.79</td>
<td>91.77</td>
<td><strong>69.59</strong></td>
<td><strong>72.39</strong></td>
<td><strong>76.78</strong></td>
<td><strong>81.43</strong></td>
</tr>
</tbody>
</table>
<p>We also referred to another model benchmarks given by <a href="https://github.com/tunib-ai/tunib-electra">Tunib-Electra's benchmark scores</a> and <a href="https://github.com/monologg/KoELECTRA">KoElectra's benchmark scores</a></p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center"><strong># Params</strong></th>
<th align="center"><strong>Avg.</strong></th>
<th align="center"><strong>Naver NER</strong> (F1)</th>
<th align="center"><strong>KorNLI</strong> (acc)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><strong><em>TUNiB-Electra-ko-base</em></strong></td>
<td align="center">110M</td>
<td align="center"><strong>85.99</strong></td>
<td align="center">87.63</td>
<td align="center"><strong>82.27</strong></td>
</tr>
<tr>
<td align="center"><strong><em>TUNiB-Electra-ko-en-base</em></strong></td>
<td align="center">133M</td>
<td align="center">85.34</td>
<td align="center">87.25</td>
<td align="center">80.43</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/monologg/KoELECTRA">KoELECTRA-base-v3</a></td>
<td align="center">110M</td>
<td align="center">85.92</td>
<td align="center"><strong>88.11</strong></td>
<td align="center">82.24</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/Beomi/KcELECTRA">KcELECTRA-base</a></td>
<td align="center">124M</td>
<td align="center">84.75</td>
<td align="center">86.90</td>
<td align="center">81.65</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/SKTBrain/KoBERT">KoBERT-base</a></td>
<td align="center">90M</td>
<td align="center">81.92</td>
<td align="center">86.11</td>
<td align="center">79.00</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/Beomi/KcBERT">KcBERT-base</a></td>
<td align="center">110M</td>
<td align="center">79.79</td>
<td align="center">84.34</td>
<td align="center">74.85</td>
</tr>
<tr>
<td align="center"><a href="https://github.com/pytorch/fairseq/tree/master/examples/xlmr">XLM-Roberta-base</a></td>
<td align="center">280M</td>
<td align="center">83.03</td>
<td align="center">86.26</td>
<td align="center">79.92</td>
</tr>
<tr>
<td align="center">HanBERT</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">87.70</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">XLM-Roberta-Base</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">86.65</td>
<td align="center">-</td>
</tr>
</tbody>
</table>
<p>We first tested KoElectra as backbone model, since its NER performance was the highest. But we later on switched to RoBERTA.</p>
<p><a href="https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/snoop/notebooks/EDA.ipynb">By counting the number of unk tokens of the pretrained models</a>, we assumed that the lower unknown tokens appeared, the better the model's performance it would be. <strong>Given that the number of unknown tokens are the fewest on klue/roberta-base model, we decided to stick with the klue-pretrained models.</strong></p>
<h3 id="how-we-fine-tuned-the-model-according-to-the-relation-extraction-task" style="position:relative;"><a href="#how-we-fine-tuned-the-model-according-to-the-relation-extraction-task" aria-label="how we fine tuned the model according to the relation extraction task permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How we Fine-tuned the model according to the relation extraction task</h3>
<p><a href="https://paperswithcode.com/sota/relation-extraction-on-tacred">Based on TACRED Benchmark Leaderboard</a>, our team decided to test SOTA model according to the order. Along with TACRED score, the team also referred to <a href="https://aclanthology.org/P19-1279.pdf">Matching the Blanks: Distributional Similarity for Relation Learning. Soares et al. 2019</a> to find where to extract hidden features from.</p>
<p>According to <a href="https://aclanthology.org/P19-1279.pdf">Matching the Blanks: Distributional Similarity for Relation Learning. Soares et al. 2019</a>, The best tokens to extract features from were either (1) pooling multiple entity tokens' hidden states or (2) extract the first entity markers of each subject entity and object entity. Provided model's structure from the paper are given as below, along with its methods' performance.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 52%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB2UlEQVQoz0VSiXKjMAzl/z9tZ7eTBApJCOG2MSGU+zCQt7LTUs9oLOlJlvRkY10GzEMOdV4/8nppe10kxoZhmerd/4stmLoCcqywvX5zjFnOCAIXvmvjThKFAaRcsG4bkugO1/qDm/2BOIqw0CM/55EzeM4H7pcTGGNY1/X9oErMeIKCByiyiAIFVLFxGsFZjDJPkKc+ciEwz7NOKp5P+N4VWehRURecsx0z8NowDjX6fsQ0zVrU6fsebdsR1qLvSPpB+1SXdV2jqRu0TYmu68huNKbGNqQcUVUCbTegblsM47i337U1HuyC8slJr/BNEzaaqsoLfJUCT5ZiJop2Dpd1Ix4+cf88wLOO8M6O5k+JT37PIp5sk2IcyG8OVVHX/IuA8OvxH2Lf37mlpUjkLKKKDF9ZSpwprqQepRTk4xGaQhC/mR5bUnzTNHjyd04tOMqiIM6n98hlWYLxDIwSEsaRpCmSJEFEW01pe1GSap/S4ziGoOWom2UCQRiBixwR2SnFqMUYYRjCNE04jqPFtu1dP51OsCyL8Pd9OBx2n8JN0o/Ho7bVXVUVDPWHzuczPM+j/xjAdV1cLhdcr1d93243+hYcj8cDeZ5rXUlGE6muVMcKU+9MNPZ/IGrvdGCAJvwAAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211010175325279"
        title="image-20211010175325279"
        src="/static/04eace37e68b7febdcebaeeaeb3a9d14/c1b63/image-20211010175325279.png"
        srcset="/static/04eace37e68b7febdcebaeeaeb3a9d14/5a46d/image-20211010175325279.png 300w,
/static/04eace37e68b7febdcebaeeaeb3a9d14/0a47e/image-20211010175325279.png 600w,
/static/04eace37e68b7febdcebaeeaeb3a9d14/c1b63/image-20211010175325279.png 1200w,
/static/04eace37e68b7febdcebaeeaeb3a9d14/d61c2/image-20211010175325279.png 1800w,
/static/04eace37e68b7febdcebaeeaeb3a9d14/6052f/image-20211010175325279.png 2030w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 51%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABmElEQVQoz02S646CQAyFef8XWzWAxhsq3kFUvMuKeEnOzteEZH800+m0p6en471eL1VVpff7re/3q8/nYz7x0+mkbreryWSi5/OpPM+1Wq0sBz+OYz0eDy0WCw2HQ6vxSNxsNq6wI99vqdMJNR6PdTgctFwu1Ww21e/3DWC322k+n6soCqsB8Hq9qtfrqdFoWFMDvN8LRVGiIBgrDEfabnPX+VdputHtdtNoRGxroGmamgFOjMYYb8awqp6uqHBAqeuy1M/PTEmSqywfrtHd5GCk8/lsDGCEFGVZ6nK5GBCMaUyuB2ocTxxQU1m2d2xitVotG+l4PFoRwPgYfg0EOP5+vzfGBoioCBqGoRshM/183zf9WAbJMGA87vgwHAwGxhpm5LIsA+QxCAK12223mJ6m06n5MEQ7WGDoVAMCFEWRseMOGKD8Eo/H9XptQDwkSWKaITxJAOHDFJZYlmWWx1nHqbUtE6AbbDDG585X+H/HZrOZxfAhwBujE+O/MpUHA3SDPoYE6MIJe5bAnbNeSL0opKhz8Nn8H15q4moPMg3iAAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211010175418328"
        title="image-20211010175418328"
        src="/static/684faaf06c4466e8dfde49a99141b4d8/c1b63/image-20211010175418328.png"
        srcset="/static/684faaf06c4466e8dfde49a99141b4d8/5a46d/image-20211010175418328.png 300w,
/static/684faaf06c4466e8dfde49a99141b4d8/0a47e/image-20211010175418328.png 600w,
/static/684faaf06c4466e8dfde49a99141b4d8/c1b63/image-20211010175418328.png 1200w,
/static/684faaf06c4466e8dfde49a99141b4d8/d61c2/image-20211010175418328.png 1800w,
/static/684faaf06c4466e8dfde49a99141b4d8/1a867/image-20211010175418328.png 1998w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<p>Thus the team chose customized Improved Baseline model for <code>(f) Entity Markers -Entity First</code> method and RBERT for <code>(e) Entity Markers - Mention Pool</code> method.</p>
<p><strong><a href="https://paperswithcode.com/paper/an-improved-baseline-for-sentence-level">ğŸ¤– Customized Improved Baseline Custom Model</a> (f1 0.736)</strong>
<span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 42.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABYlAAAWJQFJUiTwAAACeElEQVQoz1WSbUhTYRTHz/ZhamQvaB/SBBWKoFwShUFfKkIwshfQJBTE+hAFlVIQpH5IIaQI1AXFFEEssGagZZbzhXS6JnOyzLbrdnfbbt7ci3f3dtdemsvTs5nRDhye8zzPn9/z55wH4L9AxPX8/g1iZHXfrU3sYeP8370GJnLS80152y/F7lwDogCGYSAWi0FSSJIE0WgUwtRCGo9YbLt19YKo6TgCndH9WspbEpH85Ste7/E4wL4D8jypcPEz4p65nq5tNpttC8/zhUnASCSScPCbXsyUEJ9y9XVanH5TBy+w5gMjdq+Ff44IothKNIoHp2tybiuLz5C6ou76zcPNzc2HAoHAlSRgKBRKANecdIYfscFSXdaKz1vPQ710onfG0Sh6llROdqkW0aQA1UoutK2dQwydejdrzSIOs0VRrEwClpaWgkqlkqt7nsHw2HiFcXzstcU81zExO9+pnzH2zhqNA++HtW0NAHJZC5UPD5nLeAw2VXXPpBAjcofDsXm9yTKQIWuXkVrmcbsVDpoGg8HQwi0vo9lsxvlPZtRPTyPLskic+MjbigIXpmQ2avNJnbHv6MnUjaECrv6KAwHDQtIk7zU17R0bHa16OzhY1j8wUK7RaMp0Ol3lqz7N2Rt/Nf74GvAlfkR8mEQD8LjlfmY/wIGPT9oPWl2s0qDXFxAnBRzH7aYoKpvkLpqms1Z4f27Qx21FegrgEafsM1BKyvKlcHJSV2gymYqGhoaK1Gr1TrAb9CVWORg8/S9ZIbpqdzGMRRCERbfb7SRQ1uVyfSWx4PZ4BIn3dkFafTq089zIos8R/sHTThdLB4NBgfRPslqt1X8AA4Ciq6YjslYAAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211008225119287"
        title="image-20211008225119287"
        src="/static/cbf0fa5016baa03da9c3fe9bc673302a/c1b63/image-20211008225119287.png"
        srcset="/static/cbf0fa5016baa03da9c3fe9bc673302a/5a46d/image-20211008225119287.png 300w,
/static/cbf0fa5016baa03da9c3fe9bc673302a/0a47e/image-20211008225119287.png 600w,
/static/cbf0fa5016baa03da9c3fe9bc673302a/c1b63/image-20211008225119287.png 1200w,
/static/cbf0fa5016baa03da9c3fe9bc673302a/d61c2/image-20211008225119287.png 1800w,
/static/cbf0fa5016baa03da9c3fe9bc673302a/81ebd/image-20211008225119287.png 1868w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<ul>
<li><a href="https://github.com/boostcampaitech2/klue-level2-nlp-15/tree/dev">(1) first version code @dev branch</a></li>
<li><a href="https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/main/RE_improved_baseline.ipynb">(2) Improved_Baseline code</a> (f1 0.732)</li>
<li><a href="">(3) Improved Baseline kfold code</a> (f1 0.736)</li>
<li><a href="https://global-sunset-142.notion.site/RE_improved_baseline-a6f4bb9ecd2c4362996d18df507f4327">Notes for Improved Baseline</a></li>
</ul>
<p><strong><a href="https://paperswithcode.com/paper/enriching-pre-trained-language-model-with">ğŸ¤– Customized RBERT</a> (f1 0.745, <a href="https://wandb.ai/snoop2head/KLUE-RE?workspace=user-snoop2head">ğŸ“ˆ wandb</a>)</strong></p>
<p>ğŸ‘‰ <a href="https://snoop2head.github.io/Relation-Extraction-Code/">Please refer to my blog post for detailed RBERT finetuning process</a>
<span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 61.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAACQUlEQVQoz22S/U/acBDG+f//g+3X/bQtbskS52aWKEanm4IiBlARaIv0jb7T0pa2n51VYIle0t63T++eu+8910Csqip5Pfunp5TzqoRsVbFYrkiykjSviNMCJ0yJBVsVpcSV5MWKDYdYY31Y+yeLFzkz/Y6j8x16wwPiOKJzdM7eh120/ohQCuR5iea4/Lzp1DlFWdYcjaeP8oXMjHx2u232r1sMBn0+7f3m+lbBtgyOTi/Y+dXGDyJJroSwQnEcvl61+N8a6+48z6N/f8vO4QmtkUYlFR80SzpU8eVfGMUMVZPxRGURRfVYHucGnfEZaQaOHxIny+2VSyEo8hzX8VkmKUVRYNoOrgRKxdo7rs/cDV5GBJarM9KOpVv4uN+me6dtO1wTjx9t5v6CXFS57CvcK2aNq7pbdzjU7M317LnJaHAqolUct/qMNfO1KFPDRjcsPN+nOxgxnDyKSAsmms7DRGOszraEUvz8x1l9XoQhWZY+E1ZVuSGc2xau64qyMVHg0+te1dhCSJMkRtdnpGlax0aOx+XhXwrZuTzLt6I8tyhzFOfEqahqEwQhYZ5x8GdA/2EqOxnX2Ey3WK03TBLiMKrxSISqCYPIY2qqeGlCOlIJ7vqIJIShQ9a5pNnuMVAs1J6BGzhClqJNdIYDDS/x8KKQZRZvxtZQZg90ZLBm6pE1T1C/fcZYBmjKAOvde2bTG9m9gOaXG8bTIX5ic9aUQt8vMAIF0zFERGNLyBtmmaaoXLzCl7Jn87nzVspGg38DYY4iv+/zZQAAAABJRU5ErkJggg=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211008225126824"
        title="image-20211008225126824"
        src="/static/55ce894326815cec56f7c0f1037120b6/c1b63/image-20211008225126824.png"
        srcset="/static/55ce894326815cec56f7c0f1037120b6/5a46d/image-20211008225126824.png 300w,
/static/55ce894326815cec56f7c0f1037120b6/0a47e/image-20211008225126824.png 600w,
/static/55ce894326815cec56f7c0f1037120b6/c1b63/image-20211008225126824.png 1200w,
/static/55ce894326815cec56f7c0f1037120b6/5ba90/image-20211008225126824.png 1604w"
        sizes="(max-width: 1200px) 100vw, 1200px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<p><strong><a href="https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/085dd842e93a8d1e0d30f8cf42268ddb96cafd4a/notebooks/train_with_pororo_with_val_klue-roberta.ipynb">ğŸ¤– Customized Concat Model</a> (f1 0.730, <a href="https://wandb.ai/snoop2head/huggingface/runs/1d3hlfn6?workspace=user-snoop2head">ğŸ“ˆ wandb</a>)</strong></p>
<p>The concat method was given from the boostcamp as a baseline. It was simply putting Entity 1 and Entity 2 with <code>[SEP]</code> separator in the beginning of the tokenized input. We tried to exclude the concat in the beginning of the tokenized sentence, but this led to worse evaluation loss and evaluation accuracy: <a href="https://wandb.ai/danielkim30433/huggingface/runs/3e1lomf5?workspace=user-danielkim30433">ğŸ“ˆ wandb</a>. We concluded that putting concated subject entity and object entity in the beginning boosts the classification. Thus we also adopted customized concat model.</p>
<ul>
<li><a href="https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/main/train_with_pororo.ipynb">(1) pororo POS &#x26; Entity tagged &#x26; stratified 5-fold cross validation </a></li>
<li><a href="https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/snoop/notebooks/train_with_pororo_with_val.ipynb">(2) replaced bert model with xlm-roberta &#x26; applied focal loss(gamma=0.5)</a> (<a href="https://wandb.ai/snoop2head/huggingface/runs/2576sujh">ğŸ“ˆ wandb</a>, f1 0.70)</li>
<li><a href="https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/snoop/notebooks/train_with_pororo_with_val_klue-roberta.ipynb">(3) used klue/roberta-large model &#x26; applied focal loss(gamma=0.5)</a> (<a href="https://wandb.ai/snoop2head/huggingface/runs/1d3hlfn6?workspace=user-snoop2head">ğŸ“ˆ wandb</a>, f1 0.733)</li>
</ul>
<p><strong><a href="https://github.com/Saintfe/RECENT">ğŸ¤– RECENT / Duo classifier</a> (f1 0.60)</strong> required more time to study for our team and has not been fully implemented.</p>
<h3 id="findings-from-fine-tuning-methods" style="position:relative;"><a href="#findings-from-fine-tuning-methods" aria-label="findings from fine tuning methods permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Findings from fine-tuning methods</h3>
<p>Number of Epochs were decided by monitoring model's performance with ğŸ“ˆ wandb. KPI for the model's performance was set as evaluation loss.</p>
<ul>
<li>It was evident that concat model should not exceed more than 2000 training steps(or 3 epochs) as evaluation loss increased after then.</li>
<li>However, RBERT's evaluation loss kept decreasing until 3200 training steps(or 5 epochs). This might possibly show that <strong>RBERT providing more information about the entities' relation within the sentence with additional masks increases robustness.</strong></li>
<li>Improved Baseline is light-weight. Compared to RBERT which takes up 26GB of GPU capacity and taking 10hrs for 5 fold training, Improved Baseline on the other hand takes up about 15GB of GPU capacity and takes more or less than 4 hours for training.</li>
<li>Let's compare RBERT and Improved Baseline method. It is surprising that light-weight Improved Baseline(f1: 0.736) almost yielded similar performance as RBERT(f1: 0.745).</li>
<li>Improved Baseline only extracts first entity token marker whereas RBERT averages all the tokens between the entity tokens. <strong>One of the downside of averaging the hidden features of multiple entity tokens is that it ignores the order of the tokens given in the sentence.</strong> I think this is the reason that extracting the first token of the entity resulted in similar f1 score with RBERT method.</li>
</ul>
<h2 id="training" style="position:relative;"><a href="#training" aria-label="training permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Training</h2>
<h3 id="why-we-selected-focalloss-as-the-criterion" style="position:relative;"><a href="#why-we-selected-focalloss-as-the-criterion" aria-label="why we selected focalloss as the criterion permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why we selected FocalLoss as the criterion</h3>
<p><img src="https://user-images.githubusercontent.com/30318926/134863763-eac345a4-b4c2-46f3-b093-1fcbb284ce70.png" alt="img"></p>
<p>Looking at such class imbalance, the team tried to apply the distrubution of such classes as weights to CrossEntropy criterion and to LabelSmoothing criterion. It was worth trying, but it was better to apply focal loss, which yielded better output for the previous p-stage competition, as the criterion.
<span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1052px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 60.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAABwUlEQVQoz4WSbW/aMBSF+f+/Zl+6TdP2qV0ZCDRQIaQNpMYOwSROnDh24vglqVMo3YumHcmWr+Xn6Opcj7quzwtiO9P3feeK39W96Vxa2zXKOJ1vRm7hFDSyklJBCAkhSrWMsf0ecM7/8KrqBpGKUooxvsAA+lwU1tpduDsej03TFAUlJHNGWZZBBK8uilMVrQhJ4zi+wCQ7gmDtDg5rpXQurjG3q1e5LrTWZ7jmnMQ4y0hO8wFWSpM0mX//5F73/5Ns65xj17ZzHGAEIRPCm3/zF7PXiOzfsf1LI61dY1XJ0+XXD2HwKN9iPmd/9emsLcuyaeo8z4UQF3iIoVWmMyRHaHq7XdxDnFTK6F/mNbBGP/r+dDoZTyZlyd5h56SVES1L6IFsn/ByHC7HINhEp1NSNLW2aSW5NK3SRcF4JVrZci5cWAPsJnGID5QWtWQZP0XHMNquYm8W3H/Z3N4s7j4+/Pjs/bzzvQWII5gmGaOsrow1A5wkyTAPo1nJaE773qiuBYcwLbCQJAZeuJ6lhxVGM29+EwaTJxSAk/tXYoCv383tJCX+xl89rHfbHdoj8Lx/3qNtCCCKUYTf5zBk2b0AGkOoPTfR1xIAAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="image-20211008014220660"
        title="image-20211008014220660"
        src="/static/33d9c3744a70d4762fd9b4b7411aa557/218a4/image-20211008014220660.png"
        srcset="/static/33d9c3744a70d4762fd9b4b7411aa557/5a46d/image-20211008014220660.png 300w,
/static/33d9c3744a70d4762fd9b4b7411aa557/0a47e/image-20211008014220660.png 600w,
/static/33d9c3744a70d4762fd9b4b7411aa557/218a4/image-20211008014220660.png 1052w"
        sizes="(max-width: 1052px) 100vw, 1052px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<h3 id="how-we-selected-the-gamma-parameter-for-focal-loss" style="position:relative;"><a href="#how-we-selected-the-gamma-parameter-for-focal-loss" aria-label="how we selected the gamma parameter for focal loss permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How we selected the gamma parameter for Focal Loss</h3>
<p>The team experiment gamma paremeter by monitoring wandb for first 500 steps. For the first 500 steps, we designated f1 score and evaluation loss as the key primary index to determine the criterion's performance.</p>
<ul>
<li>FocalLoss 0.5, AdamP (lowest val/loss) -> 500 step, eval loss 0.69 is considered to be higher than the concat model's evaluation loss so the team increased the gamma value.</li>
<li>FocalLoss 1.0, AdamP (lowest val/loss) -> 500 step, eval loss 0.56 is considered to be adequate which was lower than concat model's loss. I was aware of the fact that increasing gamma value might risk the model to fall within the local minimum, so I stopped at 1.0</li>
<li>Teammate experimented gamma parameter started off from 2.0, which is concluded to be inadequate, thus the team's gamma parameter converged to 1.0.</li>
</ul>
<h3 id="how-we-selected-the-optimizer-adamp-vs-adamw" style="position:relative;"><a href="#how-we-selected-the-optimizer-adamp-vs-adamw" aria-label="how we selected the optimizer adamp vs adamw permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How we selected the optimizer AdamP vs AdamW</h3>
<p>Custom model's results were compared using wandb for first 500 steps. We concluded that AdamP of ClovaAI allowed model to converge the loss slightly faster than AdamW provided by huggingface. This is in accordance with ClovaAI team's benchmark when compared AdamW and AdamP.</p>
<p><img src="https://clovaai.github.io/AdamP/static/img/table07.svg" alt="img"></p>
<h3 id="other-important-details" style="position:relative;"><a href="#other-important-details" aria-label="other important details permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Other important details</h3>
<ul>
<li>Applying Stratified KFold alone increased the model's performance by +3%p for f1 score (0.67 -> 0.7) for public leaderboard</li>
<li>Schedule: linear vs cosine</li>
<li>Saving best model strategies were differed: accuracy, f1 score, eval/loss.</li>
</ul>
<h3 id="inferencing" style="position:relative;"><a href="#inferencing" aria-label="inferencing permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Inferencing</h3>
<ul>
<li>Out of fold ensemble when each of the is trained on train dataset.</li>
<li>
<p>Soft-voting ensemble the 1) best concat model, 2) best improved baseline model, 3) best RBERT model. Each of the model's saving criteria was different, which enabled further performance boost when scored in private leaderboard.</p>
<ol>
<li>Best concat model was based on best accuracy</li>
<li>Best Improved Baseline model was based on best f1 score</li>
<li>Best RBERT model was based on lowest evaluation loss</li>
</ol>
</li>
</ul>
<hr>
<h3 id="other-details-to-try-next-time" style="position:relative;"><a href="#other-details-to-try-next-time" aria-label="other details to try next time permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Other details to try Next time</h3>
<ul>
<li class="task-list-item"><input type="checkbox" disabled> str.replace() sometimes replaces not only target words/tokens, but other words/tokens that has same characters. If given the index of the target entity/token, it is better to use that even if it is such a nuisance.</li>
<li class="task-list-item"><input type="checkbox" disabled> Task Adaptive Pretraining(TAPT): Pretraining for the given dataset was refrained for this competition. Since Klue/roberta models were already pretrained on task dataset, we saved time not doing pretraining. However, when given with specific domains such as math, law, science, I think it is still worth trying MLM tasks and NSP tasks based pretraining. TAPT was allowed for both train and test datasets for this competition</li>
<li class="task-list-item"><input type="checkbox" disabled> Uniform Length Batching using huggingface's collate class / or making on my own.</li>
<li class="task-list-item"><input type="checkbox" disabled> optuna fine-tuning</li>
<li class="task-list-item"><input type="checkbox" disabled> Round-trip translation / Back translation based on cosine similarity for data augmentation</li>
<li class="task-list-item">
<p><input type="checkbox" disabled> Adding bidirectional GRU(or LSTM) layers after the transformers layer for the sake of non-linearity.</p>
<ul>
<li class="task-list-item"><input type="checkbox" disabled> <a href="">had difficulty of certain proportion of validation dataset being dropped</a></li>
<li class="task-list-item"><input type="checkbox" disabled> had difficulty of matching the torch tensor size in between transformers encoder layer to fully connected classifier layer.</li>
</ul>
</li>
</ul>
<h3 id="teamwork-" style="position:relative;"><a href="#teamwork-" aria-label="teamwork  permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Teamwork ğŸ‘¨â€ğŸ’»</h3>
<ul>
<li>It was our team's first time to fine-tune BERT model for the Relation Extraction task. We set our goals to the absolute value of f1 score(0.75) and never gave up. I never looked at the leaderboard until the end of competition in order to enjoy the process of learning.</li>
<li>Purpose of participating competition was to familiarize ourselves to fine-tuning BERT model. Finding the effective way to preprocess/train/infer was our objective.</li>
<li>Thus our team spent most of the time doing custom preprocessing and custom model fine-tuning method of our own. Along with increasing the f1 score, it was our goal to practice writing code that reflects our idea.</li>
<li>Since group of 7 people had to work as a team remotely, we set our ground rule not to cut in while other person is speaking.</li>
<li>Our team decided to respect each teammate's beliefs. If teammate wants to commence certain experiment and believes that it will contribute to robustness and performance of model, we promised to patiently wait and help the experiment.</li>
<li>By sharing both of Jupyter notebook links and wandb links, it helped other teammates to utilize(or copy &#x26; paste) code of the teammate and observe the performance.</li>
<li>While running the model and GPU is occupied, our teammates helps to debug other teammate's code. For example, if one GPU is occpupied with MLM TAPT, then the teammate "live coded" putting bidirectional gru between the classifier and last transformer encoding layer.</li>
</ul>
<h3 id="reference" style="position:relative;"><a href="#reference" aria-label="reference permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reference</h3>
<ul>
<li><a href="https://github.com/KLUE-benchmark/KLUE/tree/main/klue_benchmark">KLUE RE Relation Extraction Dataset / CC BY-SA</a></li>
<li><a href="https://arxiv.org/pdf/2102.01373v3.pdf">An Improved Baseline for Sentence-level Relation Extraction(Zhou et al. 2021)</a></li>
<li><a href="https://aclanthology.org/P19-1279.pdf">Matching the Blanks: Distributional Similarity for Relation Learning. Soares et al. 2019</a></li>
<li><a href="https://arxiv.org/pdf/1905.08284v1.pdf">Enriching Pre-trained Language Model with Entity Information for Relation Classification, Wu et al. 2019</a></li>
</ul>
<style class="grvsc-styles">
  .grvsc-container {
    overflow: auto;
    position: relative;
    -webkit-overflow-scrolling: touch;
    padding-top: 1rem;
    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));
    padding-bottom: 1rem;
    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));
    border-radius: 8px;
    border-radius: var(--grvsc-border-radius, 8px);
    font-feature-settings: normal;
    line-height: 1.4;
  }
  
  .grvsc-code {
    display: table;
  }
  
  .grvsc-line {
    display: table-row;
    box-sizing: border-box;
    width: 100%;
    position: relative;
  }
  
  .grvsc-line > * {
    position: relative;
  }
  
  .grvsc-gutter-pad {
    display: table-cell;
    padding-left: 0.75rem;
    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);
  }
  
  .grvsc-gutter {
    display: table-cell;
    -webkit-user-select: none;
    -moz-user-select: none;
    user-select: none;
  }
  
  .grvsc-gutter::before {
    content: attr(data-content);
  }
  
  .grvsc-source {
    display: table-cell;
    padding-left: 1.5rem;
    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));
    padding-right: 1.5rem;
    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));
  }
  
  .grvsc-source:empty::after {
    content: ' ';
    -webkit-user-select: none;
    -moz-user-select: none;
    user-select: none;
  }
  
  .grvsc-gutter + .grvsc-source {
    padding-left: 0.75rem;
    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);
  }
  
  /* Line transformer styles */
  
  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {
    content: ' ';
    position: absolute;
    width: 100%;
  }
  
  .grvsc-line-diff-add::before {
    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));
  }
  
  .grvsc-line-diff-del::before {
    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));
  }
  
  .grvsc-line-number {
    padding: 0 2px;
    text-align: right;
    opacity: 0.7;
  }
  
  .one-dark-pro {
    background-color: #282c34;
    color: #abb2bf;
  }
  .one-dark-pro .mtki { font-style: italic; }
  .one-dark-pro .mtk10 { color: #C678DD; }
  .one-dark-pro .mtk1 { color: #ABB2BF; }
  .one-dark-pro .mtk3 { color: #61AFEF; }
  .one-dark-pro .mtk7 { color: #D19A66; }
  .one-dark-pro .mtk6 { color: #98C379; }
  .one-dark-pro .mtk8 { color: #56B6C2; }
  .one-dark-pro .mtk5 { color: #7F848E; }
  .one-dark-pro .mtk4 { color: #E06C75; }
  .one-dark-pro .grvsc-line-highlighted::before {
    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));
    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));
  }
</style></div></div></div></div><div class="css-1bdwg0l eyldt480"><div><style data-emotion-css="17t5ffy">.css-17t5ffy{margin-top:1rem;margin-bottom:1rem;}</style><div class="css-17t5ffy"><div class="css-1l4w6pd"><div class="css-yapsbb"></div></div></div><style data-emotion-css="i1cgbm">.css-i1cgbm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;margin-top:1rem;padding-left:0.5rem;padding-right:0.5rem;}</style><div class="css-i1cgbm"><style data-emotion-css="16k19ub">.css-16k19ub{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;margin-left:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#2D87FD;}</style><button class="css-16k19ub"><style data-emotion-css="u7tj59">.css-u7tj59{fill:currentColor;margin-top:auto;margin-bottom:auto;margin-right:0.25rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 320 512" class="css-u7tj59" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z"></path></svg>Share with <!-- -->Facebook</button><style data-emotion-css="9nr5sz">.css-9nr5sz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;margin-left:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#1CA1F2;}</style><button class="css-9nr5sz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-u7tj59" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>Share with <!-- -->Twitter</button><style data-emotion-css="rk0yc0">.css-rk0yc0{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;margin-left:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#6E7783;}</style><button class="css-rk0yc0"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-u7tj59" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg>Share with <!-- -->Url</button></div></div></div></div></div><div class="css-1bdwg0l eyldt480"><style data-emotion-css="17t1oy1">.css-17t1oy1{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap-reverse;-ms-flex-wrap:wrap-reverse;flex-wrap:wrap-reverse;margin-left:0.5rem;margin-right:0.5rem;margin-top:1rem;}@media (min-width:768px){.css-17t1oy1{-webkit-flex-wrap:nowrap;-ms-flex-wrap:nowrap;flex-wrap:nowrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}}</style><div class="css-17t1oy1 e816y8n0"><style data-emotion-css="1pwr1ry">.css-1pwr1ry{width:100%;margin:0.5rem;}@media (min-width:768px){.css-1pwr1ry{width:50%;margin:1rem;}}</style><div class="css-1pwr1ry e816y8n1"><style data-emotion-css="vl2eok">.css-vl2eok{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);text-align:left;width:100%;height:100%;padding:0.5rem;background-color:#eee;border-radius:0.25rem;border-left-width:4px;border-color:#86a8e7;}.css-vl2eok:hover{background-color:#ddd;}</style><a rel="prev" class="css-vl2eok" href="/Configs/VSCode-Configuration/"><style data-emotion-css="19o7xeo">.css-19o7xeo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;margin-right:1rem;margin-left:0.5rem;height:100%;}</style><div class="css-19o7xeo"><style data-emotion-css="11za1ik">.css-11za1ik{width:2rem;height:2rem;margin-top:auto;margin-bottom:auto;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-11za1ik" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M872 474H286.9l350.2-304c5.6-4.9 2.2-14-5.2-14h-88.5c-3.9 0-7.6 1.4-10.5 3.9L155 487.8a31.96 31.96 0 0 0 0 48.3L535.1 866c1.5 1.3 3.3 2 5.2 2h91.5c7.4 0 10.8-9.2 5.2-14L286.9 550H872c4.4 0 8-3.6 8-8v-60c0-4.4-3.6-8-8-8z"></path></svg></div><style data-emotion-css="v38or">.css-v38or{display:inline-block;margin-top:0.5rem;margin-bottom:0.5rem;}</style><div class="css-v38or"><style data-emotion-css="2m7hin">.css-2m7hin{color:#3737B9;}</style><p class="css-2m7hin">ì´ì „ í¬ìŠ¤íŠ¸</p><p>My VSCode editor settings in JSON format</p></div></a></div><div class="css-1pwr1ry e816y8n1"><style data-emotion-css="xhvfnc">.css-xhvfnc{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);text-align:right;width:100%;height:100%;padding:0.5rem;background-color:#eee;border-radius:0.25rem;border-right-width:4px;border-color:#86a8e7;}.css-xhvfnc:hover{background-color:#ddd;}</style><a rel="next" class="css-xhvfnc" href="/DL&amp;ML/Relation-Extraction-Code/"><div class="css-v38or"><p class="css-2m7hin">ë‹¤ìŒ í¬ìŠ¤íŠ¸</p><p>RBERT for Relation Extraction: full code &amp; Wandb log</p></div><div class="css-19o7xeo"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-11za1ik" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M869 487.8L491.2 159.9c-2.9-2.5-6.6-3.9-10.5-3.9h-88.5c-7.4 0-10.8 9.2-5.2 14l350.2 304H152c-4.4 0-8 3.6-8 8v60c0 4.4 3.6 8 8 8h585.1L386.9 854c-5.6 4.9-2.2 14 5.2 14h91.5c1.9 0 3.8-.7 5.2-2L869 536.2a32.07 32.07 0 0 0 0-48.4z"></path></svg></div></a></div></div><style data-emotion-css="14yohw7">.css-14yohw7{width:100%;max-width:768px;padding-left:1rem;padding-right:1rem;margin-left:auto;margin-right:auto;padding-top:2rem;margin-top:0.5rem;margin-bottom:1rem;}@media (min-width:768px){.css-14yohw7{padding-left:0;padding-right:0;padding-top:3rem;}}</style><div class="css-14yohw7 e16bs3iv0"><style data-emotion-css="180ky7f">.css-180ky7f{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:0.5rem;padding-right:0.5rem;}@media (min-width:768px){.css-180ky7f{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}</style><div class="css-180ky7f e16bs3iv1"><style data-emotion-css="p5b1u1">.css-p5b1u1{border-radius:9999px;border-width:1px;--border-opacity:1;border-color:rgba(214,188,250,var(--border-opacity));margin-right:2rem;margin-bottom:0.5rem;}@media (min-width:768px){.css-p5b1u1{margin-bottom:1rem;}}</style><div class="css-p5b1u1 gatsby-image-wrapper" style="position:relative;overflow:hidden;display:inline-block;width:128px;height:128px"><img aria-hidden="true" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAQBBf/EABYBAQEBAAAAAAAAAAAAAAAAAAECA//aAAwDAQACEAMQAAABynZIqtSk4c5qdwD/AP/EABgQAAMBAQAAAAAAAAAAAAAAAAABAgMR/9oACAEBAAEFApTIkuNHXZgjWK2bZvTM6b1P/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAEQEf/aAAgBAwEBPwFiK//EABURAQEAAAAAAAAAAAAAAAAAAAEg/9oACAECAQE/ASP/xAAdEAACAQQDAAAAAAAAAAAAAAAAASECEBFRIjGB/9oACAEBAAY/AvCZ2QoMsw5TOJ2Up7t//8QAHRAAAgICAwEAAAAAAAAAAAAAAAERIUFhMVFxkf/aAAgBAQABPyGQ1UIIVo1dtoaHoXgWF10MklGMEvhCEYta+DAJgvw//9oADAMBAAIAAwAAABBYODz/xAAYEQEBAQEBAAAAAAAAAAAAAAABABEhQf/aAAgBAwEBPxB279ksrt//xAAXEQEBAQEAAAAAAAAAAAAAAAABABAx/9oACAECAQE/EI9kM//EAB4QAQEAAgICAwAAAAAAAAAAAAERACFRYTFBoeHw/9oACAEBAAE/ENiSENW+VTiZpVWrCLvvKMeEnTGARaXZevjBBRTTtdPnjWuccCRSa1+JjqKA/TCoCwoW324ixDPbn//Z" alt="profileImg" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/584d7a912ca03da16698aea724815677/6dc0c/profile.jpg 1x,
/static/584d7a912ca03da16698aea724815677/cc017/profile.jpg 1.5x,
/static/584d7a912ca03da16698aea724815677/0c30b/profile.jpg 2x" /><img loading="lazy" width="128" height="128" srcset="/static/584d7a912ca03da16698aea724815677/6dc0c/profile.jpg 1x,
/static/584d7a912ca03da16698aea724815677/cc017/profile.jpg 1.5x,
/static/584d7a912ca03da16698aea724815677/0c30b/profile.jpg 2x" src="/static/584d7a912ca03da16698aea724815677/6dc0c/profile.jpg" alt="profileImg" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div><div><span>Written by </span><style data-emotion-css="1t4jyca">.css-1t4jyca{display:inline-block;font-size:1.25rem;font-weight:700;border-radius:9999px;margin-bottom:0.5rem;padding-left:0.75rem;padding-right:0.75rem;--bg-opacity:1;background-color:rgba(237,242,247,var(--bg-opacity));color:#3737B9;}</style><p class="css-1t4jyca">@<!-- -->Young Jin Ahn</p><style data-emotion-css="vg2p6i">.css-vg2p6i{font-size:0.875rem;font-weight:400;margin-bottom:0.5rem;}</style><div class="css-vg2p6i">break, compose, display</div></div></div><style data-emotion-css="1air669">.css-1air669{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-left:0.5rem;margin-right:0.5rem;}</style><div class="css-1air669"><div class="css-yapsbb"></div></div><style data-emotion-css="1baulvz">.css-1baulvz{display:inline-block;}</style><a title="github Link" href="https://github.com/snoop2head" class="css-1baulvz"><style data-emotion-css="vnd1fq">.css-vnd1fq{width:2rem;height:2rem;margin-top:1rem;margin-left:1rem;-webkit-transition:all 300ms cubic-bezier(0,0,0.2,1);transition:all 300ms cubic-bezier(0,0,0.2,1);color:#888;}.css-vnd1fq:hover{color:#000;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="css-vnd1fq" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="facebook Link" href="https://www.facebook.com/profile.php?id=100009133042568" class="css-1baulvz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-vnd1fq" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"></path></svg></a></div><style data-emotion-css="18jj1tc">.css-18jj1tc{margin-top:1.25rem;margin-left:0.5rem;margin-right:0.5rem;}</style><div class="css-18jj1tc"><div class="utterances"></div></div></div></div><style data-emotion-css="xgi74q">.css-xgi74q{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:fixed;bottom:0;right:0;padding-right:1.5rem;padding-bottom:1.5rem;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}</style><div class="css-xgi74q e8huvi00"><style data-emotion-css="1a68u">.css-1a68u{box-shadow:0 2px 2px 0 rgba(0,0,0,0.15);-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#636363;font-size:0.75rem;padding-left:0.5rem;padding-right:0.5rem;padding-top:0.5rem;padding-bottom:0.5rem;border-radius:9999px;--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;-webkit-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));-ms-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-content:flex-end;-ms-flex-line-pack:end;align-content:flex-end;z-index:100;}.css-1a68u:hover{background-color:#404040;color:#FFFFFF;}.css-1a68u:hover{--transform-scale-x:1.05;--transform-scale-y:1.05;}</style><button title="change to darkmode" class="css-1a68u"><style data-emotion-css="1alqh2e">.css-1alqh2e{fill:currentColor;--text-opacity:1;color:rgba(246,224,94,var(--text-opacity));width:1rem;height:1rem;margin-top:auto;margin-bottom:auto;margin-left:0;margin-right:0;}@media (min-width:768px){.css-1alqh2e{display:inline-block;margin-left:0.25rem;margin-right:0.25rem;}}</style><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="css-1alqh2e" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg><style data-emotion-css="flxr9x">.css-flxr9x{display:none;margin-right:0;}@media (min-width:768px){.css-flxr9x{display:inline-block;margin-right:0.25rem;}}</style><span class="css-flxr9x">ë‹¤í¬ ëª¨ë“œë¡œ ë³´ê¸°</span></button><style data-emotion-css="15afv4q">.css-15afv4q{box-shadow:0 2px 2px 0 rgba(0,0,0,0.15);-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#636363;font-size:0.75rem;padding-left:0.5rem;padding-right:0.5rem;padding-top:0.5rem;padding-bottom:0.5rem;border-radius:9999px;--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;-webkit-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));-ms-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));cursor:pointer;margin-left:0.5rem;margin-top:auto;margin-bottom:auto;z-index:100;}.css-15afv4q:hover{background-color:#404040;color:#FFFFFF;}.css-15afv4q:hover{--transform-scale-x:1.05;--transform-scale-y:1.05;}</style><button title="top page" class="css-15afv4q"><style data-emotion-css="13htjwu">.css-13htjwu{width:1rem;height:1rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-13htjwu" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M868 545.5L536.1 163a31.96 31.96 0 0 0-48.3 0L156 545.5a7.97 7.97 0 0 0 6 13.2h81c4.6 0 9-2 12.1-5.5L474 300.9V864c0 4.4 3.6 8 8 8h60c4.4 0 8-3.6 8-8V300.9l218.9 252.3c3 3.5 7.4 5.5 12.1 5.5h81c6.8 0 10.5-8 6-13.2z"></path></svg></button></div><style data-emotion-css="1k8xcyw">.css-1k8xcyw{text-align:center;padding-top:2rem;padding-bottom:2rem;bottom:0;}</style><footer class="css-1k8xcyw"><style data-emotion-css="1xju3od">.css-1xju3od{font-size:0.75rem;font-weight:700;}</style><a href="https://github.com/snoop2head" class="css-1xju3od">Â©snoop2head</a></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-186254784-2', 'auto', {});
      
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/DL&ML/Relation-Extraction/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-2f72579fb641bf14a0fa.js"],"app":["/app-97235b1800926a9fde68.js"],"component---src-pages-404-js":["/component---src-pages-404-js-52653b52ec9c7b389244.js"],"component---src-pages-index-js":["/component---src-pages-index-js-fbb692f58f9fda19439c.js"],"component---src-pages-search-js":["/component---src-pages-search-js-b32d7426c8be7684ef3e.js"],"component---src-templates-blog-post-js":["/component---src-templates-blog-post-js-2da73b992f9a5d5d1c33.js"],"component---src-templates-category-js":["/component---src-templates-category-js-0c15cae52c52c0f57585.js"]};/*]]>*/</script><script src="/polyfill-2f72579fb641bf14a0fa.js" nomodule=""></script><script src="/component---src-templates-blog-post-js-2da73b992f9a5d5d1c33.js" async=""></script><script src="/7a297f752dcfe258c0b0106d89edb3a916af916e-cedd3fd12e7e0b393ad2.js" async=""></script><script src="/commons-193e8d98dacc19f3118d.js" async=""></script><script src="/1bfc9850-409296e666dade882413.js" async=""></script><script src="/5e2a4920-da90abce4a08c86a094c.js" async=""></script><script src="/d7eeaac4-dcbe97e7a5aa158c9d08.js" async=""></script><script src="/app-97235b1800926a9fde68.js" async=""></script><script src="/dc6a8720040df98778fe970bf6c000a41750d3ae-17eb047fb821ccbad0b0.js" async=""></script><script src="/styles-84a9bc99193fe5828ffe.js" async=""></script><script src="/framework-eb684e3e828ad13b3940.js" async=""></script><script src="/webpack-runtime-3d93945ad234d2f13d98.js" async=""></script></body></html>