{"componentChunkName":"component---src-templates-blog-post-js","path":"/Engineering/Relation-Extraction/","result":{"data":{"site":{"siteMetadata":{"author":"Young Jin Ahn","comment":{"utterances":"snoop2head/snoop2head.github.io"},"sponsor":{"buyMeACoffeeId":""}}},"markdownRemark":{"excerpt":"ğŸ¥‡ AUPRC score of 83.2 ranked the 1st place / 19 teams ğŸ¥‰ F1 score of 73.9 ranked 3rd place / 19 teams KLUE(Korean Language Understanding Evaluation) Benchmark is newly introduced Korean NLP Benchmark.â€¦","html":"<p><strong>ğŸ¥‡ AUPRC score of 83.2 ranked the 1st place / 19 teams</strong></p>\n<p><strong>ğŸ¥‰ F1 score of 73.9 ranked 3rd place / 19 teams</strong></p>\n<p><a href=\"https://paperswithcode.com/dataset/klue\">KLUE(Korean Language Understanding Evaluation) Benchmark</a> is newly introduced Korean NLP Benchmark. In Naver Boostcamp, the team solved Relation Extraction task from KLUE Benchmark dataset within the span of 12 days.</p>\n<h2 id=\"dataset--dataloader\" style=\"position:relative;\"><a href=\"#dataset--dataloader\" aria-label=\"dataset  dataloader permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Dataset &#x26; Dataloader</h2>\n<h3 id=\"entity-representation\" style=\"position:relative;\"><a href=\"#entity-representation\" aria-label=\"entity representation permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Entity Representation</h3>\n<p><strong>Putting labels(or entity markers) around the target entity has boosted the performance.</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">Sentence</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">Origianal</td>\n<td align=\"center\">ì¡°ì§€ í•´ë¦¬ìŠ¨ì´ ì“°ê³  ë¹„í‹€ì¦ˆê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</td>\n</tr>\n<tr>\n<td align=\"center\">Entity Marker Method</td>\n<td align=\"center\">[E2]ì¡°ì§€ í•´ë¦¬ìŠ¨[/E2]ì´ ì“°ê³  [E1]ë¹„í‹€ì¦ˆ[/E1]ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</td>\n</tr>\n<tr>\n<td align=\"center\">Entity Marker Punctuation Method</td>\n<td align=\"center\">#ì¡°ì§€ í•´ë¦¬ìŠ¨#ì´ ì“°ê³  @ë¹„í‹€ì¦ˆ@ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤</td>\n</tr>\n<tr>\n<td align=\"center\">Entity Replacement Method</td>\n<td align=\"center\">[OBJ-ORG]ì´ ì“°ê³  [SUBJ-ORG]ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</td>\n</tr>\n<tr>\n<td align=\"center\">Typed Entity Marker Method</td>\n<td align=\"center\">[OBJ-ORG]ì¡°ì§€ í•´ë¦¬ìŠ¨[/OBJ-ORG]ì´ ì“°ê³  [SUBJ-ORG]ë¹„í‹€ì¦ˆ[/SUBJ-ORG]ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</td>\n</tr>\n<tr>\n<td align=\"center\"><strong>Typed Entity Marker Punctuation Method</strong></td>\n<td align=\"center\"><strong>#^ORG^ì¡°ì§€ í•´ë¦¬ìŠ¨#ì´ ì“°ê³  @<em>ORG</em>ë¹„í‹€ì¦ˆ@ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</strong></td>\n</tr>\n</tbody>\n</table>\n<p>How to annotate entity marker around the target entities was important point of discussion.The paper <a href=\"https://arxiv.org/pdf/2102.01373v3.pdf\">An Improved Baseline for Sentence-level Relation Extraction(Zhou et al. 2021)</a> gives 5 types of composite entity information labelling technique as depicted above.</p>\n<p>Typed entity marker method\u000b was good but required two additional steps. It required adding special token to the tokenizer and resizing the embedding layer accordingly.</p>\n<p>Even though it is good idea, this has few shortcomings. <strong>Creating and importing new tokens with no pretrained hidden features might hinder the model's performance.</strong> <strong>Moreover, additional part of speech(POS) tagging information is not going in as the input to the pretrained model, but only regarded as special tokens.</strong></p>\n<p>With such background, the paper Improved Baseline proposes \"Typed entity marker punctioation method\". <strong>Enclosing the entity with entity span(POS) and entity types(SUB/OBJ) without introducing new special tokens</strong>. This paper argues that enclosing the subject and object entities with â€œ@â€ and â€œ#â€ alone boosts the perfomance. Performance comparisions are given with the table below.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 20.333333333333332%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAtElEQVQY0z2QSQqEUAxEXSsqqIg4z7PgcP+zVfOy6EUIya96Sb6zLIuu61JVVWqaRsMw6L5vi77v1batuq6z4J38fZ+2bdPzPJbR0qvrWs40TVaUZSnf9xVFkdZ1NeE4jjqOw4YARxOGoeZ5VpIkBs+yTGmaCg5+ByomgscgCP5AAjNgAEVR2EDA6Kjpe55nXtd15XDSeZ5/AOZ93/W+r53Ed1CzJTq2wgOMZch5ntuGcRzrB4HUbvhk7M1gAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20211008223302060\"\n        title=\"image-20211008223302060\"\n        src=\"/static/2827eef5d8c6c1dc139a6170fa1839ff/c1b63/image-20211008223302060.png\"\n        srcset=\"/static/2827eef5d8c6c1dc139a6170fa1839ff/5a46d/image-20211008223302060.png 300w,\n/static/2827eef5d8c6c1dc139a6170fa1839ff/0a47e/image-20211008223302060.png 600w,\n/static/2827eef5d8c6c1dc139a6170fa1839ff/c1b63/image-20211008223302060.png 1200w,\n/static/2827eef5d8c6c1dc139a6170fa1839ff/d61c2/image-20211008223302060.png 1800w,\n/static/2827eef5d8c6c1dc139a6170fa1839ff/3c2d4/image-20211008223302060.png 2092w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>The team utilized <a href=\"https://kakaobrain.github.io/pororo/tagging/ner.html\">Pororo NER POS Tagging function</a> for both train and test dataset. With Pororo POS tagger, the team experimented both (1) typed entity marker and (2) typed entity punctutation method. (1) Typed entity marked was fed into as an input of RBERT custom model, whereas (2) typed entity punctuation method was fed into its own custom model.</p>\n<h3 id=\"1-typed-entity-marker-dataset-creation\" style=\"position:relative;\"><a href=\"#1-typed-entity-marker-dataset-creation\" aria-label=\"1 typed entity marker dataset creation permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(1) Typed Entity Marker Dataset Creation</h3>\n<p>Instead of saving the tokenizer itself, the special tokens added with Pororo NER POS Tagging were saved as txt format file. It was later loaded as txt file, added to tokenizer with add<em>special</em>tokens() method. The embedding layer was resized accordingly. However, it is still remain unsolved that whether resizing embedding layer boosts the performance or harms the performance.</p>\n<p>The following CSV files were created for time-saving purpose: Pororo POS tagging took 12+ hours for 40k train + test sentences.</p>\n<ul>\n<li><a href=\"https://raw.githubusercontent.com/boostcampaitech2/klue-level2-nlp-15/main/dataset/train_pororo_sub.csv?token=AG3HZNZI4TIT7XLSBIMJYHDBL4EVE\">Pororo POS Tagging with [SUB-{POS}] [/SUB-{POS}] entity special tokens</a></li>\n<li><a href=\"https://raw.githubusercontent.com/boostcampaitech2/klue-level2-nlp-15/main/dataset/train_typed_entity_marker_punct.csv?token=AG3HZN4TYFCN3HXLUWYQ7Y3BL4EVG\">Pororo POS Tagging with improved baseline style <code>#^organization^ëŒ€ì•ˆì‹ ë‹¹#</code></a></li>\n<li><a href=\"https://raw.githubusercontent.com/boostcampaitech2/klue-level2-nlp-15/main/dataset/train_punct_kor.csv?token=AG3HZN3VUMQMEUL337RH333BL4EVC\">Pororo POS Tagging with improved baseline style translated into Korean <code>#^ì‚¬ëŒ^ì¡°ì§€ í•´ë¦¬ìŠ¨#</code></a></li>\n</ul>\n<h3 id=\"2-typed-entity-marker-punctuation-dataset-creation\" style=\"position:relative;\"><a href=\"#2-typed-entity-marker-punctuation-dataset-creation\" aria-label=\"2 typed entity marker punctuation dataset creation permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(2) Typed Entity Marker Punctuation Dataset Creation</h3>\n<p>Teammate has created typed entity marker punctuation function as following:</p>\n<pre class=\"grvsc-container one-dark-pro\" data-language=\"python\" data-index=\"0\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk10\">def</span><span class=\"mtk1\"> </span><span class=\"mtk3\">tokenized_dataset</span><span class=\"mtk1\">(</span><span class=\"mtk7 mtki\">dataset</span><span class=\"mtk1\">, </span><span class=\"mtk7 mtki\">tokenizer</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk6\">&quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk6\">    Inserting typed entity markers to each sentences</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk6\">    subject: @*type*subject word@ (e.g.  ê¹€í˜„ìˆ˜ -&gt; @*ì‚¬ëŒ*ê¹€í˜„ìˆ˜@)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk6\">    object: #^type^object word# (e.g. #^ì§€ëª…^í•œêµ­#)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk6\">    &lt;&lt;An Improved Baseline for Sentence-level Relation Extraction&gt;&gt;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk6\">    &quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    type_dict </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> {</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk6\">&quot;PER&quot;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&quot;ì‚¬ëŒ&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk6\">&quot;LOC&quot;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&quot;ì§€ëª…&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk6\">&quot;ORG&quot;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&quot;ê¸°ê´€&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk6\">&quot;DAT&quot;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&quot;ë‚ ì§œ&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk6\">&quot;TIM&quot;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&quot;ì‹œê°„&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk6\">&quot;DUR&quot;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&quot;ê¸°ê°„&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk6\">&quot;MNY&quot;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&quot;í†µí™”&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk6\">&quot;PNT&quot;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&quot;ë¹„ìœ¨&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk6\">&quot;NOH&quot;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&quot;ìˆ˜ëŸ‰&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk6\">&quot;POH&quot;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&quot;ê¸°íƒ€&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    }</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    sentences </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> []</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    e01, e02, sent </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> dataset[</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">], dataset[</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">], dataset[</span><span class=\"mtk6\">&#39;sentence&#39;</span><span class=\"mtk1\">]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    subject_start, subject_end, sub_type </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> e01</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    object_start, object_end, obj_type </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> e02</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    subj </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> sent[e01[</span><span class=\"mtk7\">0</span><span class=\"mtk1\">]: e01[</span><span class=\"mtk7\">1</span><span class=\"mtk1\">] </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\">]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    obj </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> sent[e02[</span><span class=\"mtk7\">0</span><span class=\"mtk1\">]: e02[</span><span class=\"mtk7\">1</span><span class=\"mtk1\">] </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\">]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk10 mtki\">if</span><span class=\"mtk1\"> subject_start </span><span class=\"mtk8\">&lt;</span><span class=\"mtk1\"> object_start:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        sent_ </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> sent[:subject_start] </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk10\">f</span><span class=\"mtk6\">&#39;@*</span><span class=\"mtk7\">{</span><span class=\"mtk1\">type_dict[sub_type]</span><span class=\"mtk7\">}</span><span class=\"mtk6\">*&#39;</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> subj </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk6\">&#39;@&#39;</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> \\</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                    sent[subject_end </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\">:object_start] </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk10\">f</span><span class=\"mtk6\">&#39;&amp;^</span><span class=\"mtk7\">{</span><span class=\"mtk1\">type_dict[obj_type]</span><span class=\"mtk7\">}</span><span class=\"mtk6\">^&#39;</span><span class=\"mtk1\"> \\</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                    </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> obj </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk6\">&#39;&amp;&#39;</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> sent[object_end </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\">:]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        ss </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk8\">len</span><span class=\"mtk1\">(tokenizer.</span><span class=\"mtk3\">tokenize</span><span class=\"mtk1\">(sent[:subject_start]))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        se </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> ss </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">4</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk8\">len</span><span class=\"mtk1\">(tokenizer.</span><span class=\"mtk3\">tokenize</span><span class=\"mtk1\">(subj))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        es </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> se </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk8\">len</span><span class=\"mtk1\">(tokenizer.</span><span class=\"mtk3\">tokenize</span><span class=\"mtk1\">(sent[subject_end </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\">:object_start]))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        ee </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> es </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">4</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk8\">len</span><span class=\"mtk1\">(tokenizer.</span><span class=\"mtk3\">tokenize</span><span class=\"mtk1\">(obj))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk10 mtki\">else</span><span class=\"mtk1\">:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        sent_ </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> sent[:object_start] </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk10\">f</span><span class=\"mtk6\">&#39;&amp;^</span><span class=\"mtk7\">{</span><span class=\"mtk1\">type_dict[obj_type]</span><span class=\"mtk7\">}</span><span class=\"mtk6\">^&#39;</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> obj </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk6\">&#39;&amp;&#39;</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> \\</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                sent[object_end </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\">:subject_start] </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk10\">f</span><span class=\"mtk6\">&#39;@*</span><span class=\"mtk7\">{</span><span class=\"mtk1\">type_dict[sub_type]</span><span class=\"mtk7\">}</span><span class=\"mtk6\">*&#39;</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> subj </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk6\">&#39;@&#39;</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> \\</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                sent[subject_end </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\">:]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        es </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk8\">len</span><span class=\"mtk1\">(tokenizer.</span><span class=\"mtk3\">tokenize</span><span class=\"mtk1\">(sent[:object_start]))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        ee </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> es </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">4</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk8\">len</span><span class=\"mtk1\">(tokenizer.</span><span class=\"mtk3\">tokenize</span><span class=\"mtk1\">(obj))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        ss </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> ee </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk8\">len</span><span class=\"mtk1\">(tokenizer.</span><span class=\"mtk3\">tokenize</span><span class=\"mtk1\">(sent[object_end </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">1</span><span class=\"mtk1\">:subject_start]))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        se </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> ss </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk7\">4</span><span class=\"mtk1\"> </span><span class=\"mtk8\">+</span><span class=\"mtk1\"> </span><span class=\"mtk8\">len</span><span class=\"mtk1\">(tokenizer.</span><span class=\"mtk3\">tokenize</span><span class=\"mtk1\">(subj))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    sentences.</span><span class=\"mtk3\">append</span><span class=\"mtk1\">(sent_)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    max_length </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> </span><span class=\"mtk7\">256</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    senttokens </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> tokenizer.</span><span class=\"mtk3\">tokenize</span><span class=\"mtk1\">(sent_)[:max_length </span><span class=\"mtk8\">-</span><span class=\"mtk1\"> </span><span class=\"mtk7\">2</span><span class=\"mtk1\">]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    input_ids </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> tokenizer.</span><span class=\"mtk3\">convert_tokens_to_ids</span><span class=\"mtk1\">(senttokens)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    input_ids </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> tokenizer.</span><span class=\"mtk3\">build_inputs_with_special_tokens</span><span class=\"mtk1\">(input_ids)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk10 mtki\">return</span><span class=\"mtk1\"> input_ids, ss, se, es, ee</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk10\">def</span><span class=\"mtk1\"> </span><span class=\"mtk3\">processor</span><span class=\"mtk1\">(</span><span class=\"mtk7 mtki\">tokenizer</span><span class=\"mtk1\">, </span><span class=\"mtk7 mtki\">dataset</span><span class=\"mtk1\">, </span><span class=\"mtk7 mtki\">train_mode</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk6\">&#39;&#39;&#39;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk6\">    train_dataset = processor(tokenizer, train_df))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk6\">    --&gt; train_dataloader = Dataloader(train_dataset, batch_size = ...)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk6\">    &#39;&#39;&#39;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    features </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> []</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    labels </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> dataset[</span><span class=\"mtk6\">&#39;label&#39;</span><span class=\"mtk1\">].values</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk10 mtki\">if</span><span class=\"mtk1\"> train_mode:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        labels </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> </span><span class=\"mtk3\">label_to_num</span><span class=\"mtk1\">(dataset[</span><span class=\"mtk6\">&#39;label&#39;</span><span class=\"mtk1\">].values)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk10 mtki\">for</span><span class=\"mtk1\"> i </span><span class=\"mtk10\">in</span><span class=\"mtk1\"> </span><span class=\"mtk8\">range</span><span class=\"mtk1\">(</span><span class=\"mtk8\">len</span><span class=\"mtk1\">(dataset)):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        input_ids, new_ss, new_se, new_es, new_ee </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> </span><span class=\"mtk3\">tokenized_dataset</span><span class=\"mtk1\">(dataset.iloc[i], tokenizer)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        label </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> labels[i]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        feature </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> {</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk6\">&#39;input_ids&#39;</span><span class=\"mtk1\"> : input_ids,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk6\">&#39;labels&#39;</span><span class=\"mtk1\"> : label,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk6\">&#39;ss&#39;</span><span class=\"mtk1\">: new_ss,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk6\">&#39;se&#39;</span><span class=\"mtk1\">: new_se,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk6\">&#39;es&#39;</span><span class=\"mtk1\"> : new_es,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk6\">&#39;ee&#39;</span><span class=\"mtk1\"> : new_ee,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        }</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        features.</span><span class=\"mtk3\">append</span><span class=\"mtk1\">(feature)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk10 mtki\">return</span><span class=\"mtk1\"> features</span></span></span></code></pre>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">Sentence</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><strong>Typed Entity Marker Punctuation Method</strong></td>\n<td align=\"center\"><strong>#^ORG^ì¡°ì§€ í•´ë¦¬ìŠ¨#ì´ ì“°ê³  @<em>ORG</em>ë¹„í‹€ì¦ˆ@ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</strong></td>\n</tr>\n<tr>\n<td align=\"center\"><strong>Typed Entity Marker Korean Punctuation Method</strong></td>\n<td align=\"center\"><strong>&#x26;^ë‹¨ì²´^ì¡°ì§€ í•´ë¦¬ìŠ¨&#x26;ì´ ì“°ê³  @<em>ë‹¨ì²´</em>ë¹„í‹€ì¦ˆ@ê°€ 1969ë…„ ì•¨ë²” ã€ŠAbbey Roadã€‹ì— ë‹´ì€ ë…¸ë˜ë‹¤.</strong></td>\n</tr>\n</tbody>\n</table>\n<p>Rather than merely implementing the paper <a href=\"https://arxiv.org/pdf/2102.01373v3.pdf\">An Improved Baseline for Sentence-level Relation Extraction(Zhou et al. 2021)</a>, the team went two steps further.</p>\n<p>First, we translated the english entity marker punctuation into Korean word. This was because pretraind <code>klue/roberta-large</code> tokenizer's english vocabulary sets are more or less than 800 words out of 32000 token vocab sets. Thus the team decided that using Korean punctuation rather than english punctuation in order to boost performance.</p>\n<p>Moreover, the team replaced <code>#</code> punctuation representation with <code>&#x26;</code> representation. Since the team is using pretrained RoBERTa, <code>#</code> is often found in tokenizers as sub-word representations(<code>ì•ˆë…•í•˜ì„¸ìš”</code> -> [<code>ì•ˆë…•</code>, <code>##í•˜ì„¸ìš”</code>]). Therefore we thought that <code>&#x26;</code> would be better for annotation for the punctuation representation.</p>\n<h3 id=\"fixing-preprocessor\" style=\"position:relative;\"><a href=\"#fixing-preprocessor\" aria-label=\"fixing preprocessor permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Fixing Preprocessor</h3>\n<p>Upon receiving baseline code, I encountered that the baseline's code has errors. For example, the baseline's preprocessing code splitted nested json as column value of the pandas dataframe as such.</p>\n<pre class=\"grvsc-container one-dark-pro\" data-language=\"python\" data-index=\"1\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk10\">def</span><span class=\"mtk1\"> </span><span class=\"mtk3\">preprocessing_dataset</span><span class=\"mtk1\">(</span><span class=\"mtk7 mtki\">dataset</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  subject_entity </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> []</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  object_entity </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> []</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk10 mtki\">for</span><span class=\"mtk1\"> i,j </span><span class=\"mtk10\">in</span><span class=\"mtk1\"> </span><span class=\"mtk8\">zip</span><span class=\"mtk1\">(dataset[</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">], dataset[</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">]):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    i </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> i[</span><span class=\"mtk7\">1</span><span class=\"mtk1\">:</span><span class=\"mtk8\">-</span><span class=\"mtk7\">1</span><span class=\"mtk1\">].</span><span class=\"mtk3\">split</span><span class=\"mtk1\">(</span><span class=\"mtk6\">&#39;,&#39;</span><span class=\"mtk1\">)[</span><span class=\"mtk7\">0</span><span class=\"mtk1\">].</span><span class=\"mtk3\">split</span><span class=\"mtk1\">(</span><span class=\"mtk6\">&#39;:&#39;</span><span class=\"mtk1\">)[</span><span class=\"mtk7\">1</span><span class=\"mtk1\">] </span><span class=\"mtk5 mtki\"># &lt;- ERROR OCCURS</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    j </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> j[</span><span class=\"mtk7\">1</span><span class=\"mtk1\">:</span><span class=\"mtk8\">-</span><span class=\"mtk7\">1</span><span class=\"mtk1\">].</span><span class=\"mtk3\">split</span><span class=\"mtk1\">(</span><span class=\"mtk6\">&#39;,&#39;</span><span class=\"mtk1\">)[</span><span class=\"mtk7\">0</span><span class=\"mtk1\">].</span><span class=\"mtk3\">split</span><span class=\"mtk1\">(</span><span class=\"mtk6\">&#39;:&#39;</span><span class=\"mtk1\">)[</span><span class=\"mtk7\">1</span><span class=\"mtk1\">] </span><span class=\"mtk5 mtki\"># &lt;- ERROR OCCURS</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    subject_entity.</span><span class=\"mtk3\">append</span><span class=\"mtk1\">(i)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    object_entity.</span><span class=\"mtk3\">append</span><span class=\"mtk1\">(j)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  out_dataset </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> pd.</span><span class=\"mtk3\">DataFrame</span><span class=\"mtk1\">({</span><span class=\"mtk6\">&#39;id&#39;</span><span class=\"mtk1\">:dataset[</span><span class=\"mtk6\">&#39;id&#39;</span><span class=\"mtk1\">], </span><span class=\"mtk6\">&#39;sentence&#39;</span><span class=\"mtk1\">:dataset[</span><span class=\"mtk6\">&#39;sentence&#39;</span><span class=\"mtk1\">],</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">:subject_entity,</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">:object_entity,</span><span class=\"mtk6\">&#39;label&#39;</span><span class=\"mtk1\">:dataset[</span><span class=\"mtk6\">&#39;label&#39;</span><span class=\"mtk1\">],})</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk10 mtki\">return</span><span class=\"mtk1\"> out_dataset</span></span></span></code></pre>\n<p>When preprocessing CSV format dataset, handling the data's value with comma should be handled with care. According to the code above, numerical string <code>100,000</code> could be splitted into different columns.</p>\n<p>So I fixed the code with the following code.</p>\n<pre class=\"grvsc-container one-dark-pro\" data-language=\"python\" data-index=\"2\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk10\">def</span><span class=\"mtk1\"> </span><span class=\"mtk3\">pull_out_dictionary</span><span class=\"mtk1\">(</span><span class=\"mtk7 mtki\">df_input</span><span class=\"mtk1\">: pd.DataFrame):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk6\">&quot;&quot;&quot; pull out str `{}` values from the pandas dataframe and shape it as a new column&quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  df </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> df_input.</span><span class=\"mtk3\">copy</span><span class=\"mtk1\">()</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk5 mtki\"># assign subject_entity and object_entity column values type as dictionary</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  df[</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">] </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> df[</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">].</span><span class=\"mtk3\">apply</span><span class=\"mtk1\">(</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: </span><span class=\"mtk8\">eval</span><span class=\"mtk1\">(x))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  df[</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">] </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> df[</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">].</span><span class=\"mtk3\">apply</span><span class=\"mtk1\">(</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: </span><span class=\"mtk8\">eval</span><span class=\"mtk1\">(x))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk5 mtki\"># parse item inside of subject_entity and object_entity&#39;s dictionary values as columns of dataframe</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk5 mtki\"># word, start_idx, end_idx, type as new columns</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  df </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> df.</span><span class=\"mtk3\">assign</span><span class=\"mtk1\">(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk5 mtki\"># subject_entity</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk4 mtki\">subject_word</span><span class=\"mtk8\">=</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">].</span><span class=\"mtk3\">apply</span><span class=\"mtk1\">(</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;word&#39;</span><span class=\"mtk1\">]),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk4 mtki\">subject_start_idx</span><span class=\"mtk8\">=</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">].</span><span class=\"mtk3\">apply</span><span class=\"mtk1\">(</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;start_idx&#39;</span><span class=\"mtk1\">]),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk4 mtki\">subject_end_idx</span><span class=\"mtk8\">=</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">].</span><span class=\"mtk3\">apply</span><span class=\"mtk1\">(</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;end_idx&#39;</span><span class=\"mtk1\">]),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk4 mtki\">subject_type</span><span class=\"mtk8\">=</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">].</span><span class=\"mtk3\">apply</span><span class=\"mtk1\">(</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;type&#39;</span><span class=\"mtk1\">]),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk5 mtki\"># object_entity</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk4 mtki\">object_word</span><span class=\"mtk8\">=</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">].</span><span class=\"mtk3\">apply</span><span class=\"mtk1\">(</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;word&#39;</span><span class=\"mtk1\">]),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk4 mtki\">object_start_idx</span><span class=\"mtk8\">=</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">].</span><span class=\"mtk3\">apply</span><span class=\"mtk1\">(</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;start_idx&#39;</span><span class=\"mtk1\">]),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk4 mtki\">object_end_idx</span><span class=\"mtk8\">=</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">].</span><span class=\"mtk3\">apply</span><span class=\"mtk1\">(</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;end_idx&#39;</span><span class=\"mtk1\">]),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk4 mtki\">object_type</span><span class=\"mtk8\">=</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">].</span><span class=\"mtk3\">apply</span><span class=\"mtk1\">(</span><span class=\"mtk10\">lambda</span><span class=\"mtk1\"> </span><span class=\"mtk7 mtki\">x</span><span class=\"mtk1\">: x[</span><span class=\"mtk6\">&#39;type&#39;</span><span class=\"mtk1\">]),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  )</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk5 mtki\"># drop subject_entity and object_entity column</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  df </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> df.</span><span class=\"mtk3\">drop</span><span class=\"mtk1\">([</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">, </span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">], </span><span class=\"mtk4 mtki\">axis</span><span class=\"mtk8\">=</span><span class=\"mtk7\">1</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk10 mtki\">return</span><span class=\"mtk1\"> df</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk10\">def</span><span class=\"mtk1\"> </span><span class=\"mtk3\">preprocessing_dataset</span><span class=\"mtk1\">(</span><span class=\"mtk7 mtki\">dataset</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk5 mtki\"># pull out nested json into separate pandas columns</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  dataset </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> </span><span class=\"mtk3\">pull_out_dictionary</span><span class=\"mtk1\">(dataset)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk5 mtki\"># rename columns subject_word as subject_entity, object_word as object_entity</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  dataset </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> dataset.</span><span class=\"mtk3\">rename</span><span class=\"mtk1\">(</span><span class=\"mtk4 mtki\">columns</span><span class=\"mtk8\">=</span><span class=\"mtk1\">{</span><span class=\"mtk6\">&#39;subject_word&#39;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">, </span><span class=\"mtk6\">&#39;object_word&#39;</span><span class=\"mtk1\">: </span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">})</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  out_dataset </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> pd.</span><span class=\"mtk3\">DataFrame</span><span class=\"mtk1\">({</span><span class=\"mtk6\">&#39;id&#39;</span><span class=\"mtk1\">:dataset[</span><span class=\"mtk6\">&#39;id&#39;</span><span class=\"mtk1\">], </span><span class=\"mtk6\">&#39;sentence&#39;</span><span class=\"mtk1\">:dataset[</span><span class=\"mtk6\">&#39;sentence&#39;</span><span class=\"mtk1\">],</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">:dataset[</span><span class=\"mtk6\">&#39;subject_entity&#39;</span><span class=\"mtk1\">],</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">:dataset[</span><span class=\"mtk6\">&#39;object_entity&#39;</span><span class=\"mtk1\">],</span><span class=\"mtk6\">&#39;label&#39;</span><span class=\"mtk1\">:dataset[</span><span class=\"mtk6\">&#39;label&#39;</span><span class=\"mtk1\">],})</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\">display</span><span class=\"mtk1\">(out_dataset.</span><span class=\"mtk3\">head</span><span class=\"mtk1\">(</span><span class=\"mtk7\">2</span><span class=\"mtk1\">))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk10 mtki\">return</span><span class=\"mtk1\"> out_dataset</span></span></span></code></pre>\n<h3 id=\"setting-maximum-token-length-for-roberta-tokenizer\" style=\"position:relative;\"><a href=\"#setting-maximum-token-length-for-roberta-tokenizer\" aria-label=\"setting maximum token length for roberta tokenizer permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Setting maximum token length for RoBERTa tokenizer</h3>\n<p><a href=\"https://wandb.ai/danielkim30433/huggingface/reports/Comparison-through-changing-max_length-parameter--VmlldzoxMDc1NTE0?accessToken=4r9exwlxam05iy0u0aaexwxfpgl041hyno7gsxthwygf37hgq4xg2kbj66dtj1gf\">ğŸ“ˆ wandb: Comparison through changing \"max_length\" parameter</a></p>\n<p><a href=\"(https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/dev/v03/token_length%EA%B4%80%EB%A0%A8.ipynb)\">ğŸ Jupyter Notebook for EDA for KLUE Relation Extraction dataset</a></p>\n<p>There are only 460 sentences out of 32.5k train set that exceeded the token length of 128, using <code>klue/roberta-base</code> wordpiece tokenizers. Thus we set the maximum token length as 128.</p>\n<p>Thanks for my teammate's concise inspection for finding optimal max<em>token</em>length in EDA, <strong>it is confirmed that each of the class label's token length distribution are uniform to one another</strong>. Therefore even if we drop 460 sentences which exceeds maximum<em>token</em>length, balance of data between the classes wouldn't be affected.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Class 1</th>\n<th align=\"center\">Class 2</th>\n<th align=\"center\">Class 3</th>\n<th align=\"center\">...</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><img src=\"../assets/images/2021-10-08-Relation-Extraction/7E22FA0E-BBEC-4742-96C8-46E316D30CCA.png\" alt=\"img\"></td>\n<td align=\"center\"><img src=\"../assets/images/2021-10-08-Relation-Extraction/AE0C1743-6B50-4819-898D-D0500A671AEE.png\" alt=\"img\"></td>\n<td align=\"center\"><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 368px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 71.33333333333334%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAACkklEQVQ4y52SbUiTURTHr9EHIZQoC3Ss5RwaFftg1Ach6kNBfQgqJAgK9UNUaGo4tam9Q1HhC82YFVFRUKjzNedLsxdqFSW+IRo2p266uRl7fUr37Hnu6d6rPRiFSgf+cO95zvnd/zk8yGw2I7vdftrv938JBILt3RaHiZ/5YeK4oCkQCJiCweCSInUdHMd9nJiYuIwAAE06HPdhPtIefoZrxiH4nyCmjAxos9l0oijS3My+irfC1gttAjkLIsYCXp5CtNnr9dairq4u5PF4ysICZQB/6I4ZUq53shdJoaTFgnwPzwPrEImIb5aRKproHvfyyVc6YPet16xQXAbsL6DVakWTU+5ymsh51sOvOFENe0rfADcbloBLufwDSHdoHbNV0kR+TR+/Orse4jRNcLFxgBWTRUrjLxs4MjrOgJrqXgaMzWuCVP0H8P/kpdEX7nRRYH9/P3K4pstoIo8Ao7PqILHYCBR8s21Ickkliv8G/+VwaNiip4nC2j4+KsuAE7QtWFHYjJOKjbh9wEk7JYUJmTjGBM6E2Vn8DTQwIIS48rYBJyiLjLy84AVWnGuBjUSy/GacWNKKy18OQ6/dB8Ou4EK4ZJCIAX0+35zDkHdKd7dzEFadfC7Ea+phQ14dyIkURHFnDRCbawCFpgFv0jbCvVdfYcTpgZ5RN/SNuUEIzYLV6RHt3wPgcrnYf7jyvLZAVdnwLikmQ6+Sn3mqXLs/e9u6g1q1LPOJUpn5QCVLLVFHpxzdFXlMr0LJRYlputYE+d70ncmnSrfwPnfCpepP8ccLb2zPzslRz41MVFH/HkWlV6G4jNtoRy+gzY85tP7IVfpgJNEaIlkEQjFqcj+QX8F6Dj8aRNM2C8rV1bA7jV+nP4FINnePrwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/23e5f273927664d874a3750259602771/2b727/F4C5C509-3CA8-4FEB-8E91-A00F2E1BD7BA.png\"\n        srcset=\"/static/23e5f273927664d874a3750259602771/5a46d/F4C5C509-3CA8-4FEB-8E91-A00F2E1BD7BA.png 300w,\n/static/23e5f273927664d874a3750259602771/2b727/F4C5C509-3CA8-4FEB-8E91-A00F2E1BD7BA.png 368w\"\n        sizes=\"(max-width: 368px) 100vw, 368px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></td>\n<td align=\"center\"></td>\n</tr>\n</tbody>\n</table>\n<p>It was important to summate token length +4 in order to compensate for later added special entity tokens. For example, four entity tokens added to the sentence were <code>[SUB-ORGANIZATION]</code>, <code>[/SUB-ORGANIZATION]</code>, <code>[OBJ-LOCATION]</code>, <code>[/OBJ-LOCATION]</code>.</p>\n<p>It should be careful that padding=\"max_length\", not set as padding=True, so that the sentences are truncated(or sliced) properly.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 36.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAAsTAAALEwEAmpwYAAABjElEQVQY0zWQ60+CUBiH+bNrlWbZureurrV1UVAotEa21sXqQ9O0SIVWKy2oTE0QzjkcwDjWitp699uzd++XZ7+XQtgt3tbk+8alpMpVTWk4St16frdfmq7adJBZc6CCTdUGKjYVy3wlxPv+H0qumv00DMZRKGH1xUCAQYs7T3Q6x+6f53PJB3G5Ki48FiOPxaWKOFcp0V9fXQhAq9XqdDqUVNEHolqQ1gdpLRDTwwl9hNNDTHso3oxs360K0spOaSMtrQnSLFeK7d0Q8mljbBjGr/mmagxzYHQLjSdhmIMBBg6xcGQT9URxMIGFTHbv5EwW2fptRC0vKDLjmxFCf+YPqvzQ7l1vh+JGmDUG/zjMGqF4e4ZX0plMLsvns6yY58Q8W8gxhYvNK/HMNA3XdT3P8836RBJMb4N5AUylwGQSjPEoItR3TwvC6XUqU+YOyvyxlDqWfG4dyfyh+PbW0FoaIYQipGvZnh/s/BJiD/m77ZlWF1hdiAmwiH+0HNLUgFrTGhqyHdv/lt/5B6EfVhRD86w4AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20211008012353902\"\n        title=\"image-20211008012353902\"\n        src=\"/static/c1111961c4641d4965caada80c655045/c1b63/image-20211008012353902.png\"\n        srcset=\"/static/c1111961c4641d4965caada80c655045/5a46d/image-20211008012353902.png 300w,\n/static/c1111961c4641d4965caada80c655045/0a47e/image-20211008012353902.png 600w,\n/static/c1111961c4641d4965caada80c655045/c1b63/image-20211008012353902.png 1200w,\n/static/c1111961c4641d4965caada80c655045/35890/image-20211008012353902.png 1582w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 36.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAAsTAAALEwEAmpwYAAABW0lEQVQY0z2OS0/CQBSF+6fdmGCRCohuJXFFDOXVSgy6cOUrPhJdGCKJkIiK0sjATDvtzBTolBa9xejNl8nJ5J57jhIuot7r6Lk/6vSsp96w3R2iCY6nH4GwpAziOA5DCYBY/M1yufxejTImPFunm3Wu1b28yRMMVDp+uLluTn0GG/+r/5oxhtAoiqLEnDpAqTJRdbxRxpkqztTstRJTdfvskdqow9Ct7w3BFMdLAMyz2YxSCocUhFneoFlTZE2+ZfBMg2sNnjOYWmPrun9x1WrfFd/796vY+DdZCDEZT+bzuYIdkdERpKUrBPJXFUgaqBCtBthqxS6ekMYl3T91q+fjQbflOl+c+2EYQrK3Y5LdJi2YFCoUDmmiV++2SXOGkzecnEG1mpOuulqd7h29DD5HBENyoCwWkSskZdLj0uWSeNL2EgE/CTxwWAITEjtsYOE3i/nTWRAE0P8HkKFi7+SOGusAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20211008012403171\"\n        title=\"image-20211008012403171\"\n        src=\"/static/35ae088a50c5bd178760f7f18d858092/c1b63/image-20211008012403171.png\"\n        srcset=\"/static/35ae088a50c5bd178760f7f18d858092/5a46d/image-20211008012403171.png 300w,\n/static/35ae088a50c5bd178760f7f18d858092/0a47e/image-20211008012403171.png 600w,\n/static/35ae088a50c5bd178760f7f18d858092/c1b63/image-20211008012403171.png 1200w,\n/static/35ae088a50c5bd178760f7f18d858092/ddb6a/image-20211008012403171.png 1592w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>Batching strategies by <a href=\"https://huggingface.co/transformers/main_classes/data_collator.html\">using huggingface's data collate class</a>, <a href=\"https://youtu.be/7q5NyFT8REg\">applying dynamic padding</a>, or making custom <a href=\"https://mccormickml.com/2020/07/29/smart-batching-tutorial/\">uniform length batching function</a> is known to decrease the train time significantly as following. <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 28.333333333333332%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAABEUlEQVQY0zVQWZaDMAzjFNOyBcK+Q4HS6f0PppHc6UdeEluSJQfX68KyrrjHCXxRIs1yFGWF49iRuAzzssDlOaqmQdt1iJLU+t/eY9+xbRtWHkdu8H7/4rqeCCkoQNf3yLzH83kaeWFNQ6Z5wjiOJtQPA6LUYd8fxj3Ow456wcbiME0GmEiWkyjNUPKOCWg0oChQty1avp0vDJcxjThN16MfJ9a9/YOTTgQI5Ya2u//pGYkS9FWFNPfIyxKeUSWkmLrFUa2sP8NNcGCMmm5uYcTIM5u1vT0FblFszhQl5wDVYucsvtbwcw9REd+0na3sTnwgEbmSSMOla+FqJJwmkIjaZcy/zneHeguX8i/MRzDBH8l8qmB9ozH8AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20211008012609016\"\n        title=\"image-20211008012609016\"\n        src=\"/static/d013db1049e251de7dae7d521842ff6e/c1b63/image-20211008012609016.png\"\n        srcset=\"/static/d013db1049e251de7dae7d521842ff6e/5a46d/image-20211008012609016.png 300w,\n/static/d013db1049e251de7dae7d521842ff6e/0a47e/image-20211008012609016.png 600w,\n/static/d013db1049e251de7dae7d521842ff6e/c1b63/image-20211008012609016.png 1200w,\n/static/d013db1049e251de7dae7d521842ff6e/d61c2/image-20211008012609016.png 1800w,\n/static/d013db1049e251de7dae7d521842ff6e/c9d77/image-20211008012609016.png 1964w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>It is noteworthy that uniform length batching(or smart batching on the table) increased the model's performance. Due to time constraint, in this competition we applied dynamic padding only.</p>\n<p>batch_size were selected to be bigger than 30 since we assumed batch numbers being bigger than class numbers would have reduced the bias towards certain classes.</p>\n<h3 id=\"data-augmentation\" style=\"position:relative;\"><a href=\"#data-augmentation\" aria-label=\"data augmentation permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Augmentation</h3>\n<p>Attempted KoEDA(Easy Data Augmentation implemented in Korean Language) for the dataset. Teammate applied Random Insertion, Random Deletion, Random Swap, Synonym Replacement but this have not led to notable increase in performance.</p>\n<h2 id=\"model--finetuning\" style=\"position:relative;\"><a href=\"#model--finetuning\" aria-label=\"model  finetuning permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model &#x26; Finetuning</h2>\n<h3 id=\"how-to-select-pretrained-model\" style=\"position:relative;\"><a href=\"#how-to-select-pretrained-model\" aria-label=\"how to select pretrained model permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>How to select pretrained model</h3>\n<p>We fixed error entailed from using klue/roberta-large huggingface model <a href=\"https://github.com/KLUE-benchmark/KLUE/issues/33\">and provided walk-through solution on this Github Issue</a>. This was fixed by setting <code>return_token_type_ids=False</code> argument on the tokenizer encoding function. Since RoBERTa didn't have token type mask, tokenizer should not return token<em>type</em>ids.</p>\n<pre class=\"grvsc-container one-dark-pro\" data-language=\"python\" data-index=\"3\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">tokenized_sentences </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> </span><span class=\"mtk3\">tokenizer</span><span class=\"mtk1\">(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        concat_entity,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk8\">list</span><span class=\"mtk1\">(dataset[</span><span class=\"mtk6\">&quot;sentence&quot;</span><span class=\"mtk1\">]),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk4 mtki\">return_tensors</span><span class=\"mtk8\">=</span><span class=\"mtk6\">&quot;pt&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk4 mtki\">padding</span><span class=\"mtk8\">=</span><span class=\"mtk7\">True</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk4 mtki\">truncation</span><span class=\"mtk8\">=</span><span class=\"mtk7\">True</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk4 mtki\">max_length</span><span class=\"mtk8\">=</span><span class=\"mtk7\">256</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk4 mtki\">add_special_tokens</span><span class=\"mtk8\">=</span><span class=\"mtk7\">True</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk4 mtki\">token_type_ids</span><span class=\"mtk1\"> </span><span class=\"mtk8\">=</span><span class=\"mtk1\"> </span><span class=\"mtk7\">False</span><span class=\"mtk1\"> )</span><span class=\"mtk5 mtki\"># for klue/roberta-large</span></span></span></code></pre>\n<p>Pretrained model selection was based on given model benchmarks in fields of task. The task we focused on were relation extraction. If not given the corresponding performance for RE(relation extraction), we looked at Named Entity Recognition and Natural Language Inference.\u0010</p>\n<p>Model Benchmarks given by <a href=\"https://github.com/KLUE-benchmark/KLUE#baseline-scores\">KLUE's benchmark scores</a></p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Total Combined</th>\n<th>Natural Language Inference</th>\n<th>Named Entity Recognition</th>\n<th></th>\n<th>Relation Extraction</th>\n<th></th>\n<th>MRC</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Score</strong></td>\n<td>F1</td>\n<td>ACC</td>\n<td>entity F1</td>\n<td>char F1</td>\n<td>F1</td>\n<td>AUPRC</td>\n<td>EM</td>\n<td>ROUGE</td>\n</tr>\n<tr>\n<td><strong>XLM-R-base</strong></td>\n<td>83.52</td>\n<td>77.33</td>\n<td>80.73</td>\n<td>91.37</td>\n<td>57.46</td>\n<td>54.98</td>\n<td>27.48</td>\n<td>53.93</td>\n</tr>\n<tr>\n<td><strong>XLM-R-large</strong></td>\n<td>86.06</td>\n<td>85.93</td>\n<td>81.81</td>\n<td>92.49</td>\n<td>58.39</td>\n<td>61.15</td>\n<td>35.99</td>\n<td>66.77</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>KR-BERT-base</strong></td>\n<td>84.58</td>\n<td>77.17</td>\n<td>75.37</td>\n<td>90.42</td>\n<td>62.74</td>\n<td>60.94</td>\n<td>48.28</td>\n<td>58.54</td>\n</tr>\n<tr>\n<td><strong>koELECTRA-base</strong></td>\n<td>84.59</td>\n<td><em>85.63</em></td>\n<td><strong><em>86.82</em></strong></td>\n<td><strong><em>92.79</em></strong></td>\n<td>62.85</td>\n<td>58.94</td>\n<td>59.82</td>\n<td>66.05</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>KLUE-BERT-base</strong></td>\n<td><em>85.49</em></td>\n<td>81.63</td>\n<td>84.77</td>\n<td>91.28</td>\n<td>66.44</td>\n<td>66.17</td>\n<td>62.32</td>\n<td>68.51</td>\n</tr>\n<tr>\n<td><strong>KLUE-RoBERTa-base</strong></td>\n<td>85.12</td>\n<td>84.97</td>\n<td>85.13</td>\n<td>91.52</td>\n<td><em>66.66</em></td>\n<td><em>67.74</em></td>\n<td><em>68.52</em></td>\n<td><em>74.02</em></td>\n</tr>\n<tr>\n<td><strong>KLUE-RoBERTa-large</strong></td>\n<td><strong>86.42</strong></td>\n<td><strong>89.43</strong></td>\n<td>85.79</td>\n<td>91.77</td>\n<td><strong>69.59</strong></td>\n<td><strong>72.39</strong></td>\n<td><strong>76.78</strong></td>\n<td><strong>81.43</strong></td>\n</tr>\n</tbody>\n</table>\n<p>We also referred to another model benchmarks given by <a href=\"https://github.com/tunib-ai/tunib-electra\">Tunib-Electra's benchmark scores</a> and <a href=\"https://github.com/monologg/KoELECTRA\">KoElectra's benchmark scores</a></p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\"><strong># Params</strong></th>\n<th align=\"center\"><strong>Avg.</strong></th>\n<th align=\"center\"><strong>Naver NER</strong> (F1)</th>\n<th align=\"center\"><strong>KorNLI</strong> (acc)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><strong><em>TUNiB-Electra-ko-base</em></strong></td>\n<td align=\"center\">110M</td>\n<td align=\"center\"><strong>85.99</strong></td>\n<td align=\"center\">87.63</td>\n<td align=\"center\"><strong>82.27</strong></td>\n</tr>\n<tr>\n<td align=\"center\"><strong><em>TUNiB-Electra-ko-en-base</em></strong></td>\n<td align=\"center\">133M</td>\n<td align=\"center\">85.34</td>\n<td align=\"center\">87.25</td>\n<td align=\"center\">80.43</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://github.com/monologg/KoELECTRA\">KoELECTRA-base-v3</a></td>\n<td align=\"center\">110M</td>\n<td align=\"center\">85.92</td>\n<td align=\"center\"><strong>88.11</strong></td>\n<td align=\"center\">82.24</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://github.com/Beomi/KcELECTRA\">KcELECTRA-base</a></td>\n<td align=\"center\">124M</td>\n<td align=\"center\">84.75</td>\n<td align=\"center\">86.90</td>\n<td align=\"center\">81.65</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://github.com/SKTBrain/KoBERT\">KoBERT-base</a></td>\n<td align=\"center\">90M</td>\n<td align=\"center\">81.92</td>\n<td align=\"center\">86.11</td>\n<td align=\"center\">79.00</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://github.com/Beomi/KcBERT\">KcBERT-base</a></td>\n<td align=\"center\">110M</td>\n<td align=\"center\">79.79</td>\n<td align=\"center\">84.34</td>\n<td align=\"center\">74.85</td>\n</tr>\n<tr>\n<td align=\"center\"><a href=\"https://github.com/pytorch/fairseq/tree/master/examples/xlmr\">XLM-Roberta-base</a></td>\n<td align=\"center\">280M</td>\n<td align=\"center\">83.03</td>\n<td align=\"center\">86.26</td>\n<td align=\"center\">79.92</td>\n</tr>\n<tr>\n<td align=\"center\">HanBERT</td>\n<td align=\"center\">-</td>\n<td align=\"center\">-</td>\n<td align=\"center\">87.70</td>\n<td align=\"center\">-</td>\n</tr>\n<tr>\n<td align=\"center\">XLM-Roberta-Base</td>\n<td align=\"center\">-</td>\n<td align=\"center\">-</td>\n<td align=\"center\">86.65</td>\n<td align=\"center\">-</td>\n</tr>\n</tbody>\n</table>\n<p>We first tested KoElectra as backbone model, since its NER performance was the highest. But we later on switched to RoBERTA.</p>\n<p><a href=\"https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/snoop/notebooks/EDA.ipynb\">By counting the number of unk tokens of the pretrained models</a>, we assumed that the lower unknown tokens appeared, the better the model's performance it would be. <strong>Given that the number of unknown tokens are the fewest on klue/roberta-base model, we decided to stick with the klue-pretrained models.</strong></p>\n<h3 id=\"how-we-fine-tuned-the-model-according-to-the-relation-extraction-task\" style=\"position:relative;\"><a href=\"#how-we-fine-tuned-the-model-according-to-the-relation-extraction-task\" aria-label=\"how we fine tuned the model according to the relation extraction task permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>How we Fine-tuned the model according to the relation extraction task</h3>\n<p><a href=\"https://paperswithcode.com/sota/relation-extraction-on-tacred\">Based on TACRED Benchmark Leaderboard</a>, our team decided to test SOTA model according to the order. Along with TACRED score, the team also referred to <a href=\"https://aclanthology.org/P19-1279.pdf\">Matching the Blanks: Distributional Similarity for Relation Learning. Soares et al. 2019</a> to find where to extract hidden features from.</p>\n<p>According to <a href=\"https://aclanthology.org/P19-1279.pdf\">Matching the Blanks: Distributional Similarity for Relation Learning. Soares et al. 2019</a>, The best tokens to extract features from were either (1) pooling multiple entity tokens' hidden states or (2) extract the first entity markers of each subject entity and object entity. Provided model's structure from the paper are given as below, along with its methods' performance.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB2UlEQVQoz0VSiXKjMAzl/z9tZ7eTBApJCOG2MSGU+zCQt7LTUs9oLOlJlvRkY10GzEMOdV4/8nppe10kxoZhmerd/4stmLoCcqywvX5zjFnOCAIXvmvjThKFAaRcsG4bkugO1/qDm/2BOIqw0CM/55EzeM4H7pcTGGNY1/X9oErMeIKCByiyiAIFVLFxGsFZjDJPkKc+ciEwz7NOKp5P+N4VWehRURecsx0z8NowDjX6fsQ0zVrU6fsebdsR1qLvSPpB+1SXdV2jqRu0TYmu68huNKbGNqQcUVUCbTegblsM47i337U1HuyC8slJr/BNEzaaqsoLfJUCT5ZiJop2Dpd1Ix4+cf88wLOO8M6O5k+JT37PIp5sk2IcyG8OVVHX/IuA8OvxH2Lf37mlpUjkLKKKDF9ZSpwprqQepRTk4xGaQhC/mR5bUnzTNHjyd04tOMqiIM6n98hlWYLxDIwSEsaRpCmSJEFEW01pe1GSap/S4ziGoOWom2UCQRiBixwR2SnFqMUYYRjCNE04jqPFtu1dP51OsCyL8Pd9OBx2n8JN0o/Ho7bVXVUVDPWHzuczPM+j/xjAdV1cLhdcr1d93243+hYcj8cDeZ5rXUlGE6muVMcKU+9MNPZ/IGrvdGCAJvwAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20211010175325279\"\n        title=\"image-20211010175325279\"\n        src=\"/static/04eace37e68b7febdcebaeeaeb3a9d14/c1b63/image-20211010175325279.png\"\n        srcset=\"/static/04eace37e68b7febdcebaeeaeb3a9d14/5a46d/image-20211010175325279.png 300w,\n/static/04eace37e68b7febdcebaeeaeb3a9d14/0a47e/image-20211010175325279.png 600w,\n/static/04eace37e68b7febdcebaeeaeb3a9d14/c1b63/image-20211010175325279.png 1200w,\n/static/04eace37e68b7febdcebaeeaeb3a9d14/d61c2/image-20211010175325279.png 1800w,\n/static/04eace37e68b7febdcebaeeaeb3a9d14/6052f/image-20211010175325279.png 2030w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABmElEQVQoz02S646CQAyFef8XWzWAxhsq3kFUvMuKeEnOzteEZH800+m0p6en471eL1VVpff7re/3q8/nYz7x0+mkbreryWSi5/OpPM+1Wq0sBz+OYz0eDy0WCw2HQ6vxSNxsNq6wI99vqdMJNR6PdTgctFwu1Ww21e/3DWC322k+n6soCqsB8Hq9qtfrqdFoWFMDvN8LRVGiIBgrDEfabnPX+VdputHtdtNoRGxroGmamgFOjMYYb8awqp6uqHBAqeuy1M/PTEmSqywfrtHd5GCk8/lsDGCEFGVZ6nK5GBCMaUyuB2ocTxxQU1m2d2xitVotG+l4PFoRwPgYfg0EOP5+vzfGBoioCBqGoRshM/183zf9WAbJMGA87vgwHAwGxhpm5LIsA+QxCAK12223mJ6m06n5MEQ7WGDoVAMCFEWRseMOGKD8Eo/H9XptQDwkSWKaITxJAOHDFJZYlmWWx1nHqbUtE6AbbDDG585X+H/HZrOZxfAhwBujE+O/MpUHA3SDPoYE6MIJe5bAnbNeSL0opKhz8Nn8H15q4moPMg3iAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20211010175418328\"\n        title=\"image-20211010175418328\"\n        src=\"/static/684faaf06c4466e8dfde49a99141b4d8/c1b63/image-20211010175418328.png\"\n        srcset=\"/static/684faaf06c4466e8dfde49a99141b4d8/5a46d/image-20211010175418328.png 300w,\n/static/684faaf06c4466e8dfde49a99141b4d8/0a47e/image-20211010175418328.png 600w,\n/static/684faaf06c4466e8dfde49a99141b4d8/c1b63/image-20211010175418328.png 1200w,\n/static/684faaf06c4466e8dfde49a99141b4d8/d61c2/image-20211010175418328.png 1800w,\n/static/684faaf06c4466e8dfde49a99141b4d8/1a867/image-20211010175418328.png 1998w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>Thus the team chose customized Improved Baseline model for <code>(f) Entity Markers -Entity First</code> method and RBERT for <code>(e) Entity Markers - Mention Pool</code> method.</p>\n<p><strong><a href=\"https://paperswithcode.com/paper/an-improved-baseline-for-sentence-level\">ğŸ¤– Customized Improved Baseline Custom Model</a> (f1 0.736)</strong>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABYlAAAWJQFJUiTwAAACeElEQVQoz1WSbUhTYRTHz/ZhamQvaB/SBBWKoFwShUFfKkIwshfQJBTE+hAFlVIQpH5IIaQI1AXFFEEssGagZZbzhXS6JnOyzLbrdnfbbt7ci3f3dtdemsvTs5nRDhye8zzPn9/z55wH4L9AxPX8/g1iZHXfrU3sYeP8370GJnLS80152y/F7lwDogCGYSAWi0FSSJIE0WgUwtRCGo9YbLt19YKo6TgCndH9WspbEpH85Ste7/E4wL4D8jypcPEz4p65nq5tNpttC8/zhUnASCSScPCbXsyUEJ9y9XVanH5TBy+w5gMjdq+Ff44IothKNIoHp2tybiuLz5C6ou76zcPNzc2HAoHAlSRgKBRKANecdIYfscFSXdaKz1vPQ710onfG0Sh6llROdqkW0aQA1UoutK2dQwydejdrzSIOs0VRrEwClpaWgkqlkqt7nsHw2HiFcXzstcU81zExO9+pnzH2zhqNA++HtW0NAHJZC5UPD5nLeAw2VXXPpBAjcofDsXm9yTKQIWuXkVrmcbsVDpoGg8HQwi0vo9lsxvlPZtRPTyPLskic+MjbigIXpmQ2avNJnbHv6MnUjaECrv6KAwHDQtIk7zU17R0bHa16OzhY1j8wUK7RaMp0Ol3lqz7N2Rt/Nf74GvAlfkR8mEQD8LjlfmY/wIGPT9oPWl2s0qDXFxAnBRzH7aYoKpvkLpqms1Z4f27Qx21FegrgEafsM1BKyvKlcHJSV2gymYqGhoaK1Gr1TrAb9CVWORg8/S9ZIbpqdzGMRRCERbfb7SRQ1uVyfSWx4PZ4BIn3dkFafTq089zIos8R/sHTThdLB4NBgfRPslqt1X8AA4Ciq6YjslYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20211008225119287\"\n        title=\"image-20211008225119287\"\n        src=\"/static/cbf0fa5016baa03da9c3fe9bc673302a/c1b63/image-20211008225119287.png\"\n        srcset=\"/static/cbf0fa5016baa03da9c3fe9bc673302a/5a46d/image-20211008225119287.png 300w,\n/static/cbf0fa5016baa03da9c3fe9bc673302a/0a47e/image-20211008225119287.png 600w,\n/static/cbf0fa5016baa03da9c3fe9bc673302a/c1b63/image-20211008225119287.png 1200w,\n/static/cbf0fa5016baa03da9c3fe9bc673302a/d61c2/image-20211008225119287.png 1800w,\n/static/cbf0fa5016baa03da9c3fe9bc673302a/81ebd/image-20211008225119287.png 1868w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li><a href=\"https://github.com/boostcampaitech2/klue-level2-nlp-15/tree/dev\">(1) first version code @dev branch</a></li>\n<li><a href=\"https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/main/RE_improved_baseline.ipynb\">(2) Improved_Baseline code</a> (f1 0.732)</li>\n<li><a href=\"\">(3) Improved Baseline kfold code</a> (f1 0.736)</li>\n<li><a href=\"https://global-sunset-142.notion.site/RE_improved_baseline-a6f4bb9ecd2c4362996d18df507f4327\">Notes for Improved Baseline</a></li>\n</ul>\n<p><strong><a href=\"https://paperswithcode.com/paper/enriching-pre-trained-language-model-with\">ğŸ¤– Customized RBERT</a> (f1 0.745, <a href=\"https://wandb.ai/snoop2head/KLUE-RE?workspace=user-snoop2head\">ğŸ“ˆ wandb</a>)</strong></p>\n<p>ğŸ‘‰ <a href=\"https://snoop2head.github.io/Relation-Extraction-Code/\">Please refer to my blog post for detailed RBERT finetuning process</a>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 61.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAACQUlEQVQoz22S/U/acBDG+f//g+3X/bQtbskS52aWKEanm4IiBlARaIv0jb7T0pa2n51VYIle0t63T++eu+8910Csqip5Pfunp5TzqoRsVbFYrkiykjSviNMCJ0yJBVsVpcSV5MWKDYdYY31Y+yeLFzkz/Y6j8x16wwPiOKJzdM7eh120/ohQCuR5iea4/Lzp1DlFWdYcjaeP8oXMjHx2u232r1sMBn0+7f3m+lbBtgyOTi/Y+dXGDyJJroSwQnEcvl61+N8a6+48z6N/f8vO4QmtkUYlFR80SzpU8eVfGMUMVZPxRGURRfVYHucGnfEZaQaOHxIny+2VSyEo8hzX8VkmKUVRYNoOrgRKxdo7rs/cDV5GBJarM9KOpVv4uN+me6dtO1wTjx9t5v6CXFS57CvcK2aNq7pbdzjU7M317LnJaHAqolUct/qMNfO1KFPDRjcsPN+nOxgxnDyKSAsmms7DRGOszraEUvz8x1l9XoQhWZY+E1ZVuSGc2xau64qyMVHg0+te1dhCSJMkRtdnpGlax0aOx+XhXwrZuTzLt6I8tyhzFOfEqahqEwQhYZ5x8GdA/2EqOxnX2Ey3WK03TBLiMKrxSISqCYPIY2qqeGlCOlIJ7vqIJIShQ9a5pNnuMVAs1J6BGzhClqJNdIYDDS/x8KKQZRZvxtZQZg90ZLBm6pE1T1C/fcZYBmjKAOvde2bTG9m9gOaXG8bTIX5ic9aUQt8vMAIF0zFERGNLyBtmmaaoXLzCl7Jn87nzVspGg38DYY4iv+/zZQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20211008225126824\"\n        title=\"image-20211008225126824\"\n        src=\"/static/55ce894326815cec56f7c0f1037120b6/c1b63/image-20211008225126824.png\"\n        srcset=\"/static/55ce894326815cec56f7c0f1037120b6/5a46d/image-20211008225126824.png 300w,\n/static/55ce894326815cec56f7c0f1037120b6/0a47e/image-20211008225126824.png 600w,\n/static/55ce894326815cec56f7c0f1037120b6/c1b63/image-20211008225126824.png 1200w,\n/static/55ce894326815cec56f7c0f1037120b6/5ba90/image-20211008225126824.png 1604w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p><strong><a href=\"https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/085dd842e93a8d1e0d30f8cf42268ddb96cafd4a/notebooks/train_with_pororo_with_val_klue-roberta.ipynb\">ğŸ¤– Customized Concat Model</a> (f1 0.730, <a href=\"https://wandb.ai/snoop2head/huggingface/runs/1d3hlfn6?workspace=user-snoop2head\">ğŸ“ˆ wandb</a>)</strong></p>\n<p>The concat method was given from the boostcamp as a baseline. It was simply putting Entity 1 and Entity 2 with <code>[SEP]</code> separator in the beginning of the tokenized input. We tried to exclude the concat in the beginning of the tokenized sentence, but this led to worse evaluation loss and evaluation accuracy: <a href=\"https://wandb.ai/danielkim30433/huggingface/runs/3e1lomf5?workspace=user-danielkim30433\">ğŸ“ˆ wandb</a>. We concluded that putting concated subject entity and object entity in the beginning boosts the classification. Thus we also adopted customized concat model.</p>\n<ul>\n<li><a href=\"https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/main/train_with_pororo.ipynb\">(1) pororo POS &#x26; Entity tagged &#x26; stratified 5-fold cross validation </a></li>\n<li><a href=\"https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/snoop/notebooks/train_with_pororo_with_val.ipynb\">(2) replaced bert model with xlm-roberta &#x26; applied focal loss(gamma=0.5)</a> (<a href=\"https://wandb.ai/snoop2head/huggingface/runs/2576sujh\">ğŸ“ˆ wandb</a>, f1 0.70)</li>\n<li><a href=\"https://github.com/boostcampaitech2/klue-level2-nlp-15/blob/snoop/notebooks/train_with_pororo_with_val_klue-roberta.ipynb\">(3) used klue/roberta-large model &#x26; applied focal loss(gamma=0.5)</a> (<a href=\"https://wandb.ai/snoop2head/huggingface/runs/1d3hlfn6?workspace=user-snoop2head\">ğŸ“ˆ wandb</a>, f1 0.733)</li>\n</ul>\n<p><strong><a href=\"https://github.com/Saintfe/RECENT\">ğŸ¤– RECENT / Duo classifier</a> (f1 0.60)</strong> required more time to study for our team and has not been fully implemented.</p>\n<h3 id=\"findings-from-fine-tuning-methods\" style=\"position:relative;\"><a href=\"#findings-from-fine-tuning-methods\" aria-label=\"findings from fine tuning methods permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Findings from fine-tuning methods</h3>\n<p>Number of Epochs were decided by monitoring model's performance with ğŸ“ˆ wandb. KPI for the model's performance was set as evaluation loss.</p>\n<ul>\n<li>It was evident that concat model should not exceed more than 2000 training steps(or 3 epochs) as evaluation loss increased after then.</li>\n<li>However, RBERT's evaluation loss kept decreasing until 3200 training steps(or 5 epochs). This might possibly show that <strong>RBERT providing more information about the entities' relation within the sentence with additional masks increases robustness.</strong></li>\n<li>Improved Baseline is light-weight. Compared to RBERT which takes up 26GB of GPU capacity and taking 10hrs for 5 fold training, Improved Baseline on the other hand takes up about 15GB of GPU capacity and takes more or less than 4 hours for training.</li>\n<li>Let's compare RBERT and Improved Baseline method. It is surprising that light-weight Improved Baseline(f1: 0.736) almost yielded similar performance as RBERT(f1: 0.745).</li>\n<li>Improved Baseline only extracts first entity token marker whereas RBERT averages all the tokens between the entity tokens. <strong>One of the downside of averaging the hidden features of multiple entity tokens is that it ignores the order of the tokens given in the sentence.</strong> I think this is the reason that extracting the first token of the entity resulted in similar f1 score with RBERT method.</li>\n</ul>\n<h2 id=\"training\" style=\"position:relative;\"><a href=\"#training\" aria-label=\"training permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Training</h2>\n<h3 id=\"why-we-selected-focalloss-as-the-criterion\" style=\"position:relative;\"><a href=\"#why-we-selected-focalloss-as-the-criterion\" aria-label=\"why we selected focalloss as the criterion permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Why we selected FocalLoss as the criterion</h3>\n<p><img src=\"https://user-images.githubusercontent.com/30318926/134863763-eac345a4-b4c2-46f3-b093-1fcbb284ce70.png\" alt=\"img\"></p>\n<p>Looking at such class imbalance, the team tried to apply the distrubution of such classes as weights to CrossEntropy criterion and to LabelSmoothing criterion. It was worth trying, but it was better to apply focal loss, which yielded better output for the previous p-stage competition, as the criterion.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1052px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 60.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAABwUlEQVQoz4WSbW/aMBSF+f+/Zl+6TdP2qV0ZCDRQIaQNpMYOwSROnDh24vglqVMo3YumHcmWr+Xn6Opcj7quzwtiO9P3feeK39W96Vxa2zXKOJ1vRm7hFDSyklJBCAkhSrWMsf0ecM7/8KrqBpGKUooxvsAA+lwU1tpduDsej03TFAUlJHNGWZZBBK8uilMVrQhJ4zi+wCQ7gmDtDg5rpXQurjG3q1e5LrTWZ7jmnMQ4y0hO8wFWSpM0mX//5F73/5Ns65xj17ZzHGAEIRPCm3/zF7PXiOzfsf1LI61dY1XJ0+XXD2HwKN9iPmd/9emsLcuyaeo8z4UQF3iIoVWmMyRHaHq7XdxDnFTK6F/mNbBGP/r+dDoZTyZlyd5h56SVES1L6IFsn/ByHC7HINhEp1NSNLW2aSW5NK3SRcF4JVrZci5cWAPsJnGID5QWtWQZP0XHMNquYm8W3H/Z3N4s7j4+/Pjs/bzzvQWII5gmGaOsrow1A5wkyTAPo1nJaE773qiuBYcwLbCQJAZeuJ6lhxVGM29+EwaTJxSAk/tXYoCv383tJCX+xl89rHfbHdoj8Lx/3qNtCCCKUYTf5zBk2b0AGkOoPTfR1xIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image-20211008014220660\"\n        title=\"image-20211008014220660\"\n        src=\"/static/33d9c3744a70d4762fd9b4b7411aa557/218a4/image-20211008014220660.png\"\n        srcset=\"/static/33d9c3744a70d4762fd9b4b7411aa557/5a46d/image-20211008014220660.png 300w,\n/static/33d9c3744a70d4762fd9b4b7411aa557/0a47e/image-20211008014220660.png 600w,\n/static/33d9c3744a70d4762fd9b4b7411aa557/218a4/image-20211008014220660.png 1052w\"\n        sizes=\"(max-width: 1052px) 100vw, 1052px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<h3 id=\"how-we-selected-the-gamma-parameter-for-focal-loss\" style=\"position:relative;\"><a href=\"#how-we-selected-the-gamma-parameter-for-focal-loss\" aria-label=\"how we selected the gamma parameter for focal loss permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>How we selected the gamma parameter for Focal Loss</h3>\n<p>The team experiment gamma paremeter by monitoring wandb for first 500 steps. For the first 500 steps, we designated f1 score and evaluation loss as the key primary index to determine the criterion's performance.</p>\n<ul>\n<li>FocalLoss 0.5, AdamP (lowest val/loss) -> 500 step, eval loss 0.69 is considered to be higher than the concat model's evaluation loss so the team increased the gamma value.</li>\n<li>FocalLoss 1.0, AdamP (lowest val/loss) -> 500 step, eval loss 0.56 is considered to be adequate which was lower than concat model's loss. I was aware of the fact that increasing gamma value might risk the model to fall within the local minimum, so I stopped at 1.0</li>\n<li>Teammate experimented gamma parameter started off from 2.0, which is concluded to be inadequate, thus the team's gamma parameter converged to 1.0.</li>\n</ul>\n<h3 id=\"how-we-selected-the-optimizer-adamp-vs-adamw\" style=\"position:relative;\"><a href=\"#how-we-selected-the-optimizer-adamp-vs-adamw\" aria-label=\"how we selected the optimizer adamp vs adamw permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>How we selected the optimizer AdamP vs AdamW</h3>\n<p>Custom model's results were compared using wandb for first 500 steps. We concluded that AdamP of ClovaAI allowed model to converge the loss slightly faster than AdamW provided by huggingface. This is in accordance with ClovaAI team's benchmark when compared AdamW and AdamP.</p>\n<p><img src=\"https://clovaai.github.io/AdamP/static/img/table07.svg\" alt=\"img\"></p>\n<h3 id=\"other-important-details\" style=\"position:relative;\"><a href=\"#other-important-details\" aria-label=\"other important details permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Other important details</h3>\n<ul>\n<li>Applying Stratified KFold alone increased the model's performance by +3%p for f1 score (0.67 -> 0.7) for public leaderboard</li>\n<li>Schedule: linear vs cosine</li>\n<li>Saving best model strategies were differed: accuracy, f1 score, eval/loss.</li>\n</ul>\n<h3 id=\"inferencing\" style=\"position:relative;\"><a href=\"#inferencing\" aria-label=\"inferencing permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inferencing</h3>\n<ul>\n<li>Out of fold ensemble when each of the is trained on train dataset.</li>\n<li>\n<p>Soft-voting ensemble the 1) best concat model, 2) best improved baseline model, 3) best RBERT model. Each of the model's saving criteria was different, which enabled further performance boost when scored in private leaderboard.</p>\n<ol>\n<li>Best concat model was based on best accuracy</li>\n<li>Best Improved Baseline model was based on best f1 score</li>\n<li>Best RBERT model was based on lowest evaluation loss</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h3 id=\"other-details-to-try-next-time\" style=\"position:relative;\"><a href=\"#other-details-to-try-next-time\" aria-label=\"other details to try next time permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Other details to try Next time</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> str.replace() sometimes replaces not only target words/tokens, but other words/tokens that has same characters. If given the index of the target entity/token, it is better to use that even if it is such a nuisance.</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Task Adaptive Pretraining(TAPT): Pretraining for the given dataset was refrained for this competition. Since Klue/roberta models were already pretrained on task dataset, we saved time not doing pretraining. However, when given with specific domains such as math, law, science, I think it is still worth trying MLM tasks and NSP tasks based pretraining. TAPT was allowed for both train and test datasets for this competition</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Uniform Length Batching using huggingface's collate class / or making on my own.</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> optuna fine-tuning</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Round-trip translation / Back translation based on cosine similarity for data augmentation</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> Adding bidirectional GRU(or LSTM) layers after the transformers layer for the sake of non-linearity.</p>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"\">had difficulty of certain proportion of validation dataset being dropped</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> had difficulty of matching the torch tensor size in between transformers encoder layer to fully connected classifier layer.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"teamwork-\" style=\"position:relative;\"><a href=\"#teamwork-\" aria-label=\"teamwork  permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Teamwork ğŸ‘¨â€ğŸ’»</h3>\n<ul>\n<li>It was our team's first time to fine-tune BERT model for the Relation Extraction task. We set our goals to the absolute value of f1 score(0.75) and never gave up. I never looked at the leaderboard until the end of competition in order to enjoy the process of learning.</li>\n<li>Purpose of participating competition was to familiarize ourselves to fine-tuning BERT model. Finding the effective way to preprocess/train/infer was our objective.</li>\n<li>Thus our team spent most of the time doing custom preprocessing and custom model fine-tuning method of our own. Along with increasing the f1 score, it was our goal to practice writing code that reflects our idea.</li>\n<li>Since group of 7 people had to work as a team remotely, we set our ground rule not to cut in while other person is speaking.</li>\n<li>Our team decided to respect each teammate's beliefs. If teammate wants to commence certain experiment and believes that it will contribute to robustness and performance of model, we promised to patiently wait and help the experiment.</li>\n<li>By sharing both of Jupyter notebook links and wandb links, it helped other teammates to utilize(or copy &#x26; paste) code of the teammate and observe the performance.</li>\n<li>While running the model and GPU is occupied, our teammates helps to debug other teammate's code. For example, if one GPU is occpupied with MLM TAPT, then the teammate \"live coded\" putting bidirectional gru between the classifier and last transformer encoding layer.</li>\n</ul>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<ul>\n<li><a href=\"https://github.com/KLUE-benchmark/KLUE/tree/main/klue_benchmark\">KLUE RE Relation Extraction Dataset / CC BY-SA</a></li>\n<li><a href=\"https://arxiv.org/pdf/2102.01373v3.pdf\">An Improved Baseline for Sentence-level Relation Extraction(Zhou et al. 2021)</a></li>\n<li><a href=\"https://aclanthology.org/P19-1279.pdf\">Matching the Blanks: Distributional Similarity for Relation Learning. Soares et al. 2019</a></li>\n<li><a href=\"https://arxiv.org/pdf/1905.08284v1.pdf\">Enriching Pre-trained Language Model with Entity Information for Relation Classification, Wu et al. 2019</a></li>\n</ul>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n  .one-dark-pro {\n    background-color: #282c34;\n    color: #abb2bf;\n  }\n  .one-dark-pro .mtki { font-style: italic; }\n  .one-dark-pro .mtk10 { color: #C678DD; }\n  .one-dark-pro .mtk1 { color: #ABB2BF; }\n  .one-dark-pro .mtk3 { color: #61AFEF; }\n  .one-dark-pro .mtk7 { color: #D19A66; }\n  .one-dark-pro .mtk6 { color: #98C379; }\n  .one-dark-pro .mtk8 { color: #56B6C2; }\n  .one-dark-pro .mtk5 { color: #7F848E; }\n  .one-dark-pro .mtk4 { color: #E06C75; }\n  .one-dark-pro .grvsc-line-highlighted::before {\n    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));\n    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));\n  }\n</style>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/Engineering/Relation-Extraction/#dataset--dataloader\">Dataset &#x26; Dataloader</a></p>\n<ul>\n<li><a href=\"/Engineering/Relation-Extraction/#entity-representation\">Entity Representation</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#1-typed-entity-marker-dataset-creation\">(1) Typed Entity Marker Dataset Creation</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#2-typed-entity-marker-punctuation-dataset-creation\">(2) Typed Entity Marker Punctuation Dataset Creation</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#fixing-preprocessor\">Fixing Preprocessor</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#setting-maximum-token-length-for-roberta-tokenizer\">Setting maximum token length for RoBERTa tokenizer</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#data-augmentation\">Data Augmentation</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/Engineering/Relation-Extraction/#model--finetuning\">Model &#x26; Finetuning</a></p>\n<ul>\n<li><a href=\"/Engineering/Relation-Extraction/#how-to-select-pretrained-model\">How to select pretrained model</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#how-we-fine-tuned-the-model-according-to-the-relation-extraction-task\">How we Fine-tuned the model according to the relation extraction task</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#findings-from-fine-tuning-methods\">Findings from fine-tuning methods</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/Engineering/Relation-Extraction/#training\">Training</a></p>\n<ul>\n<li><a href=\"/Engineering/Relation-Extraction/#why-we-selected-focalloss-as-the-criterion\">Why we selected FocalLoss as the criterion</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#how-we-selected-the-gamma-parameter-for-focal-loss\">How we selected the gamma parameter for Focal Loss</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#how-we-selected-the-optimizer-adamp-vs-adamw\">How we selected the optimizer AdamP vs AdamW</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#other-important-details\">Other important details</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#inferencing\">Inferencing</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#other-details-to-try-next-time\">Other details to try Next time</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#teamwork-\">Teamwork ğŸ‘¨â€ğŸ’»</a></li>\n<li><a href=\"/Engineering/Relation-Extraction/#reference\">Reference</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"date":"2021-10-08","title":"KLUE Relation Extraction: Subject Entity and Object Entity","tags":["NLP","Competition"]}}},"pageContext":{"slug":"/Engineering/Relation-Extraction/","previous":{"fields":{"slug":"/Configuring/VSCode-Configuration/"},"frontmatter":{"title":"My VSCode editor settings in JSON format"}},"next":{"fields":{"slug":"/Engineering/Relation-Extraction-Code/"},"frontmatter":{"title":"RBERT for Relation Extraction: full code & Wandb log"}}}},"staticQueryHashes":["1081905842","3911196313"]}